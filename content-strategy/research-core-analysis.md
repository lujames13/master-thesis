
# Research Core Analysis
研究問題
論文旨在解決區塊鏈聯邦學習中 PBFT 共識的效率問題，同時保持計算通用性。傳統 PBFT 方案（如 FLCoin）每次聚合都需要執行共識，通信開銷高且延遲大。而 Optimistic 方案（如 opML）雖然高效，但使用 fraud proof 進行仲裁，受 FPVM 限制，無法支援複雜聚合算法和大型模型。
核心創新
Optimistic PBFT：結合 Optimistic 挑戰期與 PBFT 共識的混合機制
將 Optimistic 驗證的挑戰期理念應用於 PBFT 共識，創造一個兼具效率與計算通用性的聯邦學習驗證架構：
正常情況（無挑戰）：聚合者發布結果 → 挑戰期 → 無人挑戰 → 結果確認

依賴 1-of-N 假設（至少一個誠實驗證者會發現問題並挑戰）
樂觀通過，避免每次都執行昂貴的 PBFT 共識

異常情況（被挑戰）：驗證者提出挑戰 → 觸發 PBFT 共識（全體驗證者參與）

依賴 M-of-N 假設（>2/3 誠實節點達成共識）
驗證者在原生環境重新計算聚合，通過 PBFT 達成共識
不使用 fraud proof（關鍵差異），因此無 FPVM 的計算限制

關鍵洞察
挑戰期機制不必然要用 fraud proof 來仲裁。本研究證明 PBFT 共識同樣可以作為挑戰期的仲裁機制，從而在保持高效率的同時，獲得計算通用性（支援任意聚合算法和模型規模）。
關鍵技術

PBFT (Practical Byzantine Fault Tolerance): 用於挑戰仲裁階段的共識達成（M-of-N 誠實假設，需要 >2/3 誠實節點）
Optimistic Detection: 用於正常情況的樂觀通過機制（1-of-N 誠實假設，至少一個誠實驗證者會發現並挑戰錯誤）
Byzantine 容錯理論: 支撐威脅檢測與異常節點識別

主要對比對象

FLCoin（傳統 PBFT 方案）: 每次聚合都執行 PBFT 共識，通信開銷高且延遲大（O(n²) 通信複雜度）
opML (Optimistic Machine Learning): 基於 fraud proof 的樂觀驗證機制，採用鏈下執行 + 挑戰期的模型，依賴 1-of-N 誠實假設。使用 FPVM (Fault Proof Virtual Machine) 進行仲裁，受記憶體和計算限制
zkML (Zero-Knowledge Machine Learning): 基於零知識證明的鏈上驗證機制，透過 zk-SNARKs/zk-STARKs 等證明系統提供數學級別的計算完整性保證，但需要算術化，計算開銷極高

優勢分析
1. 效率優勢（相對於傳統 PBFT）—— 主要貢獻
本研究在兩個獨立維度上實現了顯著的效率提升：

計算負擔優化：從每節點 R 次聚合降至 R/N 次
通訊複雜度優化：從 O(n²) 降至平均 O(1)

1.1 計算負擔優化（聚合運算次數）
傳統 PBFT 的計算負擔問題
傳統 PBFT 方案（如 FLCoin [9]）中，每個驗證者都需要參與每輪聚合的驗證：

每個驗證者的聚合運算次數：R 次（R 為總訓練輪數）
系統總聚合運算次數：R × V 次（V 為驗證者數量）

本研究的多聚合器輪替機制
通過引入多聚合器架構並採用輪替（Round-Robin）機制：
(1) 計算負擔分散

每個聚合器的平均聚合運算次數：R/N 次（N 為聚合器總數）
單節點計算負擔降低：N 倍
系統總聚合運算次數（正常情況）：R 次（分散在 N 個聚合器上）

(2) 考慮挑戰情況
設挑戰發生概率為 p：

聚合器的聚合次數：R/N 次（不變）
驗證者的平均聚合次數：p × R 次（僅在被挑戰時重新計算）
系統總計算量：R × (1 + p × V) 次

(3) 計算效率提升

單節點負擔降低：從 R 次 → R/N 次（降低 N 倍）
系統總開銷降低（當 p 較小時）：從 R × V → R × (1 + p × V)

範例：當 p=0.05, V=21 時，系統總計算量從 2,100 次降至 205 次（降低約 90%）




1.2 通訊複雜度優化（消息交換次數）
傳統 PBFT 的通訊開銷問題
傳統 PBFT 方案在每次聚合時都需要執行完整的 PBFT 共識協議，這導致：
(1) 高通訊開銷

PBFT 需要 O(n²) 的通訊複雜度，其中 n 為驗證者數量
每次聚合需要多輪消息交換：Pre-Prepare → Prepare (n 個消息) → Commit (n 個消息)
當驗證者數量增加時，通訊成本呈平方級增長

(2) 高延遲

每次聚合都需要等待多輪通訊完成（至少 2 輪）
需要等待 >2/3 節點響應才能達成共識
在網路延遲較高或節點地理分布廣泛的場景中，延遲更加顯著

(3) 無差異化處理

無論實際威脅等級如何，每次聚合都執行相同的昂貴協議
在低威脅場景下（大多數情況），這種「過度保護」造成資源浪費

本研究的 Optimistic PBFT 通訊優勢
(1) 樂觀通過機制（正常情況）

無需共識協議：大多數情況下（無挑戰），結果在挑戰期結束後直接確認
通訊開銷降至 O(1)：聚合器只需發布一次結果，無需多輪消息交換
低延遲：只需等待挑戰期（例如幾分鐘），無需等待共識協議的多輪通訊

(2) 按需執行 PBFT（異常情況）

只在被挑戰時才觸發 PBFT 共識
假設大多數情況下聚合是誠實的（這在許可鏈/聯盟鏈場景中是合理假設）
平均通訊開銷遠低於傳統 PBFT

(3) 通訊效率分析
設挑戰發生的概率為 p（通常 p << 1）：

傳統 PBFT：每次聚合開銷 = O(n²)
Optimistic PBFT：平均開銷 = O(1) × (1-p) + O(n²) × p ≈ O(1)
效率提升：當 p 較小時（例如 p < 0.1），平均效率提升接近 O(n²)

(4) 可擴展性優勢

傳統 PBFT 的可擴展性受限於 O(n²) 通訊複雜度，實際部署通常限制在 10-20 個驗證者
Optimistic PBFT 在正常情況下的 O(1) 開銷，使得系統可以支援更多驗證者而不顯著影響效率


1.3 雙重效率提升的綜合效果
本研究通過混合 Optimistic-PBFT 機制，實現了兩個維度的獨立且互補的效率提升：
優化維度傳統 PBFT本研究提升倍數計算負擔（單節點）R 次/節點R/N 次/節點N 倍通訊開銷（正常）O(n²) 每輪O(1) 每輪n² 倍系統總計算量（p=0.05）R × VR × (1+p×V)V/(1+p×V) 倍
數值範例（R=100, N=10, V=21, p=0.05）
計算維度：

單個聚合器：100 次 → 10 次（降低 90%）
系統總計：2,100 次 → 205 次（降低 90.2%）

通訊維度：

每輪消息：約 882 條 → 約 45 條（降低 94.9%）
總消息數：88,200 條 → 4,505 條（降低 94.9%）

關鍵洞察：

計算優化來自多聚合器輪替機制（architectural design）
通訊優化來自樂觀通過機制（consensus design）
兩者結合產生乘法效應，實現雙重效率提升


2. 計算通用性優勢（相對於 opML/zkML）—— 次要貢獻
雖然 opML 和 zkML 等方案提供了不同的安全保證和效率權衡，但它們都面臨計算通用性限制，無法支援聯邦學習中的任意聚合操作。
opML 的計算限制
opML 使用 fraud proof 進行挑戰仲裁，需要通過 FPVM (Fault Proof Virtual Machine) 重新執行計算 [3]。這導致：

記憶體限制：FPVM 記憶體上限為 4GB，無法載入大型模型
複雜邏輯分解困難：需要將聚合邏輯分解為 VM 指令層級。對於帶正則化的優化問題（如 FedProx）或需要排序/距離計算的算法（如 Krum），分解過程極其複雜甚至不可行
無 GPU 加速：FPVM 必須在 CPU 上模擬執行，無法利用 GPU 加速

zkML 的計算限制
zkML 使用零知識證明進行驗證，需要將計算「算術化」(arithmetization) 為算術電路 [1][4]。這導致：

模型規模限制：對 7B+ 參數模型「完全不可行」，實際可驗證上限僅約 18M 參數 [1][2]
算法限制：只能驗證可高效算術化的簡單算法（如 FedAvg），無法處理需要複雜邏輯的 Byzantine-robust 算法（如 Krum、Median、Trimmed Mean）
證明開銷：證明生成「慢數個數量級」，例如 ResNet50 聚合需約 55 分鐘 [8]

本研究的優勢
關鍵差異：本研究的挑戰仲裁機制是 PBFT 共識（而非 fraud proof 或零知識證明）

驗證者在原生環境執行：不需要 FPVM，不需要算術化
支援任意聚合算法：包括 FedAvg、FedProx、q-FedAvg、Krum、Median、Trimmed Mean 等任何算法，甚至包括未來提出的新算法
支援任意模型規模：7B-175B 參數的大型語言模型
原生框架與 GPU 加速：可使用完整的 PyTorch/TensorFlow 和 GPU/TPU 環境
高效仲裁：PBFT 共識（分鐘級）遠快於 zkML 的證明生成（數十分鐘到小時級）

總結：opML 和 zkML 的方案雖然在信任模型或透明度上有各自的優勢，但在聯邦學習場景中，它們受限於各自驗證機制的計算能力。本研究通過使用 PBFT 作為仲裁機制，在保持樂觀通過效率的同時，實現了對任意聚合操作的支援。

3. 雙層安全模型與計算通用性
本研究採用雙層安全模型，結合兩種信任假設的優勢：
第一層：Optimistic 檢測（1-of-N 誠實假設）

機制：聚合者發布結果 → 挑戰期 → 驗證者監控
假設：只要有至少一個誠實驗證者在線並檢查結果，就能發現錯誤並提出挑戰
優勢：大多數情況下（無惡意行為）實現高效率

第二層：PBFT 仲裁（M-of-N 誠實假設）

機制：挑戰觸發 → 全體驗證者重新計算 → PBFT 共識
假設：需要超過 2/3 的驗證者誠實
優勢：當檢測到問題時，提供強安全性保證（Byzantine 容錯）

相對於其他方案的優勢分析
這種雙層模型提供了「防禦縱深」(Defense in Depth)，同時避免了鏈上仲裁機制的計算限制：
(1) 相對於傳統 PBFT

效率更高：大多數情況樂觀通過，避免每次都執行 O(n²) 共識
計算通用性相同：同樣在原生環境執行，無限制

(2) 相對於 opML/zkML（關鍵差異）

計算通用性更高：不需要管理鏈上仲裁機器（FPVM 或算術電路），因此無以下限制：

✅ 無記憶體上限（opML 的 4GB 限制）
✅ 無需將聚合邏輯分解為 VM 指令或算術電路
✅ 可使用完整的原生框架和 GPU 加速
✅ 支援任意複雜的聚合算法（Byzantine-robust、自適應算法等）
✅ 支援任意規模的模型（7B-175B 參數）


效率相當：正常情況下同樣採用樂觀通過，效率相近
信任模型權衡：

opML/zkML 的優勢：1-of-N 或數學級信任，仲裁過程可在鏈上驗證
本研究的優勢：雙層防禦（1-of-N + M-of-N），在聯盟鏈場景中同樣有效



適用場景分析
特性opMLzkML本研究仲裁機制Fraud Proof (FPVM)Zero-Knowledge ProofPBFT 共識計算環境虛擬機（受限）算術電路（受限）原生環境（無限制）模型規模上限~4GB 記憶體限制~18M 參數無限制（僅受硬體限制）算法支援簡單算法簡單算法任意算法適用場景公鏈 + 簡單 FL極高信任要求 + 小模型聯盟鏈 + 通用 FL
總結：本研究通過採用 PBFT 作為仲裁機制，在保持與 opML/zkML 相近的效率優勢的同時，避免了鏈上仲裁機器帶來的計算限制，實現了對聯邦學習場景中任意聚合操作的支援。這種設計特別適合聯盟鏈/許可鏈環境中的生產級聯邦學習應用。

4. 方案對比總結
方案效率（正常情況）計算通用性信任模型適用場景傳統 PBFT低（每次 O(n²)）高（原生執行）M-of-N (>2/3)高威脅 + 小規模驗證者opML高（樂觀通過）中等（受 FPVM 限制）1-of-N公鏈 + 中型模型 + 簡單算法zkML低（證明生成慢）極低（18M 參數上限）數學級信任小模型 + 簡單算法 + 極高信任要求本研究 (Optimistic PBFT)高（樂觀通過）高（原生執行）1-of-N + M-of-N（雙層）聯盟鏈 + 生產環境的通用 FL 應用
本研究的定位：在聯盟鏈/許可鏈場景中（驗證者集合已知且基礎信任度較高），通過將 Optimistic 挑戰期與 PBFT 共識結合，既保持了與 opML/zkML 相近的效率，又通過避免鏈上仲裁機器的限制實現了計算通用性，從而達到效率、安全性與計算通用性的最佳平衡，使其適合生產環境的真實聯邦學習應用。

Key References
本文檔引用的核心文獻：

[1] Z. Xing et al., "Zero-Knowledge Proof-based Verifiable Decentralized Machine Learning in Communication Network: A Comprehensive Survey," arXiv preprint arXiv:2310.14848, 2023.
[2] D. Kang, K. Gurkan, and A. Rose, "Scaling up Trustless DNN Inference with Zero-Knowledge Proofs," in Proc. NeurIPS RegulateML Workshop, 2023.
[3] K. Conway et al., "opML: Optimistic Machine Learning on Blockchain," arXiv preprint arXiv:2401.17555, 2024.
[4] Z. Peng et al., "A Survey of Zero-Knowledge Proof Based Verifiable Machine Learning," arXiv preprint arXiv:2502.18535, 2025.
[8] M. Bahrami, "Decentralized Federated Learning on Blockchain using Zero Knowledge Proofs," Tesi Luiss, 2024.
[9] [FLCoin 相關文獻待補充]

備註: 完整的 zkML 研究參考文獻（63 篇）保存於獨立的 zkML 研究報告中，需要時可查閱。
