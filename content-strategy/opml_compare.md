### 3.2.1 opML - Optimistic Machine Learning

[...前面內容相同...]

**4. 計算通用性限制 - 關鍵差異** (0.3頁) ← 新增!

opML 的鏈上仲裁機制雖然提供了去中心化透明度,
但在處理聯邦學習聚合驗證時面臨**四大根本性限制**:

**(1) FPVM 記憶體限制** (0.08頁)
FPVM 記憶體上限為 4GB,無法直接載入大型模型。
例如 7B-LLaMA 模型在 float64 下需要 26GB。
雖然 opML 提出 Lazy Loading 與 Multi-Phase Protocol,
但在 FL 聚合場景中需同時載入多個客戶端模型參數,
記憶體需求可達數百 GB,根本無法在 FPVM 中執行。

**本研究優勢**:
驗證者在自己的環境重新計算聚合,無記憶體限制,
可使用完整的 PyTorch/TensorFlow,支援任意規模模型。

**(2) 浮點數計算確定性限制** (0.08頁)
opML 必須使用固定點運算 (quantization) 保證確定性,
因為浮點數的 (a+b)+c ≠ a+(b+c)。
這導致精度損失 (float32 → int16/int8),
且無法使用原生 ML 框架,限制了可驗證算法種類。

**本研究優勢**:
驗證者使用相同浮點數設定重新計算,
允許小範圍誤差 (ε-tolerance),
可使用原生框架,支援任意聚合算法。

**(3) 複雜聚合邏輯分解限制** (0.08頁)
Fraud proof 需將計算分解為 VM 指令層級。
對於簡單的 FedAvg 可行,但對於複雜聚合算法:
- FedProx (帶正則化優化): argmin 問題無法分解
- Krum (Byzantine-robust): O(n²) 距離計算 Gas 爆炸
- 自定義聚合邏輯: 可能無法表達為 VM 指令序列

**實際問題**:
許多 FL 研究提出專門的聚合算法 (如 q-FedAvg、FedNova),
這些算法包含複雜的優化邏輯,無法在智能合約中驗證。

**本研究優勢**:
驗證者直接執行高層語義聚合操作,
無需分解為 VM 指令,支援任意聚合算法。

**(4) GPU/TPU 加速限制** (0.06頁)
FPVM 必須在 CPU 模擬執行,無法利用 GPU/TPU。
雖然 Multi-Phase Protocol 允許部分階段原生執行,
但最終仲裁步驟仍需在 VM 中執行,
對於大型模型驗證可能需要數小時。

**本研究優勢**:
驗證者使用完整 GPU/TPU 環境,
與原生訓練環境效能相同。

**總結: Universality vs Transparency Tradeoff** (0.05頁)

opML 與本研究代表兩種設計哲學的權衡:

| 維度 | opML | 本研究 |
|------|------|--------|
| 仲裁透明度 | 完全鏈上,公開可驗證 | 鏈下共識,結果上鏈 |
| 計算通用性 | 受 FPVM 限制 | 無限制 (Universal) |
| 支援算法 | 簡單 ML 推理/聚合 | 任意聚合算法 |
| 大型模型 | 需特殊優化 | 原生支援 |
| 驗證成本 | Gas 成本 | 驗證者計算成本 |

**本研究選擇**:
在聯邦學習場景中,我們優先考慮**計算通用性**而非**鏈上透明度**,
因為:
(1) FL 聚合算法複雜多樣,需要支援任意算法
(2) 模型規模越來越大 (數十 GB ~ 數百 GB)
(3) 聯盟鏈場景中,驗證者集合已知且可信度較高
(4) PBFT 共識結果仍可上鏈審計

這使得本研究更適合**生產環境的真實 FL 應用**,
而 opML 更適合**公開鏈上的簡單 ML 推理任務**。
