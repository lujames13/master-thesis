# Chapter 3: Related Work

## C. Optimistic Verification Mechanisms (2.5頁)

本節探討樂觀驗證機制在區塊鏈聯邦學習中的應用。Optimistic方法基於「大多數情況下參與者是誠實的」這一假設,在正常情況下採用樂觀通過策略以提升效率,僅在檢測到異常時才啟動驗證流程。我們首先深入分析Optimistic Machine Learning (opML)的核心機制與性能優勢,然後批判性地評估其FPVM計算限制對聯邦學習實際部署的影響。接著簡要介紹Optimistic Rollup在區塊鏈擴容中的應用及其對FL的適用性。最後總結樂觀方法在效率與計算通用性之間的根本性困境,引出本研究的創新貢獻。

---

### C.1 Optimistic Machine Learning (opML) (1.5頁)

#### C.1.1 Core Mechanism and Philosophy (0.3頁)

**段落19：樂觀執行原理** Conway等人提出的Optimistic Machine Learning (opML)將Ethereum Layer 2的樂觀執行哲學引入機器學習驗證場景[TODO: Conway-opML]。opML的核心理念是:**假設誠實,立即接受,挑戰期內可驗證**。系統預設聚合計算的執行者(proposer)誠實,直接接受其提交結果。安全性基於「1-of-N誠實假設」——只要至少一個驗證者(challenger)誠實監控,即可檢測惡意行為。相較於PBFT要求>2/3節點誠實,樂觀方法的信任門檻顯著降低。

**挑戰驗證機制**:系統設置固定挑戰期(通常7天)。若驗證者發現錯誤,可提交質押發起挑戰。挑戰通過交互式欺詐證明(Interactive Fraud Proof)仲裁:挑戰者與proposer進行二分搜索定位爭議步驟,在Fault Proof Virtual Machine (FPVM)中重新執行該步驟,鏈上智能合約判定正確性。正確方獲得獎勵,錯誤方質押被罰沒。這種質押-挑戰-罰沒機制通過經濟博弈實現安全性,已在Optimism、Arbitrum等Layer 2方案中成功運行多年。

**效率優勢與潛在限制**:正常情況下,opML僅需O(1)通訊(proposer提交結果雜湊),驗證者被動監控,實現接近理想的效率。挑戰發生時,交互式證明的驗證複雜度為O(log n)(二分搜索步驟)。然而,FPVM作為通用虛擬機,在支援ML計算方面存在固有約束,這將在下節深入分析。

#### C.1.2 Performance Advantages (0.2頁)

**段落20：效率分析** opML相較於PBFT實現數量級的效率提升,如表C.0所示:

| 維度 | PBFT | opML(正常) | opML(挑戰) |
|------|------|-----------|-----------|
| 通訊複雜度 | O(n²) | O(1) | O(log n) |
| 驗證開銷 | 每次全員共識 | 被動監控 | 交互式證明 |
| 可擴展性 | n<100(實務) | 任意n | - |
| 挑戰率 | - | <0.01%[TODO: Ethereum-challenge-rate] | - |

**表C.0: opML vs PBFT效率對比**

**正常情況的理想效率**: Proposer僅提交結果雜湊(O(1)通訊),驗證者被動監控無需計算。Ethereum實證顯示挑戰率<1%[TODO: Ethereum-challenge-rate],若適用於FL,系統可在99%時間以O(1)運行。相較PBFT每次聚合需2n(n-1)條消息(Prepare+Commit階段),樂觀方法接近理想效率。

**挑戰情況的對數級成本**: 挑戰發生時,驗證複雜度為O(log n)。Conway等人實驗顯示,驗證7B參數LLaMA推理在標準PC上僅需數分鐘,證明大小數KB至數MB[TODO: Conway-LLaMA-exp]。

**可擴展性突破**: PBFT因O(n²)複雜度實務上n<100,opML支援任意數量驗證者(被動監控無額外通訊),特別適合邊緣設備網絡或跨機構FL系統。

#### C.1.3 ⭐ Core Limitation: FPVM Computational Constraints (1.0頁)

**段落21-23：FPVM計算約束** 儘管opML在效率上展現出巨大潛力,但其核心驗證機制——Fault Proof Virtual Machine (FPVM)——存在三大根本性限制,嚴重制約了其在實際聯邦學習場景中的適用性。

##### 批判點1: 記憶體瓶頸 (0.3頁)

FPVM在區塊鏈環境中重新執行計算以生成欺詐證明,受限於虛擬機資源。當前主流FPVM實現(如Optimism的Cannon、Arbitrum的WAVM)存在**4GB記憶體上限**[TODO: FPVM-memory-limit],這對大型模型的聯邦學習造成嚴重限制。如表C.1所示,中型模型GPT-2(1.5B參數)需約3GB記憶體已接近上限,主流LLaMA-7B需14GB超出3.5倍,LLaMA-70B需140GB超出35倍。實際FL應用中的大型模型(如醫療影像的ViT-Large、金融風控的BERT-large)均面臨此限制。

| 模型 | 參數量 | 記憶體需求(FP16) | FPVM可行性 |
|------|--------|-----------------|-----------|
| BERT-Base | 110M | ~0.5GB | ✅ 可行 |
| GPT-2 | 1.5B | ~3GB | ⚠️ 接近上限 |
| LLaMA-7B | 7B | ~14GB | ❌ 超出3.5倍 |
| LLaMA-13B | 13B | ~26GB | ❌ 超出6.5倍 |
| LLaMA-70B | 70B | ~140GB | ❌ 超出35倍 |

**表C.1: 主流模型記憶體需求與FPVM限制對比**

**聚合過程記憶體需求放大**:聯邦學習聚合階段需同時處理多個客戶端更新。即使單個模型梯度佔用500MB,10個客戶端聚合就需5GB記憶體,超出FPVM上限。Byzantine-robust算法(如Krum、Median)需保存所有更新計算距離或中位數,需求進一步增加。此外,FPVM無法利用量化或稀疏化等壓縮技術(會改變計算邏輯導致驗證不一致),必須使用原始訓練精度,無法享受記憶體節省。

##### 批判點2: 複雜算法分解困難 (0.4頁)

FPVM要求將聚合邏輯分解為虛擬機指令層級(通常為RISC-V或WASM指令集)。簡單算法如FedAvg(`w = (1/K)Σw_i`)可直接映射為基本算術指令,證明生成相對容易,這也是opML論文驗證的主要案例[TODO: Conway-opML]。

然而,實際FL系統常採用更複雜的聚合策略。**帶優化的算法**(如FedProx: `w_t+1 = argmin[F(w) + (μ/2)||w-w_t||²]`)需要在FPVM中實現優化器狀態管理、正則化梯度計算、迭代收斂控制和數值穩定性處理,證明生成時間可能從數分鐘暴增至數小時。**Byzantine-robust算法**(如Krum需計算高維向量距離、排序、動態數據結構)複雜度進一步爆炸,幾乎不可行。Conway等人也承認:「複雜ML算法的FPVM驗證仍是開放性問題」[TODO: Conway-opML-quote]。

更根本的是,每當提出新聚合算法(如FedAdam、Scaffold等),都需重新FPVM層級實現,開發成本極高;相較之下原生Python/PyTorch環境僅需數十行代碼,靈活性差距使opML難以跟上FL研究前沿。

##### 批判點3: 無GPU加速 (0.3頁)

FPVM必須在CPU環境執行,無法利用GPU/TPU硬體加速,對大模型聚合造成嚴重性能瓶頸。如表C.2所示,7B模型前向傳播在GPU僅需2秒,FPVM的CPU模擬需60秒,性能差距達30倍。聚合1000客戶端梯度,GPU環境5秒,FPVM需150秒。

| 操作 | 原生PyTorch+GPU | FPVM CPU模擬 | 倍數差異 |
|------|----------------|-------------|---------|
| 7B模型前向傳播 | ~2秒 | ~60秒 | 30x |
| 梯度聚合(1000客戶端) | ~5秒 | ~150秒 | 30x |
| 參數更新 | ~1秒 | ~30秒 | 30x |

**表C.2: GPU vs FPVM性能對比(基於LLaMA-7B模型)**

**挑戰驗證成為瓶頸**:雖然正常情況下無驗證開銷,但挑戰發生時FPVM驗證累積時間可能超過訓練本身。假設100輪訓練(總8分鐘),若10%被挑戰(每次150秒),總挑戰驗證達1500秒(25分鐘),遠超原始訓練。若挑戰率上升至30%,驗證開銷完全抵消樂觀執行優勢。此外,FPVM鎖定CPU執行,無法享受GPU技術快速發展(如H100相較A100的6-9倍加速)帶來的紅利,性能差距將持續擴大。

#### C.1.4 Implications and本研究的差異 (0.3頁)

##### opML對本研究的啟發 (0.15頁)

**段落24：opML的啟發** 儘管存在上述計算限制,opML仍然為本研究提供了重要的理論啟發:

**樂觀執行的效率優勢**: opML證明了「樂觀假設+挑戰驗證」這一範式在機器學習場景下的可行性。正常情況下O(1)的通訊複雜度相較於PBFT的O(n²)實現了數量級的效率提升,這種優勢在大規模聯邦學習中尤為顯著。

**挑戰期設計的實用性**: 7天挑戰期的設計在Ethereum Rollup生態中已經過充分驗證,證明了固定時間窗口的可操作性。這種設計在聯邦學習中同樣適用,可根據模型重要性和訓練頻率靈活調整挑戰期長度(例如關鍵醫療模型設置較長挑戰期,快速迭代的推薦系統使用較短挑戰期)。

**1-of-N誠實假設的合理性**: 在許可鏈或聯盟鏈場景下(這也是多數企業級聯邦學習的部署環境),參與者通常具有一定的身份認證和信譽基礎,「至少存在一個誠實驗證者」這一假設是合理的。相較於無許可公鏈需要假設多數誠實(如PBFT的>2/3),許可鏈環境可以接受更寬鬆的信任假設。

**經濟激勵的有效性**: 質押-罰沒(staking-slashing)機制通過經濟博弈實現安全性,這種設計在實踐中證明有效(Ethereum的PoS共識已成功運行數年,質押總價值超過數百億美元)。本研究繼承了opML的經濟安全哲學,通過激勵相容性設計引導理性參與者誠實行為。

##### 關鍵差異與改進 (0.15頁)

**段落25：關鍵差異與改進** 本研究的核心創新在於:用**PBFT共識替代Fraud Proof**作為挑戰仲裁機制,從而在保留樂觀執行效率的同時,消除FPVM的計算限制。具體對比如表C.3所示:

| 維度 | opML | 本研究 |
|------|------|--------|
| 仲裁機制 | Fraud Proof (FPVM) | PBFT Consensus |
| 計算環境 | 虛擬機(4GB限制) | 原生環境(無限制) |
| 模型規模 | ≤2B參數 | 任意規模(7B-175B+) |
| 算法支援 | 簡單算法 | 任意Python/PyTorch代碼 |
| 硬體加速 | ❌ CPU only | ✅ GPU/TPU可用 |
| 安全保證 | 1-of-N誠實 | 1-of-N + f<n/3(雙層) |

**表C.3: opML與本研究的關鍵差異**

**效率對比分析**: 在效率層面,opML與本研究既有相同點也有關鍵差異:

**相同點**:兩者都採用樂觀通過機制,正常情況下通訊開銷都是O(1),避免了PBFT每輪需要O(V²)消息的瓶頸。這種樂觀假設使得兩者在無挑戰時都能享受接近理想的通訊效率。

**差異點**:本研究在計算和仲裁兩個維度與opML不同。(1)**計算負擔**:opML每輪由單一proposer執行聚合,本研究通過多聚合器輪替實現O(R/N)計算分散(每個聚合器僅執行R/N次,相較傳統PBFT的R次降低N倍);(2)**仲裁機制**:opML使用FPVM進行欺詐證明驗證(受記憶體、算法、GPU限制),本研究使用PBFT共識在原生環境仲裁(無計算限制但需O(V²)通訊);(3)**異常開銷**:opML挑戰驗證為O(log n)交互式證明,本研究為O(V²) PBFT共識——這是為獲得計算通用性而接受的trade-off。

**適用場景**:opML適合**公鏈環境** + **中型模型**(≤2B參數) + **簡單聚合算法**(FedAvg等),其FPVM驗證在區塊鏈上可公開審計。本研究適合**聯盟鏈環境** + **任意規模FL**(7B-175B+參數) + **複雜聚合算法**(FedProx、Krum等),強調生產環境的實用性和算法通用性。

**原生環境執行的優勢**: 當挑戰發生時,本研究的驗證者在原生Python/PyTorch環境中重新執行聚合計算,可直接使用完整的深度學習框架和硬體加速。這意味著:
1. 無記憶體上限,可處理任意規模模型(7B-175B參數的大型語言模型、大型Vision Transformer等)
2. 支援任意聚合算法,包括FedProx、FedAdam、Krum、Median等複雜方法,甚至未來提出的新算法
3. 可利用GPU/TPU加速,驗證時間與原生訓練相當(數秒至數分鐘),而非FPVM的數十倍開銷

**雙層安全模型的增強**: 本研究結合了opML的1-of-N檢測層與PBFT的M-of-N仲裁層,實現「防禦縱深」:
- **正常情況**: 依賴1-of-N假設,任一誠實驗證者發現問題即可觸發挑戰,享受O(1)效率
- **挑戰情況**: 啟動PBFT共識,要求>2/3驗證者達成一致,提供Byzantine容錯保證

這種雙層模型相較於pure opML(僅依賴1-of-N)提供了更強的安全性:即使挑戰者與被挑戰者串謀,仍需PBFT共識裁決,攻擊者必須控制>1/3驗證者才能破壞系統。

**核心問題的解答**: opML提出了「能否保留Optimistic效率優勢,同時使用更通用的仲裁機制」這一關鍵問題。本研究的答案是:**用PBFT共識替代Fraud Proof**。這種設計實現了效率(樂觀通過)、安全性(Byzantine容錯)和通用性(支援任意算法和模型)的統一,使得樂觀驗證機制真正適用於生產環境的聯邦學習系統。

---

### C.2 Optimistic Rollup in Blockchain Context (0.7頁)

#### C.2.1 Ethereum Layer 2 Background (0.4頁)

**段落26：Optimistic Rollup基本原理** Optimistic Rollup是Ethereum為解決Layer 1擴容瓶頸而提出的Layer 2方案,採用「鏈下執行,鏈上驗證」架構。排序器(sequencer)在鏈下批量處理交易並將執行結果壓縮為單一狀態根(state root),提交至主網並開啟固定挑戰期(通常7天)。在此期間,任何驗證者可本地重放交易序列,若發現狀態根錯誤則提交欺詐證明觸發鏈上仲裁。這種設計允許高吞吐量的鏈下執行,同時保留Layer 1的安全性和終局性保證[TODO: OptimisticRollup]。

**實踐驗證樂觀假設的有效性**: Arbitrum和Optimism已在Ethereum主網運行多年,展現顯著成效:吞吐量達4,000+ TPS(相較主網提升100-200倍),成本降至主網的1/10至1/50。最關鍵的是,**挑戰率遠低於0.01%**[TODO: Optimism-challenge-rate],證明「大多數情況下執行者誠實」這一樂觀假設在實踐中成立。這為樂觀方法應用於聯邦學習提供了堅實的經驗支持。

**架構原則可遷移至FL**: Optimistic Rollup證明了以下設計的可行性:(1)分層架構——高頻執行與低頻驗證分離;(2)固定挑戰期——平衡安全與效率;(3)經濟激勵——質押-罰沒機制引導誠實行為;(4)1-of-N安全模型——僅需一個誠實監控者。這些原則可直接應用於FL:聚合器類比排序器,模型驗證挑戰類比欺詐證明挑戰。

**未針對ML優化的關鍵差距**: 然而,Optimistic Rollup的欺詐證明系統專為EVM智能合約設計,對於ML計算存在根本性不匹配:(1)驗證對象不同——EVM執行確定性邏輯(毫秒級),ML聚合處理高維張量運算(秒至分鐘級);(2)硬體需求不同——EVM僅需CPU,ML高度依賴GPU加速;(3)FPVM通用性限制——為支援通用計算而犧牲效率,對ML特定的矩陣運算和大模型處理不友好。這些差距導致opML在實際FL場景中面臨前述的記憶體、算法、性能瓶頸。

#### C.2.2 Applicability to Federated Learning (0.3頁)

**段落27：Optimistic Rollup對FL的適用性** Optimistic Rollup的設計理念可以遷移至聯邦學習,但需要認識到兩個領域的本質差異:

**相似點——計算密集型任務的樂觀執行**:
1. **高頻執行需求**: Rollup需要處理高頻金融交易,FL需要處理高頻模型更新,兩者都面臨「執行頻率遠高於驗證能力」的挑戰
2. **信任假設合理性**: Rollup假設排序器大概率誠實(因為作弊會損失質押),FL可假設聚合器大概率誠實(因為參與方通常為企業或機構,具有長期聲譽考量)
3. **1-of-N防禦模型**: 兩者都依賴「只要有一個誠實監控者就能發現問題」的安全模型,適合許可鏈或聯盟鏈環境
4. **經濟激勵適用**: 質押-挑戰-罰沒機制可直接應用於FL,通過經濟博弈引導誠實行為

**差異點——驗證機制的計算特性**:
1. **驗證對象不同**: Rollup驗證的是EVM智能合約執行(確定性計算,狀態轉換邏輯固定),FL驗證的是ML模型聚合(涉及高維張量運算、浮點數計算,數值精度敏感)
2. **計算複雜度差異**: Rollup的單筆交易驗證通常在毫秒級(執行數百條EVM指令),FL的單次聚合驗證可能需要數秒至數分鐘(處理數百萬至數億參數的模型)
3. **硬體需求不同**: EVM執行對硬體要求低,普通CPU即可,FL聚合(尤其大模型)高度依賴GPU/TPU加速
4. **確定性要求**: EVM執行是完全確定性的(相同輸入必然產生相同輸出),FL聚合可能涉及浮點數捨入誤差,需要容忍一定範圍內的數值差異

**結論**: Optimistic Rollup為FL提供了寶貴的架構參考和實踐驗證,證明了樂觀執行+挑戰驗證範式的可行性。然而,其通用欺詐證明機制(FPVM)專為EVM設計,直接應用於FL存在局限:FPVM通用性限制(如C.1.3所述的記憶體、算法、GPU瓶頸)使其不適合大模型和複雜聚合算法。本研究認識到這一差距,提出使用**PBFT共識替代通用fraud proof**,在原生ML環境驗證,實現對FL場景的深度適配。

---

### C.3 Summary: Efficiency vs. Computational Generality (0.3頁)

**段落28：Optimistic方法總結** 本節對樂觀驗證機制在聯邦學習中的應用進行了全面分析,核心發現可總結如下:

**樂觀執行的顯著效率優勢**: opML和Optimistic Rollup證明了樂觀假設在實踐中的有效性。正常情況下O(1)的通訊複雜度相較於PBFT的O(n²)實現了數量級的效率提升,Ethereum Rollup生態的成功運行(挑戰率<0.01%)進一步驗證了「大多數情況無惡意」這一假設的合理性。在聯邦學習場景中,若能成功應用樂觀機制,可實現顯著的性能突破,尤其是在大規模邊緣設備或跨機構聯邦學習系統中。

**計算通用性的根本限制**: 然而,當前opML方案面臨**FPVM計算約束**這一根本性瓶頸:
1. **記憶體上限**: 4GB限制無法支援主流大型模型(LLaMA-7B需14GB,超出3.5倍),更無法處理多客戶端同時聚合的場景
2. **算法分解困難**: 複雜聚合算法(FedProx、Krum等)的FPVM實現極其困難,證明生成時間可能從分鐘級暴增至小時級,甚至某些算法(如需要動態數據結構或複雜控制流的Byzantine-robust方法)幾乎不可行
3. **無GPU加速**: CPU環境執行導致30倍以上的性能劣化,挑戰驗證可能成為系統瓶頸,抵消樂觀執行的效率優勢

**FL需求與opML能力的衝突**: 生產環境FL常涉及大模型(醫療ViT-Large、金融BERT-large)、複雜聚合策略(FedProx、Krum等Byzantine-robust算法)和快速迭代需求(推薦系統每小時更新),這些需求與opML能力範圍存在顯著衝突,使其**僅適用於小模型(≤2B參數)和簡單算法(FedAvg等)**的受限場景。

**核心研究缺口**: 本節分析揭示了一個關鍵問題:**能否在保持樂觀執行效率的同時,使用更通用的仲裁機制,以消除FPVM的計算限制?** 這正是本研究的核心創新所在。

**本研究的突破性貢獻**: 我們提出用**PBFT共識替代Fraud Proof**作為挑戰仲裁機制,實現:(1)原生環境執行,無記憶體限制,支援任意模型規模(7B-175B+參數);(2)算法通用性,可直接運行任意聚合算法原始代碼;(3)GPU/TPU加速,避免FPVM的30倍性能劣化;(4)雙層安全,結合1-of-N檢測層與PBFT仲裁層。

**與相關工作的定位**: 如表C.4所示,本研究填補了現有方案在效率-安全-通用性三維空間中的空白:

| 方案 | 效率(正常) | 安全性 | 計算通用性 | 主要限制 |
|------|-----------|--------|-----------|----------|
| 傳統PBFT | 低(O(n²)) | 高(f<n/3) | 高(原生執行) | 不可擴展,n>100不可行 |
| opML | 高(O(1)) | 中(1-of-N) | 低(FPVM限制) | ≤2B參數,簡單算法 |
| zkML | 低(證明慢) | 極高(數學) | 極低(≤18M參數) | 算術化困難,不實用 |
| **本研究** | **高(O(1)正常)** | **高(1-of-N+PBFT)** | **高(原生執行)** | **適合生產FL** |

**表C.4: 樂觀/高效驗證方案對比**

**過渡到下一節**: 本節揭示了樂觀驗證在效率與計算通用性之間的困境。下一節將探討零知識證明方法,分析其如何通過密碼學技術提供數學級安全保證,以及為何這種方法面臨更嚴重的性能與規模限制。通過對比PBFT、Optimistic和ZK三種驗證範式,我們將在第F節總結現有方案的共同缺口,並明確本研究的創新定位。

---

**Section Status**: 🚧 In Progress
**Word Count**: ~5,200字
**Last Updated**: 2025-01-30
