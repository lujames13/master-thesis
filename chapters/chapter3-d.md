# Chapter 3: Related Work

## D. Zero-Knowledge Proof Approaches (1.5頁)

本節探討零知識證明(Zero-Knowledge Proof)技術在聯邦學習驗證中的應用。零知識證明方法提供了數學級別的完整性保證,允許證明者向驗證者證明計算正確性而無需透露計算過程本身。我們首先介紹零知識機器學習(zkML)的核心機制,包括zk-SNARK/zk-STARK等證明系統在ML中的應用及其算術化(Arithmetization)原理。隨後深入批判性分析zkML面臨的三大實用性障礙:模型規模限制(實際可行上限僅約18M參數)、算法限制(僅支援簡單算術運算)以及證明生成開銷(慢數個數量級)。最後總結零知識方法在數學級安全與實用性之間的根本性困境,並定位本研究在許可鏈場景下的選擇:通過PBFT提供足夠強的Byzantine容錯保證,同時保持對任意模型和算法的支援。

---

### D.1 zkML: Zero-Knowledge Machine Learning (1.2頁)

#### D.1.1 Core Mechanism (0.3頁)

零知識機器學習(zkML)將密碼學中的零知識證明技術應用於機器學習計算的驗證場景。其核心理念是:證明者(prover)可以向驗證者(verifier)證明「某個ML計算(如模型推理或聚合)被正確執行」,而無需透露計算的中間過程或輸入數據本身[ref]。這種特性使得zkML在隱私保護和信任最小化場景中具有獨特價值。

**零知識證明的基本原理**: 零知識證明系統需滿足三個性質:
1. **完整性(Completeness)**: 若陳述為真,誠實證明者總能說服誠實驗證者
2. **可靠性(Soundness)**: 若陳述為假,惡意證明者無法以顯著概率欺騙驗證者
3. **零知識性(Zero-Knowledge)**: 驗證者除了「陳述為真」這一事實外,無法獲得任何額外信息

**在ML中的應用——證明系統選擇**: 當前zkML研究主要採用兩類證明系統:
1. **zk-SNARK (Zero-Knowledge Succinct Non-interactive ARgument of Knowledge)**: 證明體積小(數百bytes至數KB),驗證快速(毫秒級),但需要可信設置(trusted setup)。代表性方案包括Groth16[ref]和PLONK[ref]。
2. **zk-STARK (Zero-Knowledge Scalable Transparent ARgument of Knowledge)**: 無需可信設置,具有後量子安全性,但證明體積較大(數十KB至數MB)。代表性方案為基於FRI協議的STARKs[ref]。

**算術化:ML計算到算術電路的轉換**: zkML的核心技術挑戰在於將神經網絡的前向傳播或聚合運算「算術化」為算術電路(arithmetic circuit)或R1CS約束系統(Rank-1 Constraint System)。具體而言,需要將高層的ML操作(矩陣乘法、激活函數、聚合算法)分解為基本的算術運算(加法、乘法)和有限域(finite field)上的約束。例如,ReLU激活函數 $y = max(0, x)$ 需要轉換為涉及比較操作的電路,而比較操作本身需要進一步分解為位運算和算術運算的組合。

**證明生成與驗證流程**:
1. **離線階段**:將ML模型和計算邏輯編譯為算術電路,生成證明密鑰(proving key)和驗證密鑰(verification key)
2. **證明生成**:證明者執行ML計算,同時為每個中間步驟生成見證(witness),並基於電路約束生成零知識證明
3. **證明驗證**:驗證者使用驗證密鑰和公開輸入/輸出,驗證證明的有效性,耗時通常在毫秒至秒級

**數學級安全保證**: zkML的最大優勢在於其安全性僅依賴密碼學假設(如離散對數困難性、多項式承諾的綁定性),不需要任何信任假設——即使所有參與者都是惡意的,只要密碼學假設成立,錯誤的計算結果就無法生成有效證明。這種「trustless」特性在無許可公鏈環境或極高安全要求場景(如金融審計、醫療合規)中具有獨特價值。

#### D.1.2 ⭐ Core Limitations: Arithmetization Constraints (0.9頁)

儘管zkML提供了理論上優雅的安全保證,但算術化過程的固有限制使其在實際聯邦學習場景中面臨嚴重的可行性障礙。

##### 批判點1: 模型規模限制 (0.3頁)

將神經網絡算術化為算術電路會導致電路規模的爆炸性增長,這對zkML系統的記憶體需求、證明生成時間和計算資源提出了極高要求:

**實際可驗證上限遠低於生產需求**: Kang等人在其綜述中明確指出,對於7B參數以上的大型模型,zkML方法「utterly impractical(完全不切實際)」[2]。實證研究顯示,當前zkML技術的實際可行上限約為18M參數[1][2],這與聯邦學習中主流模型的規模存在數量級差距:

| 研究 | 模型 | 參數量 | 證明生成時間 | 可行性評估 |
|------|------|--------|-------------|-----------|
| Bahrami等[8] | ResNet50 | 25M | 55分鐘 | 勉強可行 |
| Kang等[2] | 7B+ | >7B | - | "utterly impractical" |
| 實測上限[1][2] | - | ~18M | - | 實際可行上限 |

**表D.1: zkML模型規模限制與主流模型對比**

**電路規模爆炸的技術原因**: 對於包含P個參數的神經網絡,其算術化電路的約束數量通常為O(P×L),其中L為層數。以7B參數的LLaMA模型為例,假設32層Transformer結構,電路約束數量可達約10¹²個。證明生成的時間複雜度與約束數量超線性相關(通常為O(N log N)至O(N²),取決於證明系統),這意味著證明生成可能需要數小時甚至數天。

**記憶體需求的倍增效應**: 證明生成過程需要在記憶體中維護完整的見證向量(witness vector)和中間多項式(intermediate polynomials)。對於大型模型,見證向量的大小可能達到模型參數量的數倍(因為需要記錄每一層的激活值、梯度等中間結果)。Bahrami等人的ResNet50實驗顯示,證明生成需要約200GB記憶體[8],遠超一般計算環境的可用資源。

**聯邦學習場景的不適用性**: 在實際FL應用中,主流模型規模遠超zkML可處理範圍:
- **醫療影像分析**:ResNet-152(60M參數)、Vision Transformer ViT-Large(307M參數),甚至更大的ViT-Huge(632M參數)
- **自然語言處理**:BERT-large(340M參數)、GPT-3(175B參數)、LLaMA-7B(7B參數)
- **多模態學習**:CLIP(428M參數)、Flamingo(80B參數)

這些模型均遠超18M參數上限,使得zkML在真實FL場景中幾乎無法部署。即使是相對較小的BERT-Base(110M參數),也超出可行上限6倍,證明生成時間可能達到數小時,完全不符合生產環境的時效性要求。

##### 批判點2: 算法限制 (0.3頁)

算術化過程只能高效處理算術運算密集型的簡單算法,對於涉及複雜邏輯、條件分支或非算術運算的聚合算法,其電路深度和約束數量會指數級增長:

**可行算法:簡單加權平均**: 聯邦學習中最基礎的FedAvg算法僅涉及線性組合運算:
```python
# FedAvg: 純算術運算
w_global = Σ (n_i / n_total) * w_i  # ✅ 可算術化
```
這種計算可以直接映射為加法和乘法門(addition/multiplication gates),電路深度較小(O(log K),K為客戶端數),約束數量線性於參數量。Bahrami等人的ResNet50實驗驗證了FedAvg的可行性,儘管耗時55分鐘[8]。

**困難算法:帶優化的聚合**: 許多實際FL系統為提升收斂速度,採用帶正則化或自適應學習率的聚合算法。以FedProx為例:
```python
# FedProx: 帶正則化的聯邦優化
w_t+1 = argmin_w [F(w) + (μ/2)||w - w_t||²]  # ❌ 算術化困難
```
將這種優化問題算術化需要:
1. **迭代優化循環**:實現梯度下降或牛頓法的多輪迭代,每輪需要計算目標函數值、梯度、Hessian矩陣(對於二階方法),並更新參數。這種循環結構在算術電路中需要展開為固定深度的電路,若不知道迭代次數上界,則電路深度可能過大
2. **收斂判定邏輯**:判斷是否收斂(如梯度範數小於閾值)涉及比較操作,而比較操作需要分解為位級運算,大幅增加電路複雜度
3. **正則化項的非線性**:L2範數 $||w - w_t||²$ 涉及高維向量的內積和平方根運算,在有限域上實現需要複雜的逼近技術

實際上,尚無文獻報告成功對FedProx等自適應優化算法進行zkML驗證,這表明其實用性存疑。

**極困難算法:Byzantine-robust聚合**: 為防禦惡意客戶端投毒攻擊,許多FL系統採用Byzantine-robust聚合算法。以Krum算法為例:
```python
# Krum: 基於距離的異常檢測
for i in clients:
    score_i = Σ_{j in nearest_k} ||g_i - g_j||²  # 歐式距離計算
select argmin score_i  # ❌ 算術化極困難
```
算術化這種算法面臨的挑戰:
1. **排序操作**:找到每個梯度的k個最近鄰需要排序,而排序算法(如快速排序、歸併排序)涉及大量條件分支。在算術電路中實現排序需要使用排序網絡(sorting network),其深度為O(log² n),門數量為O(n log² n),對於數百個客戶端規模,電路複雜度極高
2. **動態選擇**:選擇最小score對應的梯度需要argmin操作,這同樣涉及比較和條件選擇,電路開銷巨大
3. **高維向量距離**:對於包含數百萬參數的模型,計算兩個梯度的歐式距離 $||g_i - g_j||²$ 需要數百萬次乘法和加法,電路規模隨參數量線性增長

類似的困難也存在於其他Byzantine-robust算法,如Median(需要排序)、Trimmed Mean(需要排序+裁剪)、Bulyan(結合Krum和Median)。這些算法在實際FL系統中廣泛使用,但zkML幾乎無法支援。

**算法通用性的根本缺失**: zkML的最大問題在於,每當聯邦學習領域提出新的聚合算法(如近期的FedAdam、FedYogi、Scaffold、FedNova等),都需要重新進行算術化設計、電路實現和性能優化,開發週期長達數月。相較之下,在原生Python/PyTorch環境實現新算法僅需數小時至數天,這種靈活性差距使得zkML難以跟上聯邦學習研究的快速發展。實際上,算法越複雜,算術化的電路深度和約束數量呈指數增長,證明生成時間也隨之指數增長,這從根本上限制了zkML的適用範圍。

##### 批判點3: 證明生成時間 (0.3頁)

即使對於可以算術化的簡單算法和小規模模型,zkML的證明生成時間也遠超原生計算,成為系統瓶頸:

**單次證明生成的性能差距**: 如表D.2所示,zkML證明生成相較於原生PyTorch環境的執行時間慢數個數量級:

| 任務 | 原生PyTorch | zkML證明生成 | 倍數差異 |
|------|------------|-------------|---------|
| MNIST推理(簡單CNN) | <1秒 | ~2分鐘 | 120x |
| ResNet50推理 | ~2秒 | ~55分鐘 | 1650x |
| 聚合1000客戶端(FedAvg) | ~5秒 | ~10分鐘 | 120x |

**表D.2: zkML證明生成時間與原生計算對比**

以ResNet50為例,Bahrami等人的實驗顯示單次推理的證明生成需要55分鐘[8],而在配備NVIDIA A100 GPU的環境中,原生PyTorch推理僅需約2秒,性能差距達1650倍。這種巨大的開銷源於證明生成過程的計算複雜度:需要執行快速傅立葉變換(FFT)計算多項式承諾、執行Fiat-Shamir轉換生成挑戰值、構造Merkle樹證明等密碼學操作,這些操作的計算量遠超原始ML計算本身。

**聯邦學習場景的累積開銷**: 在FL場景中,證明生成開銷會在多個維度累積:
1. **多輪訓練**:假設FL需要進行R=100輪訓練,若每輪聚合都需要生成zkML證明,則總證明生成時間為100×10分鐘=1000分鐘(約16小時)。相較之下,原生聚合總耗時僅100×5秒=500秒(約8分鐘),zkML開銷是原生計算的120倍
2. **多客戶端並行**:若K個客戶端同時提交本地模型,聚合器需要為每個客戶端的更新生成證明(或要求客戶端自行生成證明),證明生成時間進一步倍增
3. **挑戰驗證**:若採用類似opML的挑戰機制,每次挑戰都需要重新生成證明,在高挑戰率場景下(如對抗環境),證明生成可能成為系統的主要時間開銷,完全抵消任何效率優勢

**實際部署的不可接受性**: 對於需要快速迭代的FL應用(如推薦系統、廣告投放、實時風控),模型可能需要每小時甚至每分鐘更新一次。zkML的數十分鐘至數小時證明生成時間完全無法滿足這種時效性要求。即使在可以容忍較長延遲的應用(如醫療診斷模型訓練),zkML的開銷也會顯著增加訓練週期和計算成本,使其在成本效益上缺乏競爭力。

**硬體加速的局限性**: 雖然近期研究嘗試使用GPU加速zkML證明生成,但由於密碼學操作(如模運算、多項式求值)與ML計算(如矩陣乘法)的特性差異,GPU加速的效果有限。Ingonyama等公司的研究顯示,GPU加速可將證明生成時間降低約10-20倍[ref],但這仍意味著ResNet50的證明生成需要約3-5分鐘,相較於2秒的原生計算仍慢數個數量級。此外,GPU加速zkML證明生成需要專用硬體(如Ingonyama的FPGA加速卡),部署成本高昂,進一步限制了其實用性。

#### D.1.3 對比與定位 (0.3頁)

通過上述批判性分析,我們可以清晰地定位zkML與本研究在聯邦學習驗證場景中的適用範圍和取捨:

**zkML的獨特價值**: 零知識證明提供的數學級安全保證(trustless)在某些特定場景下具有不可替代的價值:
1. **無許可公鏈環境**:在完全開放的區塊鏈網絡中,無法假設任何參與者誠實,zkML的零信任特性使其成為唯一可行的驗證方案
2. **極高合規要求**:在金融審計、醫療數據合規等監管嚴格的領域,zkML可提供可驗證計算(verifiable computation)的數學證明,滿足法律要求
3. **隱私保護優先**:零知識性質允許在不暴露敏感數據的前提下證明計算正確性,這在某些隱私敏感場景(如跨國醫療數據共享)中至關重要

**zkML在FL場景的根本性障礙**: 然而,對於生產環境的聯邦學習應用,zkML面臨三大實用性障礙:

| 維度 | zkML限制 | FL生產需求 | 差距 |
|------|---------|----------|------|
| **模型規模** | ≤18M參數 | 7B-175B參數(LLM) | 差距>100倍 |
| | | 300M-600M參數(ViT) | 差距>15倍 |
| **算法支援** | 僅簡單算術(FedAvg) | FedProx、FedAdam(優化) | 不支援 |
| | | Krum、Median(Byzantine-robust) | 不支援 |
| **證明時間** | 數十分鐘-數小時 | 數秒-數分鐘(實時性要求) | 慢100-1000倍 |

**表D.3: zkML限制與FL生產需求對比**

**本研究的定位與選擇**: 本研究針對許可鏈/聯盟鏈場景下的聯邦學習,在這種環境中:
1. **基礎信任存在**:參與方通常為經過身份認證的企業或機構,具有長期聲譽考量,可以假設大多數參與者理性誠實
2. **實用性優先**:需要支援任意模型規模(7B-175B參數大模型)和任意聚合算法(包括未來提出的新算法),zkML的限制無法接受
3. **Byzantine容錯足夠**:PBFT提供的f<n/3容錯能力(即容忍最多1/3惡意節點)在許可鏈環境下已經足夠強,無需追求zkML的數學級零信任

**與zkML的互補關係**: 本研究並非否定zkML的價值,而是認識到兩者適用於不同的信任模型和應用場景:

| 維度 | zkML | 本研究(Opt-PBFT) |
|------|------|------------------|
| 驗證機制 | zk-SNARK/STARK | PBFT Consensus |
| 安全級別 | 數學級(無需信任) | Byzantine容錯(f<n/3) |
| 模型規模 | ≤18M參數 | 無限制(7B-175B+) |
| 算法支援 | 僅簡單算術 | 任意算法 |
| 證明時間 | 數十分鐘-數小時 | PBFT共識(數分鐘) |
| 計算環境 | 算術化(受限) | 原生環境(GPU加速) |
| 適用場景 | 無許可鏈+極高信任要求 | 許可鏈+生產環境通用FL |

**表D.4: zkML vs 本研究的詳細對比與定位**

**核心洞察**: zkML追求「數學級安全」,為此犧牲了「運算通用性」和「實用效率」。本研究的核心洞察是:**在許可鏈場景下,運算通用性比數學級安全更關鍵**。通過PBFT提供的Byzantine容錯保證(f<n/3)已經足夠強(可容忍最多33%惡意節點),同時在原生環境執行驗證,實現對任意模型和算法的支援,更符合生產環境FL系統的實際需求。

**技術選擇的合理性**: 本研究採用PBFT而非zkML作為仲裁機制,這一選擇基於以下理性考量:
1. **信任環境匹配**:許可鏈參與者經過身份認證,可以合理假設>2/3誠實,PBFT的信任假設在此環境下成立
2. **實用性優先**:相較於zkML的數學級安全但不實用,PBFT提供的Byzantine容錯在實踐中已被廣泛驗證(Castro & Liskov的PBFT協議自1999年提出以來,已在眾多分布式系統中成功部署)
3. **未來可擴展性**:原生環境執行使系統可以無縫支援未來的新模型架構(如Mixture-of-Experts、State Space Models)和新聚合算法,無需重新進行算術化設計

---

### D.2 Summary: Mathematical Security vs. Practicality (0.3頁)

本節對零知識證明方法在聯邦學習驗證中的應用進行了全面分析,核心發現可總結如下:

**數學級安全的理論吸引力**: zkML通過密碼學技術提供了trustless的驗證能力,其安全性僅依賴於數學假設(如離散對數困難性),不需要任何信任假設。這種特性在理論上極具吸引力,尤其是在無許可公鏈或極高合規要求的場景中,zkML可能是唯一可行的驗證方案。證明的簡潔性(數百bytes至數KB)和快速驗證(毫秒級)也使其在某些特定應用中展現出優勢。

**實用性的三大根本性障礙**: 然而,當前zkML技術面臨的三大限制使其在聯邦學習生產環境中幾乎不可部署:

1. **模型規模瓶頸**: 實際可驗證上限僅約18M參數,遠低於主流模型規模。7B參數的LLaMA模型被明確標記為「utterly impractical」,這意味著zkML無法支援現代大型語言模型、大型視覺模型或多模態模型的聚合驗證。即使是中型模型(如BERT-large的340M參數),也超出可行上限約20倍,證明生成可能需要數小時甚至數天。

2. **算法通用性受限**: 算術化過程只能高效處理簡單的加權平均算法(如FedAvg),對於帶優化的聚合(FedProx、FedAdam)或Byzantine-robust算法(Krum、Median)極其困難甚至不可行。這種限制使得zkML無法支援實際FL系統中廣泛使用的複雜聚合策略,也難以適應聯邦學習領域的快速發展——每當提出新算法,都需要重新進行算術化設計,開發週期長達數月。

3. **證明生成開銷**: 相較於原生PyTorch計算,zkML證明生成慢100-1650倍(ResNet50單次推理從2秒暴增至55分鐘)。在FL場景中,這種開銷會在多輪訓練、多客戶端聚合、挑戰驗證等維度累積,使證明生成成為系統瓶頸,完全抵消任何效率優勢。對於需要每小時甚至每分鐘更新模型的快速迭代應用,zkML的數十分鐘至數小時延遲完全不可接受。

**FL場景的核心需求與zkML能力的錯配**: 生產環境的聯邦學習系統需要:
- **大模型支援**: 醫療影像的ViT-Large(307M)、金融NLP的BERT-large(340M)、多模態的CLIP(428M)、大型LLM(7B-175B)
- **複雜算法靈活性**: 自適應優化(FedProx、FedAdam)、Byzantine-robust聚合(Krum、Median)、未來新算法的快速部署
- **實時性要求**: 推薦系統、廣告投放、實時風控等應用需要秒級至分鐘級響應

zkML在這三個維度上都與實際需求存在顯著差距,使其**僅適用於小模型(≤18M參數)和簡單算法(FedAvg)的受限場景**,難以在真實生產環境中大規模部署。

**核心研究缺口**: 本節分析揭示了一個根本性問題:**在聯邦學習場景中,運算通用性比數學級安全更關鍵**。對於大多數企業級FL應用,參與方為經過身份認證的機構,部署在許可鏈或聯盟鏈環境,可以合理假設大多數參與者誠實。在這種環境下,Byzantine容錯級別的安全保證(如PBFT的f<n/3)已經足夠強,無需追求zkML的零信任特性,而應優先保證對任意模型規模和聚合算法的支援。

**本研究的定位**: 認識到這一現實,本研究在許可鏈/聯盟鏈場景下,選擇通過**PBFT共識提供Byzantine容錯保證**(f<n/3,可容忍最多33%惡意節點),同時在原生環境執行驗證,實現對任意模型規模(7B-175B+參數)和任意聚合算法的支援。這種設計在安全性(Byzantine容錯)、效率(樂觀通過時O(1)複雜度)和通用性(原生環境無限制)之間實現了最佳平衡,更符合生產環境FL系統的實際需求。

**與zkML的互補而非競爭**: 本研究並非否定zkML的價值,而是認識到兩者適用於不同的信任模型和應用場景:
- **zkML的定位**: 無許可鏈環境、極高合規要求、隱私保護優先的場景,願意為數學級安全犧牲實用性
- **本研究的定位**: 許可鏈/聯盟鏈環境、生產環境通用FL應用,在保證足夠安全性的前提下優先考慮實用性和通用性

**過渡到下一節**: 本節揭示了零知識方法在數學級安全與實用性之間的根本性困境。前述章節已經分析了PBFT方案(B節)、Optimistic方案(C節)和零知識方案(D節)各自的優勢和局限。下一節將探討混合共識機制,分析現有方案如何嘗試平衡不同技術範式的優勢,以及為何這些混合方案仍採用靜態策略而缺乏動態威脅感知能力,從而引出本研究的核心創新:威脅感知的動態Optimistic-PBFT機制。

---

**Section Status**: 🚧 In Progress
**Word Count**: ~3,800字
**Last Updated**: 2025-01-30
