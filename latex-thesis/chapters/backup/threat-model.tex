\begin{ZhChapter}

\chapter{威脅模型 (Threat Model)}
\label{chap:threat-model}

本章定義本研究所針對的威脅模型，特別聚焦於區塊鏈聯邦學習系統中的「委員會佔領攻擊」(Committee Capture Attack)。如第三章文獻分析所示，現有研究主要關注資料層的惡意客戶端攻擊，而系統性地忽略了共識層的驗證者共謀問題。本章將詳細描述系統模型、攻擊者能力、攻擊向量，並重點定義「漸進式權益佔領攻擊」(Progressive Committee Capture Attack, PCCA)，為後續章節的防禦機制設計提供明確的安全目標。

\section{系統模型與假設}
\label{sec:system_model}

\subsection{網路模型}

本研究考慮一個去中心化的區塊鏈聯邦學習系統，採用 BlockDFL 架構，由以下三種核心角色構成：

\begin{enumerate}
    \item \textbf{Update Providers (UP)}：原為客戶端 (Clients)，集合記為 $\mathcal{U} = \{u_1, u_2, ..., u_N\}$。每個 Update Provider 持有本地私有資料集 $\mathcal{D}_i$，負責在本地進行模型訓練，將運算出的模型更新 (Model Updates) 提交給 Aggregator。
    
    \item \textbf{Aggregators (AG)}：集合記為 $\mathcal{A} = \{a_1, a_2, ..., a_K\}$。Aggregators 負責收集來自 UP 的模型更新，執行初步聚合 (如生成 Aggregated Gradient)，並將聚合結果打包成「提案 (Proposal)」提交給委員會。Aggregator 的選擇同樣基於權益 (Stake-based)，權益越高的節點越有機會被選為當輪的 Aggregator。
    
    \item \textbf{Verifier Committee (VC)}：集合記為 $\mathcal{V} = \{v_1, v_2, ..., v_M\}$。Verifiers 組成驗證委員會 (Committee)，負責驗證 Aggregator 提交的提案。委員會成員通過共識機制決定是否批准該提案，並將合法的全局模型記錄上鏈。
\end{enumerate}

系統在每個訓練輪次 $r$ 動態選擇 Aggregators 和 Verifiers，選擇概率均與其持有的權益成正比。

\subsection{聚合與共識流程}

在每個訓練輪次，系統執行以下流程：

\begin{enumerate}
    \item \textbf{本地訓練}：Update Providers 在本地資料上訓練模型，運算模型更新 $\Delta w_i$ 並發送給選定的 Aggregator。
    \item \textbf{初步聚合}：Aggregator 收集來自多個 UP 的更新，執行演算法 (如 FedAvg) 生成聚合更新 $\Delta w_{agg}$，並構建提案交易提交至區塊鏈。
    \item \textbf{委員會驗證}：委員會 $\mathcal{V}_r$ 下載 Aggregator 的提案，執行 Krum 驗證邏輯。
    \item \textbf{共識決策}：委員會成員通過 BFT 共識協議對提案進行投票。
    \item \textbf{獎勵分配 (Reward Linkage)}：
    若提案獲得委員會批准通過：
    \begin{itemize}
        \item 投贊成票的 \textbf{Verifiers} 獲得驗證獎勵。
        \item 提案的 \textbf{Aggregator} 獲得聚合獎勵。
        \item 被包含在該提案中的 \textbf{Update Providers} 獲得貢獻獎勵。
    \end{itemize}
    若提案被拒絕，則該鏈條上的所有角色 (包括 Aggregator 和 UP) 均無法獲得獎勵。這種「捆綁式獎勵 (Bundled Reward)」機制強化了角色間的利益關聯。
\end{enumerate}

\subsection{權益動態機制}

權益在系統中扮演雙重角色：

\begin{itemize}
    \item 選擇權重：權益決定驗證者與其被選入委員會的機率，權益越高，參與機會越多。
    \item 經濟激勵：參與委員會的驗證者獲得獎勵，進一步增加其權益，形成正反饋循環。
\end{itemize}

這種機制設計的初衷是激勵誠實行為：誠實驗證者通過持續參與獲得獎勵，權益不斷增長，從而鞏固其在系統中的影響力。然而，如本章後續所示，這種機制也可能被惡意驗證者利用，通過排他性的獎勵分配實現權益壟斷。

\subsection{系統假設}

本研究基於以下假設：

\begin{itemize}
    \item 網路假設：網路為部分同步模型，訊息最終會被傳遞，但傳遞延遲有上界。
    \item 密碼學假設：密碼學原語 (如數位簽章、雜湊函數) 是安全的，攻擊者無法偽造簽章或碰撞雜湊。
    \item 誠實客戶端存在：系統中至少存在一定比例的誠實客戶端，其提交的更新是基於真實資料的正常訓練結果。
    \item 可驗證性假設：聚合結果的正確性可以被驗證。任何節點都可以重新運算演算法，驗證委員會提交的結果是否正確。
\end{itemize}

\section{攻擊者模型}
\label{sec:adversary_model}

\subsection{攻擊者類型：理性攻擊者}

本研究考慮的攻擊者為理性攻擊者 (Rational Adversary)，而非傳統的拜占庭攻擊者。兩者的關鍵區別在於動機：

\begin{itemize}
    \item 拜占庭攻擊者：以破壞系統為目標，可能採取任意惡意行為，即使損害自身利益也在所不惜。
    \item 理性攻擊者：以利益最大化為目標，僅在預期收益大於成本時才發動攻擊。如果攻擊的預期收益為負，理性攻擊者不會嘗試作惡。
\end{itemize}

這種區分至關重要，因為它為基於博弈論的防禦機制提供了理論基礎。如果能夠設計激勵機制，使得攻擊的預期收益為負，理性攻擊者將自發地選擇誠實行為，無需依賴傳統的多數誠實假設。

\subsection{攻擊者目標}

理性攻擊者的主要目標包括：

\begin{itemize}
    \item 經濟利益：通過操縱委員會，獨佔訓練獎勵，排擠誠實節點的收益。
    \item 權益壟斷：通過阻止誠實節點的權益增長，逐步提高自身在系統中的權益佔比，最終控制委員會選擇過程。
    \item 網路控制：當攻擊者的權益佔比足夠高時，可以持續控制委員會，進而控制整個聯邦學習過程，包括模型更新的接受與拒絕。
\end{itemize}

值得注意的是，理性攻擊者的目標不僅僅是短期的經濟收益，更重要的是長期的網路控制權。這種攻擊不同於傳統的模型投毒攻擊，後者僅影響模型品質，而前者則從根本上顛覆了去中心化系統的安全假設。

\subsection{攻擊者能力}

本研究假設攻擊者具有以下能力：

\begin{itemize}
    \item 節點控制：攻擊者可以控制系統中一定比例的驗證者節點，記為 $f$。在典型場景下，假設 $f \leq 0.3$，即攻擊者控制不超過 30\% 的節點。
    \item 協同作惡：被攻擊者控制的節點可以相互協調，共同執行攻擊策略。例如，當多個惡意節點同時被選入委員會時，它們可以串通一致地投票。
    \item 策略性行為：攻擊者可以根據系統狀態動態調整策略。例如，在權益較低時表現誠實以積累信譽，在獲得委員會多數席位時發動攻擊。
    \item 觀察能力：攻擊者可以觀察區塊鏈上的所有公開資訊，包括其他節點的權益、歷史行為、委員會組成等，並據此制定攻擊策略。
\end{itemize}

\subsection{攻擊者限制}

同時，攻擊者受到以下限制：

\begin{itemize}
    \item 密碼學限制：攻擊者無法破解密碼學原語，無法偽造其他節點的簽名或篡改已上鏈的資料。
    \item 網路限制：攻擊者無法控制全網多數節點，無法單獨發動 51\% 攻擊。
    \item 經濟約束：攻擊者受經濟激勵約束，如果攻擊的預期成本大於收益，理性攻擊者不會嘗試攻擊。
    \item 可驗證性：攻擊者無法阻止其他節點驗證聚合結果的正確性。任何節點都可以重新運算演算法，檢測委員會是否正確執行協議。
\end{itemize}

\section{攻擊向量分析}
\label{sec:attack_vectors}

區塊鏈聯邦學習系統面臨多層次的安全威脅。本節分析不同層次的攻擊向量，並說明本研究的關注目點。

\subsection{資料層攻擊：已有防禦}

資料層攻擊主要指惡意客戶端通過投毒攻擊破壞模型品質：

\begin{itemize}
    \item 資料投毒 (Data Poisoning)：惡意客戶端在本地訓練時使用被污染的資料集，導致訓練出的模型更新偏離正常分佈。
    \item 模型投毒 (Model Poisoning)：惡意客戶端直接構造惡意的模型更新，而非基於真實訓練過程。
\end{itemize}

針對這類攻擊，現有研究已提出多種拜占庭強健演算法，如 Krum、Trimmed Mean、Median 等。這些演算法通過統計方法識別並過濾異常更新，在一定比例的惡意客戶端存在時仍能保證模型收斂。

然而，這些防禦方法存在一個關鍵假設：執行演算法的驗證者是誠實的。如果驗證者本身是惡意的，它們可以選擇不執行這些防禦演算法，或者篡改演算法的執行結果，從而使資料層的防禦完全失效。

\subsection{共識層攻擊：本研究重點}

共識層攻擊針對的是執行聚合和驗證的委員會本身：

\begin{itemize}
    \item 驗證者共謀 (Verifier Collusion)：多個惡意驗證者協同作惡，共同通過惡意的聚合結果。
    \item 委員會佔領 (Committee Capture)：攻擊者通過操縱委員會選擇機制，逐步增加惡意節點在委員會中的佔比，最終控制委員會。
\end{itemize}

如第三章文獻分析所示，現有區塊鏈聯邦學習研究存在系統性的「驗證層盲點」：約 93\% 的研究假設驗證者是誠實的或滿足誠實多數，僅有極少數研究 (如 KFC) 明確考慮惡意驗證者的場景。

此外，現有的 BlockDFL 類論文雖然引入了 Verifier 機制，但大多假設 Aggregator 和 Verifier 之間是獨立的，或者假設 Verifier 是誠實的。本研究指出了 Verifier 和 Aggregator 可以是同一利益集團 (Cartel) 的風險，即攻擊者可能同時控制委員會與聚合節點，這是對現有 BlockDFL 架構安全分析的重要補充。

本研究聚焦於共識層攻擊，特別是委員會佔領攻擊。這種攻擊的危險性在於：

\begin{itemize}
    \item 繞過資料層防禦：惡意委員會可以直接接受惡意更新，無需執行 Krum 等防禦演算法。
    \item 隱蔽性強：攻擊者在初期表現誠實，不易被檢測，等到權益足夠高時才發動攻擊。
    \item 自我強化：一旦攻擊成功，攻擊者的權益會進一步增加，形成正反饋，使得攻擊越來越容易。
\end{itemize}

\subsection{攻擊層次對比}

表 \ref{tab:attack_comparison} 對比了不同層次攻擊的特徵與現有防禦情況。

\begin{table*}[htbp]
\centering
\caption{攻擊層次對比}
\label{tab:attack_comparison}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
攻擊層次 & 攻擊者 & 攻擊目標 & 現有防禦 & 防禦假設 & 本研究關注 \\ \hline
資料層 & 惡意客戶端 & 模型品質 & Krum, Trimmed Mean & 驗證者誠實 & 否 \\ \hline
共識層 & 惡意驗證者 & 網路控制 & 誠實多數假設 & 多數驗證者誠實 & 是 \\ \hline
\end{tabular}
\end{table*}

從表中可以看出，資料層攻擊已有成熟的防禦方法，但這些方法依賴於驗證者誠實執行的假設。相比之下，共識層攻擊的防禦仍依賴於誠實多數假設，缺乏針對理性攻擊者的激勵相容機制。

\section{漸進式權益佔領攻擊 (Progressive Committee Capture Attack)}
\label{sec:pcca}

本節詳細定義本研究針對的核心威脅：漸進式權益佔領攻擊 (Progressive Committee Capture Attack, PCCA)。這是一種針對基於權益的委員會選擇機制的隱蔽性攻擊，通過兩階段策略逐步實現網路控制。

\subsection{攻擊定義}

漸進式權益佔領攻擊是指攻擊者通過以下策略，逐步增加其在系統中的權益佔比，最終控制委員會選擇過程：

\begin{enumerate}
    \item 潛伏階段：攻擊者在初期表現誠實，提交正常的模型更新，積累權益與信譽。
    \item 佔領階段：當攻擊者在委員會中獲得超過 2/3 席位時，啟動「戰略性餓死」策略，拒絕打包誠實節點的更新，獨佔獎勵。
    \item 權益壟斷：由於誠實節點無法獲得獎勵，其權益停滯；而惡意節點持續獲得獎勵，權益呈指數增長，進一步提高其在未來委員會中的佔比。
\end{enumerate}

\begin{algorithm}[t]
\caption{High-Level Strategy of Progressive Committee Capture Attack (PCCA)}
\label{alg:pcca_strategy}
\begin{algorithmic}[1]
\Require Current Committee $\mathcal{V}$, Adversary Controlled Nodes $\mathcal{C}_{adv}$
\Ensure Action for the current round
\State \textbf{Check Phase:} Calculate control ratio $r = \frac{|\mathcal{V} \cap \mathcal{C}_{adv}|}{|\mathcal{V}|}$
\If{$r \leq 2/3$} 
    \State \textit{// State 1: Shadow Mode (Lurking)}
    \State Follow the protocol honestly to accumulate stake and await majority.
\Else 
    \State \textit{// State 2: Capture Mode (Occupying)}
    \If{\textbf{Aggregator is Adversarial}}
        \State \textbf{Full Stack Poisoning}: Force approve malicious proposal.
    \Else
        \State \textbf{Strategic Starvation}: Force reject honest proposal.
    \EndIf
\EndIf
\end{algorithmic}
\end{algorithm}

這種攻擊的關鍵在於利用了權益機制的正反饋特性：權益高的節點更容易被選入委員會，獲得更多獎勵，進而權益更高。攻擊者通過操縱這一循環，實現權益的指數增長與網路控制權的轉移。

\subsection{攻擊階段詳述}

\subsubsection{階段一：潛伏階段 (Latent Phase)}

在潛伏階段，攻擊者的目標是積累初始權益並建立信譽，具體策略包括：

\begin{itemize}
    \item 誠實行為 (Honest Behavior)：攻擊者控制的節點無論是作為 UP、Aggregator 還是 Verifier，均嚴格遵守協議規則，提交高質量的模型更新與正確的驗證結果。
    \item 權益積累 (Stake Accumulation)：通過誠實參與，攻擊者節點獲得系統獎勵，權益逐漸增加。
    \item 等待時機 (Waiting)：攻擊者持續觀察委員會組成，等待多個惡意節點同時被選入委員會，形成超過 2/3 席位的時機。
\end{itemize}

潛伏階段的持續時間取決於攻擊者的初始權益佔比與委員會大小。假設攻擊者控制 $f = 0.3$ 的節點，委員會大小 $C = 7$，則攻擊者需要至少 5 個節點被選入委員會才能形成超過 2/3 的優勢。根據超幾何分佈，這種情況發生的機率為：

\begin{equation}
P(\text{超過 2/3}) = \sum_{k=\lfloor 2C/3 \rfloor + 1}^{\min(fM, C)} \frac{\binom{fM}{k} \binom{(1-f)M}{C-k}}{\binom{M}{C}}
\end{equation}

當 $f = 0.3, C = 7$ 時，這一機率約為 2.4\%，意味著攻擊者平均需要等待約 42 輪才能獲得一次攻擊機會。

\subsubsection{階段二：佔領階段 (Capture Phase)}

當攻擊者在系統中累積了足夠的權益並控制了委員會的超過 2/3 席位時，PCCA 進入佔領階段。不同於傳統攻擊單一的破壞模式，本研究根據攻擊者對系統組件 (Verifier 和 Aggregator) 的控制程度，定義了兩種層次的攻擊場景：戰略性餓死與全棧投毒。

\paragraph{A. 場景一：戰略性餓死 (Strategic Starvation via Committee Capture)}

在此場景中，攻擊者控制了 Verifier 委員會的超過 2/3 席位 ($|\mathcal{V}_{mal}| > \frac{2}{3} |\mathcal{V}_{committee}|$)，但當前輪次的 Aggregator 為誠實節點或未受攻擊者完全控制。

攻擊者的目標是最大化相對權益增益。基於 BlockDFL 的獎勵連鎖機制，只有當提案被委員會批准時，相關聯的 Aggregator 和 Update Providers 才能獲得獎勵。利用這一點，惡意委員會採取以下策略：

\begin{itemize}
    \item \textbf{拒絕誠實提案}：惡意委員會投票否決由誠實 Aggregator 提交的高質量聚合結果。這導致誠實 Aggregator 及其背後的誠實 Update Providers 無法獲得本輪獎勵，造成「零收益」懲罰。
    \item \textbf{批准次優更新}：如果存在一個包含較多惡意 Update Providers 的 Aggregator (即使其聚合結果為次優，Sub-optimal)，惡意委員會會優先批准該提案。
\end{itemize}

\textbf{後果分析}：這種攻擊雖然在短期內僅導致模型收斂速度減緩 (因為接受了次優而非最優更新)，但其主要破壞力在於經濟層面。誠實節點的權益因持續被「餓死」而停滯，而惡意節點的權益則持續增長，導致攻擊者的權益佔比 (Stake Ratio) 在下一輪選擇中進一步擴大，形成正反饋循環。

\paragraph{B. 場景二：全棧投毒 (Full Stack Poisoning)}

在此場景中，攻擊者同時實現了對共識層和聚合層的滲透，即同時控制了委員會超過 2/3 席位以及當選的 Aggregator。這是 PCCA 最危險的形態。

攻擊者的目標轉變為直接破壞模型性能。由於 Aggregator 和 Verifier 均被攻陷，現有的防禦機制 (如聚合層的 Krum 演算法或驗證層的準確率檢查) 將完全失效：

\begin{itemize}
    \item \textbf{惡意聚合}：惡意 Aggregator 接收來自惡意 Update Providers 的「標籤翻轉 (Label Flipping)」更新，或者直接構造被污染的全域模型更新。
    \item \textbf{強制共識}：儘管該更新包含明顯的錯誤或惡意特徵，惡意委員會成員仍會協同投出贊成票，強制達成共識並將毒化模型寫入區塊鏈。
\end{itemize}

\textbf{後果分析}：全棧投毒繞過了系統所有的檢測機制。由於惡意 Aggregator 和 Verifier 瓜分了系統獎勵，攻擊者不僅成功破壞了全域模型 (Global Model) 的準確率，還進一步鞏固了其權益優勢，使得系統難以通過正常的選舉機制自我修復。

\subsection{權益增長動態分析 (Stake Growth Dynamics Analysis)}

在沒有外部干預的情況下，PCCA 會導致惡意節點的權益呈指數增長。我們可以通過數學模型來量化這種權益壟斷的過程：

\begin{itemize}
    \item 初始階段：假設攻擊者初始權益佔比為 $f_0 = 0.3$。
    \item 首次攻擊：當攻擊者首次獲得委員會超過 2/3 席位時，獨佔獎勵 $R$，權益增加至 $S_{mal}(1) = S_{mal}(0) + R$。
    \item 循環攻擊：隨著權益增加，攻擊者獲得委員會超過 2/3 席位的機率提高，攻擊頻率增加。假設每 $k$ 輪成功攻擊一次，則經過 $t$ 輪後，惡意節點的平均權益為：
\end{itemize}

\begin{equation}
S_{mal}(t) = S_{mal}(0) + \frac{t}{k} \cdot R
\end{equation}

而誠實節點的權益保持 $S_{hon}(t) = S_{hon}(0)$，導致權益比例為：

\begin{equation}
\frac{S_{mal}(t)}{S_{hon}(t)} = \frac{S_{mal}(0) + \frac{t}{k} \cdot R}{S_{hon}(0)}
\end{equation}

隨著 $t$ 增加，這一比例趨向無窮，意味著攻擊者最終將完全控制系統。

\subsection{攻擊效果與影響}

PCCA 對系統造成多層次的破壞：

\begin{itemize}
    \item 模型品質下降：由於惡意委員會可能接受次優更新或排除部分誠實更新，模型收斂速度變慢，最終準確率下降。在極端情況下，如果惡意委員會完全拒絕誠實更新，模型將無法收斂。
    \item 網路控制權轉移：隨著惡意節點權益佔比的提高，它們在委員會中的佔比也持續上升。最終，攻擊者可以持續控制委員會，完全掌握聯邦學習過程。
    \item 去中心化假設崩潰：區塊鏈聯邦學習的核心價值在於去中心化，避免單點故障與中心化信任。然而，PCCA 通過權益壟斷，實質上將系統重新中心化至攻擊者手中，違背了去中心化的初衷。
    \item 經濟激勵扭曲：誠實節點發現無論如何努力，都無法獲得獎勵，可能選擇退出系統。這進一步降低了誠實節點的佔比，加速了系統的崩潰。
\end{itemize}

\subsection{與傳統攻擊的區別}

PCCA 與傳統的拜占庭攻擊或資料投毒攻擊有本質區別，如表 \ref{tab:comparison_traditional} 所示。

\begin{table*}[htbp]
\centering
\caption{與傳統攻擊的區別}
\label{tab:comparison_traditional}
\begin{tabular}{|l|l|l|}
\hline
特徵 & 傳統攻擊 & PCCA \\ \hline
攻擊目標 & 模型品質 & 網路控制權 \\ \hline
攻擊者動機 & 破壞 & 利益最大化 \\ \hline
攻擊策略 & 直接投毒 & 漸進式滲透 \\ \hline
隱蔽性 & 低 (立即可檢測) & 高 (初期表現誠實) \\ \hline
自我強化 & 無 & 有 (權益正反饋) \\ \hline
防禦方法 & 資料層防禦 & 需要激勵相容機制 \\ \hline
\end{tabular}
\end{table*}

傳統攻擊可以通過 Krum 等資料層防禦方法應對，但 PCCA 繞過了這些防禦，直接攻擊共識層。這種攻擊的隱蔽性與自我強化特性，使得傳統的誠實多數假設不再可靠。

\section{安全目標}
\label{sec:security_goals}

基於上述威脅模型，本研究的防禦機制需要達成以下安全目標：

\subsection{防止委員會被惡意節點控制}

核心目標：即使攻擊者在某一輪獲得委員會超過 2/3 席位，也無法持續控制委員會。

具體要求：
\begin{itemize}
    \item 攻擊者無法通過單次成功攻擊獲得長期優勢。
    \item 系統能夠檢測並懲罰惡意委員會的行為。
    \item 懲罰機制足以剝奪攻擊者的作惡能力，防止其再次獲得委員會超過 2/3 席位。
\end{itemize}

\subsection{確保誠實節點的權益公平增長}

核心目標：誠實節點通過正常參與系統，能夠持續獲得獎勵，權益穩定增長。

具體要求：
\begin{itemize}
    \item 惡意委員會無法阻止誠實節點獲得應得的獎勵。
    \item 即使在攻擊發生時，誠實節點仍有機制保障其權益不受損害。
    \item 長期來看，誠實節點的權益佔比應保持穩定或增長，而非下降。
\end{itemize}

\subsection{維持模型收斂性與準確性}

核心目標：在存在 PCCA 攻擊的情況下，系統仍能保證模型正常收斂，達到預期準確率。

具體要求：
\begin{itemize}
    \item 防禦機制能夠識別並拒絕次優更新。
    \item 即使部分輪次受到攻擊影響，整體訓練過程仍能收斂。
    \item 最終模型準確率與無攻擊場景相當。
\end{itemize}

\subsection{保持系統的去中心化特性}

核心目標：防禦機制本身不應引入新的中心化風險或信任假設。

具體要求：
\begin{itemize}
    \item 不依賴可信第三方或中心化仲裁者。
    \item 不依賴誠實多數假設，而是基於激勵相容的博弈論機制。
    \item 任何節點都能參與驗證與挑戰，無需特殊權限。
\end{itemize}

\subsection{激勵相容性}

核心目標：使得理性攻擊者的最優策略是誠實行為，而非發動攻擊。

具體要求：
\begin{itemize}
    \item 攻擊的預期收益必須為負，即 $E[\text{Payoff}] = P_{success} \cdot G_{attack} - P_{caught} \cdot L_{slash} < 0$。
    \item 懲罰機制 $L_{slash}$ 必須遠大於潛在收益 $G_{attack}$，使得即使攻擊成功機率較高，預期收益仍為負。
    \item 獎勵機制應激勵誠實行為，使得誠實節點的長期收益高於攻擊者。
\end{itemize}

\section{本章小結}
\label{sec:threat_summary}

本章定義了本研究針對的威脅模型，重點聚焦於區塊鏈聯邦學習系統中的「漸進式權益佔領攻擊」(PCCA)。與傳統的資料層攻擊不同，PCCA 針對的是共識層的驗證者，通過兩階段策略 (潛伏$\rightarrow$佔領) 逐步實現網路控制權的轉移。

PCCA 的核心機制包括：
\begin{itemize}
    \item 次優更新：惡意委員會提交次優聚合結果，隱蔽性強。
    \item 戰略性餓死：通過排他性獎勵分配，阻止誠實節點權益增長。
    \item 權益指數增長：利用權益機制的正反饋特性，實現權益壟斷。
\end{itemize}

這種攻擊的危險性在於其隱蔽性、自我強化性，以及對去中心化假設的根本性顛覆。現有的資料層防禦方法 (如 Krum) 無法應對這種攻擊，因為它們依賴於驗證者誠實執行的假設。

基於這一威脅模型，本研究提出了五個安全目標：防止委員會控制、確保權益公平增長、維持模型收斂、保持去中心化特性，以及實現激勵相容性。下一章將介紹本研究提出的防禦機制，展示如何通過激勵相容的挑戰與罰沒機制，在不依賴誠實多數假設的前提下，有效防禦 PCCA 攻擊。

\end{ZhChapter}
