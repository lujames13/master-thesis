\section{現有驗證方法與其局限}
\label{sec:verification-limitations}

區塊鏈聯邦學習系統的安全性最終取決於其驗證機制能否有效識別並排除惡意的聚合結果。現有驗證方法可依據其技術路徑分為三大類：基於密碼學證明的方法追求數學上可證明的正確性、基於樂觀執行的方法透過經濟激勵達成安全保證、基於委員會共識的方法則依賴誠實多數假設。本節將系統性地分析這三類方法的技術原理與固有局限，揭示它們在面對區塊鏈聯邦學習特定需求時的不足之處。

\subsection{密碼學驗證方法的計算瓶頸}
\label{sec:zkml-limitations}

零知識機器學習（Zero-Knowledge Machine Learning, zkML）代表了密碼學驗證方法在機器學習領域的前沿探索 \cite{chen2024zkml}。其核心理念是將機器學習計算轉換為算術電路，並生成零知識證明，使驗證者無需重新執行計算即可確認結果的正確性。這種方法在理論上提供了最強的安全保證：證明的正確性完全依賴密碼學假設，無需信任任何參與方。若能將 zkML 應用於聯邦學習的聚合驗證，系統將能在不揭露個別更新內容的前提下，證明聚合結果確實是由指定的本地更新按照預定規則計算而得。

然而，zkML 面臨嚴峻的計算效能挑戰，這使其在當前技術條件下難以應用於實際的聯邦學習系統。將神經網路運算轉換為算術電路的過程會產生大量的多項式約束，約束數量隨模型複雜度急劇膨脹。根據現有基準測試，即使是相對簡單的 LeNet 模型，其約束數量也可達數億級別；對於 ResNet-18 等級的模型，證明生成時間需要近一分鐘；而對於 VGG16 或更大規模的模型，證明生成可能耗時數十分鐘甚至數小時，且需要數百 GB 乃至 TB 級別的記憶體 \cite{chen2024zkml}。考慮到聯邦學習通常需要數百至數千輪迭代，每輪都執行如此耗時的證明生成顯然不切實際。

更關鍵的局限在於 zkML 難以支援拜占庭容錯聚合演算法。Krum \cite{blanchard2017machine} 與 Multi-Krum 等防禦性聚合方法需要計算所有客戶端更新之間的成對距離，這在零知識電路中會產生 $O(n^2 \cdot d)$ 的約束爆炸，其中 $n$ 為客戶端數量，$d$ 為模型參數維度。排序與中位數運算在算術電路中同樣極度昂貴。現有的 zkFL 方案如 RiseFL \cite{zhu2024risefl} 僅能支援 L2-norm 有效性檢查等簡單驗證，而無法實現完整的拜占庭容錯聚合驗證。這意味著即使克服了效能瓶頸，zkML 仍無法為採用 Krum 等防禦機制的系統（如 BlockDFL）提供聚合正確性的密碼學證明。

\subsection{樂觀執行方法的架構限制}
\label{sec:opml-limitations}

樂觀機器學習（Optimistic Machine Learning, opML）採用與 zkML 截然不同的設計哲學：預設所有計算結果都是正確的，僅在有參與者提出質疑時才啟動驗證程序 \cite{conway2024opml}。這種「樂觀執行」的模式大幅降低了正常情況下的計算成本，因為絕大多數時候驗證程序不會被觸發。當爭議發生時，系統透過互動式的二分協議（Bisection Protocol）逐步縮小爭議範圍，最終定位至單一計算步驟，由鏈上的欺詐證明虛擬機（Fraud Proof Virtual Machine, FPVM）進行仲裁。ORA Protocol 已展示此方法可支援 LLaMA 2 等數十億參數規模的模型在以太坊上運行 \cite{ora2024opml}。

然而，opML 的架構設計與聯邦學習的需求存在根本性的衝突。首先是挑戰期的問題。為確保驗證者有充足時間偵測並提交欺詐證明，主流的樂觀執行系統如 Optimism 與 Arbitrum 採用長達一週的挑戰期 \cite{optimism2024rollup}。這種設計對於區塊鏈交易的最終確認或許可以接受，但對於需要快速迭代的聯邦學習訓練而言完全不可行——若每輪聚合都需等待一週才能確認，數百輪的訓練將耗時數年。即使大幅縮短挑戰期，仍會顯著拖慢訓練進度，且可能因驗證者反應時間不足而削弱安全保證。

其次，opML 的信任模型與 BCFL 的多驗證者場景存在落差。opML 建立在「AnyTrust」假設之上：只要存在至少一個誠實的驗證者願意監控並挑戰錯誤結果，系統就是安全的。這本質上是一個兩方爭議模型——單一提交者與單一挑戰者之間的對抗。然而，BCFL 的委員會共識涉及多個驗證者對多個提案的集體決策，這種多方參與的結構難以直接套用 opML 的爭議解決框架。此外，opML 的設計假設計算輸入（如模型更新）是公開可見的，以便驗證者能夠重新執行計算並發現錯誤。這與聯邦學習對更新隱私的保護需求存在張力。

\subsection{委員會驗證方法的安全假設}
\label{sec:committee-verification}

相較於密碼學方法與樂觀執行方法，基於委員會共識的驗證方法在效率與實用性之間取得了較佳的平衡，因而成為當前 BCFL 系統的主流選擇。這類方法的核心思想是由一個小型委員會代替全網執行驗證與共識，透過拜占庭容錯協議確保只要委員會中的誠實成員佔據多數，驗證結果就是可信的。前文介紹的 BlockDFL 即屬此類，其他代表性系統包括 FLCoin \cite{ren2024scalable} 與 BFLC \cite{li2021blockchain}。

FLCoin 提出基於滑動視窗的動態委員會機制，將聯邦學習的貢獻歷史作為委員會成員資格的依據。節點透過提交有效的模型更新獲得「份額」，在固定大小的滑動視窗內持有份額的節點組成當輪委員會。這種設計使委員會組成與 FL 目標直接對齊，且透過視窗的滑動實現成員的動態更替。FLCoin 的安全性分析顯示，在全網惡意節點比例不超過 25\% 且視窗大小為 100 的條件下，委員會安全的機率可達 98.4\% \cite{ren2024scalable}。然而，論文並未深入分析惡意節點透過策略性參與逐步累積份額的可能性，其實驗也假設無惡意節點參與，未驗證對抗性累積策略的防禦效果。

BFLC 開創性地將委員會共識引入 BCFL，採用聲譽機制決定委員會組成 \cite{li2021blockchain}。系統追蹤各節點提交更新的品質歷史，高聲譽者優先被選入委員會。委員會成員使用 K-fold 交叉驗證評估提交的模型更新，透過共識決定是否接受。這種設計能有效過濾曾有不良記錄的節點，但也面臨冷啟動問題：新加入者缺乏歷史記錄，難以建立初始信任。更重要的是，後續研究明確指出 BFLC「容易被惡意節點混入委員會，從而導致系統偏差」\cite{qin2024blockdfl}，當惡意節點佔據委員會半數席位時即可發動攻擊。

綜觀這些委員會驗證方法，它們共享一個根本性的安全假設：委員會的誠實多數。無論採用何種選舉機制——隨機抽樣、權益加權、聲譽評分或貢獻歷史——所有方案都假設某種形式的誠實多數能夠在委員會層級得到維持。這一假設在面對靜態的、比例固定的惡意節點時或許成立，但當攻擊者採取動態的、策略性的行為時，其有效性便值得商榷。下一小節將進一步分析這種靜態假設的盲區。

\subsection{系統性局限：靜態分析的盲區}
\label{sec:static-analysis-blindspot}

回顧上述三類驗證方法，可以發現一個貫穿其中的系統性局限：現有的安全性分析幾乎都建立在「攻擊者資源固定」的靜態假設之上。zkML 的安全性證明假設攻擊者的計算能力無法突破密碼學難題；opML 假設至少存在一個持續監控的誠實驗證者；委員會方法則假設惡意節點在全網中的比例 $\alpha$ 是一個固定的常數，並據此計算委員會被攻破的機率。這種「快照式」的分析視角忽略了一個關鍵的動態因素：理性的攻擊者會根據系統狀態調整其策略，而非機械地執行固定行為。

以委員會方法為例，第 \ref{sec:committee-size-security} 節的超幾何分佈分析假設每輪選舉都是從固定的惡意節點比例中獨立抽樣。然而，若系統的獎勵機制存在正反饋特性——如 BlockDFL 中，獲得獎勵的節點累積更多權益，從而提高未來被選中的機率——則各輪選舉之間並非獨立。攻擊者可利用此特性採取「耐心策略」：在初期表現完全誠實以累積權益與聲譽，僅在其控制的節點佔據委員會優勢時才發動攻擊。這種行為模式無法被靜態的機率分析所捕捉。

更根本的問題在於，現有分析未區分「惡意節點的存在比例」與「惡意節點的有效影響力」。在權益加權的選舉機制中，一個持有 10\% 權益的惡意節點，其對委員會組成的影響力可能遠大於十個各持有 1\% 權益的惡意節點。若攻擊者能夠透過合法途徑（累積獎勵、建立聲譽）集中權益於少數節點，即使其控制的節點數量佔全網比例不高，仍可能在委員會層級取得超額的影響力。FLCoin 的分析雖然考慮了惡意節點比例與委員會安全機率的關係，但未分析惡意節點比例本身可能隨時間演變的動態過程。BlockDFL 假設「持有大量權益的參與者傾向誠實」，但未充分論證此假設在面對長期潛伏的策略性攻擊者時是否仍然成立。

表 \ref{tab:verification-comparison} 總結了三類驗證方法在安全性、效率與通用性三個維度上的特性。可以看出，沒有任何一種方法能夠同時滿足所有需求：zkML 提供最強的安全保證但效率過低且無法支援複雜聚合；opML 效率較高但挑戰期過長且架構不適用於多驗證者場景；委員會方法在效率與實用性上表現最佳，但其安全性依賴可能被違反的誠實多數假設。這種「安全性-效率-通用性」的三難困境，構成了本領域研究的核心挑戰。

\begin{table}[htbp]
\centering
\caption{BCFL 驗證方法比較}
\label{tab:verification-comparison}
\begin{tabular}{|l|p{3.5cm}|p{3cm}|p{3cm}|}
\hline
\textbf{方法類別} & \textbf{安全性基礎} & \textbf{主要效率瓶頸} & \textbf{對 BCFL 的適用性} \\ \hline
zkML & 密碼學證明，無需信任假設 & 證明生成耗時數分鐘至數小時 & 低：無法支援 Krum 等複雜聚合 \\ \hline
opML & 經濟激勵與 AnyTrust 假設 & 挑戰期長達數天 & 低：架構不適用於多驗證者場景 \\ \hline
委員會共識 & 委員會誠實多數假設 & 共識通訊成本 $O(c^2)$ & 高：主流選擇，但假設可能被違反 \\ \hline
\end{tabular}
\end{table}

\section{研究缺口：從激勵設計到安全隱患}
\label{sec:research-gap}

前述分析揭示了現有 BCFL 驗證方法的共同盲區：靜態的安全性假設無法應對動態的攻擊策略。本節將聚焦於委員會驗證方法——當前最具實用性的選擇——深入探討其獎勵機制如何在激勵誠實行為的同時，也為策略性攻擊者創造了可利用的漏洞。這一分析將指向本研究欲填補的關鍵缺口，並為第三章的威脅模型建構奠定基礎。

\subsection{獎勵機制的正反饋特性}
\label{sec:reward-feedback}

第 \ref{sec:blockdfl-baseline} 節詳細介紹了 BlockDFL 的獎勵機制：當某一提案通過委員會共識時，提交該提案的聚合者、更新被納入的更新提供者、以及投贊成票的驗證者共同分享權益獎勵。這種設計的初衷是解決搭便車問題，確保只有實質貢獻者才能獲得回報。然而，從系統動態的角度審視，此機制創造了一個具有正反饋特性的循環結構。

正反饋的運作邏輯可描述如下：節點獲得權益獎勵後，其總權益增加；由於角色選舉採用權益加權機制，權益增加直接提升該節點在未來輪次被選為聚合者或驗證者的機率；作為聚合者或驗證者，節點更有機會參與被接受的提案，從而獲得更多獎勵。這種「獎勵 → 權益增加 → 選中機率提升 → 更多獎勵」的循環，在數學上構成一個正反饋系統。BlockDFL 的設計者預期此特性將使誠實參與者逐漸累積優勢，因為他們持續提交高品質更新並誠實驗證，從而獲得穩定的獎勵流入。相對地，惡意參與者若因提交低品質更新或投票與最終結果不一致而錯失獎勵，其相對權益份額將逐漸稀釋。

然而，這一預期建立在一個隱含假設之上：系統能夠有效區分誠實行為與惡意行為，並據此差異化地分配獎勵。問題在於，當惡意節點選擇「偽裝誠實」——在攻擊發動前完全模仿誠實節點的行為——系統便無法將其與真正的誠實節點區分開來。在這種情況下，惡意節點同樣能夠獲得獎勵、累積權益、提升影響力，正反饋機制反而成為攻擊者滲透系統的工具。

\subsection{策略性攻擊者的潛在威脅}
\label{sec:strategic-attacker}

基於上述分析，可以設想一種策略性的攻擊模式：攻擊者控制的節點在初期階段完全表現為誠實參與者，正常參與訓練、提交高品質更新、在驗證時投票支持真正優質的提案。透過這種「潛伏」行為，攻擊節點逐步累積權益與聲譽，提高其被選為聚合者或驗證者的機率。當攻擊者評估其控制的節點已在委員會中佔據足夠優勢時——例如，在某一輪選舉中恰好佔據超過三分之一的驗證者席位——才發動實際攻擊。

這種攻擊模式的危險性在於其隱蔽性與自我強化性。在潛伏階段，攻擊節點的行為與誠實節點完全一致，現有的異常偵測機制無從識別。更重要的是，一旦攻擊者在某一輪成功控制委員會，他們可以操控共識結果，將獎勵僅分配給自己控制的節點（透過接受包含攻擊節點更新的提案、拒絕僅包含誠實節點更新的提案），同時確保攻擊節點作為「投贊成票的驗證者」獲得驗證獎勵。這種操控使攻擊者的權益份額在成功攻擊後加速增長，進一步提高其在未來輪次控制委員會的機率，形成惡性循環。

現有文獻已零星地意識到委員會滲透的風險。FedBlock 在其未來展望中指出：「目前版本中，智能合約以隨機方式選取客戶端作為驗證者，但此選擇標準可能並非最佳」，並警告「驗證者本身亦可能是惡意的」\cite{nguyen2024fedblock}。BFLC 的後續評論指出該系統「容易被惡意節點混入委員會」\cite{qin2024blockdfl}。然而，這些觀察多停留在定性描述的層次，尚未發展出系統性的威脅模型來形式化分析此類攻擊的具體機制、成功條件與潛在危害。特別是，現有研究未充分探討獎勵機制的正反饋特性如何與委員會選舉機制交互作用，使得攻擊者能夠透過「合法」途徑逐步擴大影響力。

\subsection{本研究的切入點}
\label{sec:research-contribution}

綜合本章的分析，可以明確界定當前 BCFL 委員會安全性研究的核心缺口：

第一，\textbf{缺乏針對策略性攻擊者的形式化威脅模型}。現有安全性分析假設惡意節點比例固定且行為模式單一，未考慮攻擊者可能採取的動態策略，如長期潛伏、選擇性攻擊時機、以及利用正反饋機制累積優勢。

第二，\textbf{缺乏對獎勵機制安全性意涵的深入分析}。現有研究將獎勵機制視為激勵誠實行為的工具，但未系統性地審視其正反饋特性可能被攻擊者利用的風險。

第三，\textbf{缺乏能夠偵測與抵禦漸進式滲透的防禦機制}。現有委員會選舉機制——無論是隨機選擇、權益加權或聲譽導向——都未針對「透過合法途徑累積影響力」的攻擊模式設計相應的防護措施。

針對上述缺口，本研究將在後續章節展開以下工作。第三章將形式化定義「漸進式委員會佔領攻擊」（Progressive Committee Capture Attack, PCCA）的威脅模型，基於第 \ref{sec:blockdfl-baseline} 節建立的 BlockDFL 系統模型，分析攻擊者如何利用獎勵機制的正反饋特性逐步滲透委員會，並量化攻擊在不同參數設定下的成功機率與所需時間。第四章將提出針對 PCCA 的防禦架構設計，透過打破正反饋循環與引入動態挑戰機制，在維持系統效率的前提下提升對策略性攻擊者的抵抗能力。第五章將透過實驗評估所提出方法的有效性，驗證其在多種攻擊場景下的防護效能。