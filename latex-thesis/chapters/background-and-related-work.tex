\chapter{背景知識與相關研究}
\label{chap:background-related}

本章旨在建立理解本研究所需之技術基礎，並對現有區塊鏈聯邦學習（BCFL）的驗證機制進行系統性回顧與批判性分析。首先介紹聯邦學習的基本原理及其面臨的拜占庭威脅，接著探討區塊鏈技術如何重塑聯邦學習的信任模型。在相關研究部分，本章將深入剖析當前主流的密碼學驗證（zkML）、樂觀驗證（opML）與委員會共識機制，運用具體數據論證現有方案在安全性、效率與通用性上的結構性權衡。最後，本章定義了本研究所採用的基準系統模型，為後續的威脅建模與防禦設計奠定基礎。

\section{聯邦式學習與拜占庭威脅 (Federated Learning and Byzantine Threats)}
\label{sec:fl_background}

聯邦學習（Federated Learning, FL）是由 McMahan 等人於 2017 年正式提出之分散式機器學習框架 \cite{mcmahan2017communication}。其核心目標在於多個參與方（Clients）協同訓練模型，而無需將原始資料集中於中央伺服器，從而解決資料隱私與孤島問題。

\subsection{聯邦式學習基礎 (Fundamentals of Federated Learning)}
在標準聯邦學習架構中，目標是最小化全域損失函數 $F(w)$：
\begin{equation}
    \min_{w} F(w) = \sum_{k=1}^{K} \frac{n_k}{n} F_k(w)
\end{equation}
其中 $K$ 為參與客戶端總數，$n_k$ 為第 $k$ 個客戶端之本地樣本數，$F_k(w)$ 為其本地損失函數。

經典的 \textit{FederatedAveraging} (FedAvg) 演算法透過週期性地收集客戶端模型更新 $w_{t+1}^k$，並在伺服器端進行加權聚合：
\begin{equation}
    w_{t+1} \leftarrow \sum_{k=1}^{K} \frac{n_k}{n} w_{t+1}^k
\end{equation}
此方法相較於同步隨機梯度下降（SGD）可顯著減少通訊開銷，但其安全性建立在中央聚合器完全誠實且客戶端皆非惡意的假設之上。

\subsection{拜占庭攻擊模型 (Byzantine Attack Models)}
在分散式環境中，系統必須面對拜占庭故障（Byzantine Fault）。根據 Blanchard 等人的定義，拜占庭節點可發送任意、潛在惡意的更新，並可能與其他惡意節點共謀。聯邦學習中的攻擊主要分為兩類：

\begin{enumerate}
    \item \textbf{資料投毒 (Data Poisoning)}：攻擊者汙染本地訓練資料（如標籤翻轉），導致模型學習錯誤的特徵。
    \item \textbf{模型投毒 (Model Poisoning)}：攻擊者直接操控上傳的梯度或模型參數。研究顯示，模型投毒比資料投毒更具威脅性。例如，Bagdasaryan 等人提出的模型替換攻擊（Model Replacement Attack） \cite{bagdasaryan2020how} 可在單一輪次內植入後門，並保持主任務的高準確率。
\end{enumerate}

\subsection{傳統拜占庭容錯聚合 (Traditional Byzantine-Robust Aggregation)}
為抵禦拜占庭攻擊，學界提出多種強健聚合演算法（Robust Aggregation Rules）：

\begin{itemize}
    \item \textbf{Krum 及其變體} \cite{blanchard2017machine}：基於幾何距離選擇最接近多數節點的更新。Krum 選擇一個更新 $u^*$，使得其與最近 $n-f-2$ 個鄰居的歐式距離平方和最小。
    \item \textbf{裁剪均值 (Trimmed Mean)} \cite{yin2018byzantine}：在每個維度上移除最大與最小的 $\beta$ 比例數值後取平均，能有效抵禦統計極端值。
    \item \textbf{座標中位數 (Coordinate-wise Median)} \cite{yin2018byzantine}：取每個維度的中位數，具有高崩潰點（Breakdown Point）。
\end{itemize}

然而，這些防禦機制存在一個關鍵的局限性：\textbf{誠實聚合者假設}。如果不誠實的聚合器（Server）控制了聚合過程，它可以故意忽略防禦規則，甚至與惡意客戶端共謀。這構成了傳統聯邦學習的單點信任危機。

\section{區塊鏈聯邦式學習 (Blockchain-based Federated Learning, BCFL)}
\label{sec:bcfl_background}

區塊鏈聯邦式學習（BCFL）透過將分散式帳本技術（Distributed Ledger Technology, DLT）引入聯邦學習架構，從根本上重塑了多方協作訓練的信任模型。

\subsection{技術動機：從中心化信任到去中心化共識}

\subsubsection{傳統聯邦學習的信任集中化困境}
儘管聯邦學習承諾「數據不出本地」，其標準架構仍高度依賴單一中央聚合器（Central Aggregator），這種中心化設計引入了三類關鍵的信任風險。首先是\textbf{聚合器的誠實性風險}：由於缺乏外部監督，中央伺服器可能執行選擇性聚合，故意排除特定客戶端的更新以操縱模型表現，甚至如同 Geiping 等人 \cite{geiping2020inverting} 指出，惡意伺服器可對梯度執行反演攻擊（Gradient Inversion Attack），從更新中重建原始訓練影像。其次是\textbf{單點故障（Single Point of Failure, SPOF）}：中央伺服器的可用性直接決定了整個系統的穩定性。最後是\textbf{拜占庭容錯能力的缺乏}：在惡意客戶端佔比超過 50\% 或中央伺服器本身遭入侵的情況下，傳統的穩健聚合演算法將失效。

\subsubsection{區塊鏈技術的解決方案}
區塊鏈技術的引入為上述問題提供了結構性的解方。\textbf{不可篡改性（Immutability）}確保了所有模型更新與聚合結果一旦上鏈便無法被回溯修改，為系統提供了可信任的審計軌跡。\textbf{智能合約的透明性（Transparency）}將聚合規則與客戶端選擇邏輯代碼化，使得所有參與者皆能驗證聚合過程的正確性。\textbf{去中心化架構（Decentralization）}則通過點對點網路（P2P）取代了中央節點，利用共識機制（Consensus Mechanism）確保在部分節點失效或作惡的情況下，系統仍能維持運作並達成資料一致性。

\subsection{BCFL 架構的演進概況}
BCFL 的發展歷程反映了學界在去中心化程度、通訊效率與安全性三者之間的權衡。早期的研究如 BlockFL \cite{kim2020blockchained} 採用工作量證明（PoW）與全節點驗證，雖實現了極致的去中心化但帶來了難以承受的計算負擔與延遲。隨後，為了克服擴展性瓶頸，基於委員會（Committee-based）的架構逐漸成為主流，如 BFLC \cite{li2021blockchain} 與 BlockDFL \cite{qin2024blockdfl}，透過選舉小型驗證委員會來降低通訊複雜度，這也是本研究主要的探討對象。

\subsection{智能合約的功能職責}
在 BCFL 系統中，智能合約扮演著自動化管理者的角色，其功能通常劃分為四個核心模組：\textbf{註冊模組}維護參與者身分與權益；\textbf{聚合模組}協調訓練輪次與參數收集；\textbf{驗證模組}執行校驗邏輯（如準確率測試）以過濾惡意更新；\textbf{獎勵模組}則依據貢獻度自動分配代幣激勵，並對被偵測到的惡意行為執行罰沒（Slashing）。

\section[拜占庭容錯機制]{拜占庭容錯機制 (Byzantine Fault Tolerance Mechanisms)}
\label{sec:bft_background}

分散式系統在面對節點故障時，必須具備持續運作的能力。當故障涉及節點發送矛盾訊息或與其他惡意節點共謀時，系統便需要更強韌的拜占庭容錯機制。

\subsection{拜占庭將軍問題與容錯閾值}
拜占庭將軍問題由 Lamport 等人 \cite{lamport1982byzantine} 提出，定義了在存在叛徒的情況下如何達成一致性。Lamport 證明了在僅使用口頭訊息的情況下，系統若要達成拜占庭容錯，總節點數 $n$ 與惡意節點數 $f$ 必須滿足 $n \geq 3f + 1$。此理論極限確立了 PBFT 等共識協議的安全性邊界。

\subsection{實用拜占庭容錯協議 (PBFT)}
Castro 與 Liskov 於 1999 年提出的 PBFT 協議 \cite{castro1999practical} 首次將 BFT 共識的通訊複雜度從指數級降至多項式級別 $O(n^2)$。協議透過 Pre-prepare、Prepare 與 Commit 三個階段達成共識。當節點收集到 $2f+1$ 個匹配的 Commit 訊息時，即確認達成共識。在聯盟鏈環境下，PBFT 提供了堅實的信任基礎，特別適用於本研究所探討的委員會共識場景。

\section[相關研究與盲點分析]{相關研究與盲點分析 (Related Work and Blind Spot Analysis)}
\label{sec:related_work}

現有的區塊鏈聯邦學習驗證方法可大致分為兩大類：基於密碼學證明的驗證方法與基於委員會的共識方法。前者追求數學上可證明的計算正確性，但往往面臨嚴重的效能瓶頸；後者則透過經濟激勵與多數決達成共識，但高度依賴誠實多數假設。本節將系統性分析這些方法的技術原理、效能數據與固有局限，以釐清本研究的學術定位。

\subsection{基於密碼學驗證的方法 (Cryptographic Verification Methods)}
\subsubsection{零知識機器學習 (zkML) 的計算瓶頸}
零知識機器學習（zkML）試圖透過將機器學習計算轉換為算術電路，使驗證者無需重新執行模型即可確認計算的正確性與數據隱私 \cite{chen2024zkml}。其技術堆疊通常包括 Groth16（以約 200 bytes 的極小證明著稱）、PLONK（具備通用可更新設置特性）\cite{gabizon2019plonk} 與 zk-STARK（無需信任設置且具量子抗性）。轉換過程需經歷三個高成本階段：首先將浮點數量化為有限域整數，接著將每個運算分解為多項式約束，最後生成密碼學證明。

然而，約束數量隨深度學習模型的複雜度呈指數級膨脹。根據 ZEN 編譯器的基準測試 \cite{feng2021zen}，一個簡單的 ShallowNet-MNIST 模型需要 4.31 百萬（4.31M）個約束，而稍大的 LeNet-Face-large-ORL 則暴增至 2.63 億（263M）個約束。Chen 等人在 EuroSys 2024 的實驗數據進一步揭示了其效能瓶頸 \cite{chen2024zkml}：ResNet-18 模型的證明生成需耗時 52.9 秒，VGG16 需要 637 秒，而 DistillGPT-2 更高達 3,651 秒（約一小時），且在生成過程中需要高達 1TB RAM 的高規格硬體支援。儘管框架效能持續優化——例如 EZKL 相比 RISC Zero 快了 65.88 倍且記憶體使用減少 98.13\% \cite{ezkl2024benchmarking}——但對於需要頻繁迭代的聯邦學習而言，此類開銷仍難以負荷。

此外，zkML 的核心局限在於難以支援複雜的拜占庭容錯聚合演算法。Krum 與 Multi-Krum 等演算法需計算所有客戶端更新間的成對距離，這將產生 $O(n^2 \cdot d)$ 的約束爆炸；排序與中位數運算在零知識電路中亦極度昂貴。現有 zkFL 方案如 RiseFL \cite{zhu2024risefl} 僅能支援 L2-norm 等簡單有效性檢查，將密碼學成本從 $O(d)$ 降至 $O(d/\log d)$，但仍無法實現完整的距離計算防禦。因此，zkML 雖然提供了強大的密碼學安全性，卻以犧牲聚合演算法的通用性與系統效率為代價。

\subsection{基於樂觀驗證的方法 (Optimistic Verification Methods)}
\subsubsection{opML 的架構限制與延遲挑戰}
樂觀機器學習（optimistic Machine Learning, opML）採用「預設正確」的執行模式，僅在爭議發生時才啟動驗證程序 \cite{conway2024opml}。其運作流程為：服務提供者於鏈下執行機器學習推論並提交結果，驗證者在規定的挑戰期內可發起欺詐證明（Fraud Proof），透過二分協議（Bisection Protocol）逐步縮小爭議範圍至單一計算步驟，最終由鏈上的 FPVM（欺詐證明虛擬機）進行仲裁。ORA Protocol 作為首個開源 opML 實現，已能支援 LLaMA 2 等 70 億參數模型直接於以太坊環境下運行 \cite{ora2024opml}。

挑戰期的設計反映了安全性與效率的根本權衡。為了確保驗證者有充足時間偵測並提交證明，同時容納網路延遲與潛在的審查攻擊，主流 Optimistic Rollup 協議如 Optimism 與 Arbitrum 分別採用了 7 天與 6.4 天的挑戰期 \cite{optimism2024rollup}。這種長週期的確認機制與聯邦學習的需求存在本質衝突——聯邦學習依賴快速的迭代更新與聚合，若每一輪訓練皆需等待數天的挑戰期，將使模型訓練完全不可行。

此外，opML 基於 AnyTrust 假設（即系統中至少存在一個誠實驗證者），這與 BCFL 的多方共識需求存在差異。opML 設計初衷為處理單一提交者與單一挑戰者間的爭議，而非多方參與者間的複雜共識。加之 FPVM 的記憶體限制需採用延遲載入設計，當聯邦學習模型涉及大量參與者的梯度更新時，可能超出其實際處理能力。雖然部分方案試圖整合 zkML 元件以增強隱私，但仍受限於單一證明者架構，無法滿足 BCFL 對於多驗證者去中心化共識的需求。

\subsection{基於委員會共識的方法 (Committee-Based Consensus Methods)}
相較於上述驗證方法，基於委員會的共識機制在效率與實用性之間取得了較佳的平衡，因而成為當前 BCFL 的主流選擇。現有研究主要在委員會的「選舉機制」上進行創新。

\subsubsection{FLCoin：基於滑動窗口的動態選舉}
FLCoin 提出了一種基於滑動窗口（Sliding Window）的動態委員會選舉機制 \cite{ren2024scalable}，將聯邦學習的貢獻歷史作為委員會成員資格的依據。每個有效的更新區塊代表一份成員資格，窗口大小固定為 $s$，隨著新區塊的生成而滑動更新。節點的貢獻值 $C_k$ 由訓練數據規模 $|D_k|$ 決定，貢獻值最高者將成為委員會領導者。

根據其安全性分析，在網路規模 $n=500$、惡意節點比例 $\leq 25\%$、窗口大小 $s=100$ 的條件下，委員會內惡意節點數不超過容錯閾值的機率可達 98.4\%；若將 $s$ 提升至 150，此機率更可提升至 99.8\%。在效能方面，FLCoin 透過此機制相較於傳統 PBFT 實現了 90\% 的通訊開銷降低與 35\% 的訓練時間縮短。在 100 個節點的配置下，其共識延遲僅需 3.05 秒。然而，FLCoin 的滑動窗口設計未建立權益衰減機制，且依賴「預定義的可信管理者群組」來維護身分鏈，引入了潛在的中心化風險。更關鍵的是，該研究未考慮惡意節點採取長期策略，透過持續參與逐步累積權益以控制委員會的情境。

\subsubsection{BlockDFL：基於權益加權的雙層驗證}
BlockDFL 採用了完全去中心化的點對點架構 \cite{qin2024blockdfl}，透過區塊雜湊值與權益加權（Stake-weighted）實現委員會選舉的隨機性與可驗證性。其核心假設為「持有大量權益的參與者傾向誠實行為，因為他們能從貨幣獎勵中獲益更多」。該系統設計了雙層評分機制：第一層由聚合者進行本地推論篩選，第二層由驗證者使用 Krum 演算法過濾異常值。

BlockDFL 宣稱能容忍高達 40\% 的惡意參與者，優於多數現有框架。其獎勵連鎖機制確保了權益能均等地分配給貢獻者。與 FLCoin 的關鍵差異在於，BlockDFL 的選舉基礎是經濟權益而非純粹的貢獻次數。這雖然提高了攻擊門檻，但也引入了新的攻擊面：國家級攻擊者或競爭對手可能願意承擔經濟損失（Sacrifice Stake）來破壞模型。此外，該機制同樣缺乏防止 Sybil 攻擊者跨多重身份逐步累積權益的防禦手段。

\subsubsection{BFLC 與其他信譽機制}
BFLC 開創性地將委員會共識引入 BCFL \cite{li2021blockchain}，採用雙區塊儲存設計並利用 K-fold 交叉驗證評估更新品質。然而，BFLC 面臨嚴重的冷啟動問題（Cold Start Problem）——新加入節點因缺乏歷史數據而難以建立信任，導致系統容易被早期進入的惡意節點掌控。後續研究如 VBFL \cite{chen2021robust} 與 VFChain \cite{peng2022vfchain} 雖引入了準確度差異（VAD）指標與可審計的雙跳鏈結構來增強安全性，但仍共同面臨 50\% 拜占庭閾值的硬性限制以及資源受限裝置的計算負擔問題。

\subsection{現有方法的系統性局限與研究缺口}

\subsubsection{安全性、效率與通用性的三難困境}
綜合上述分析，揭示了現有方法在「安全性-效率-通用性」三個維度上的 Pareto 前沿權衡（Trade-off）。如表 \ref{tab:methodology_comparison} 所示，zkML 提供了最強的密碼學安全性，無需依賴誠實假設，但其證明生成時間隨模型規模呈超線性增長，且無法支援 Krum 等複雜聚合算法。opML 透過經濟激勵大幅降低了計算成本，但其長達數天的挑戰期與單一證明者架構使其難以應用於即時性要求高的聯邦學習場景。委員會方法在效率與實用性間取得了折衷，但均依賴某種形式的誠實多數假設。

\begin{table}[ht]
\centering
\caption{現有 BCFL 驗證與共識機制之比較分析}
\label{tab:methodology_comparison}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{方案類型} & \textbf{代表技術/系統} & \textbf{安全性保證來源} & \textbf{效率 (典型延遲)} & \textbf{聚合通用性} \\ \hline
密碼學驗證 & zkML (Groth16, PLONK) & 數學證明 (無信任假設) & 分鐘至小時 (極慢) & 僅限簡單聚合 (如 FedAvg) \\ \hline
樂觀驗證 & opML (Optimism, ORA) & 經濟賽局 (AnyTrust) & 7 天挑戰期 & 受限於 FPVM 實作 \\ \hline
\multirow{3}{*}{委員會共識} & FLCoin & 統計機率 (98.4\%) & 3.05 秒 & 支援多種聚合 \\ \cline{2-5} 
 & BlockDFL & 經濟權益 (40\% 容錯) & <3 秒 & 支援 Krum/Median \\ \cline{2-5} 
 & BFLC & 聲譽積累 (50\% 閾值) & 中等 & 支援 \\ \hline
\end{tabular}%
}
\end{table}

\subsubsection{關鍵缺口：動態累積攻擊的防禦真空}
更為關鍵的是，所有現有的委員會方案均未充分處理\textbf{長期權益累積（Long-term Stake Accumulation）}導致的委員會滲透風險。無論是 FLCoin 的滑動窗口或 BlockDFL 的權益加權，均採用静態的安全性分析模型（如超幾何分佈），假設攻擊者的資源或權益比例是固定的。然而，在實際賽局中，理性的攻擊者會採取\textbf{漸進式委員會佔領（Progressive Committee Capture）}策略：先在潛伏期表現誠實以獲取合法獎勵，待累積了足夠的權益或聲譽後，再於關鍵時刻發動攻擊。

現有文獻存在三個核心缺口：
\begin{enumerate}
    \item \textbf{缺乏動態安全性分析}：忽略了攻擊者透過時間維度累積影響力的動態過程。
    \item \textbf{驗證效率與通用性的矛盾}：尚無方案能在保持聚合演算法通用性（如支援 Krum）的同時，提供接近密碼學等級的安全性。
    \item \textbf{缺乏抗累積機制}：現有權益證明機制多設計為線性累積，賦予了早期參與者或長期潛伏者過大的系統控制權，缺乏類似「權益衰減」或「動態輪換」的防禦設計。
\end{enumerate}

本研究旨在透過引入時間衰減權益函數與動態挑戰機制，填補上述缺口，在維持委員會機制的高效率同時，顯著提升對抗長期滲透攻擊的安全性。

\section{系統模型與前置定義 (System Model and Preliminaries)}
\label{sec:system_model}

本節定義本研究所採用的基準系統模型。此模型基於 BlockDFL 委員會架構並進行擴展，作為後續威脅分析與防禦設計的基礎。

\subsection{網路模型}
本研究考慮一個去中心化的區塊鏈聯邦學習系統，由以下三種核心角色構成：
\begin{enumerate}
    \item \textbf{Update Providers (UP)}：原為客戶端 (Clients)，集合記為 $\mathcal{U} = \{u_1, u_2, ..., u_N\}$。每個 Update Provider 持有本地私有資料集 $\mathcal{D}_i$，負責在本地進行模型訓練並提交更新。
    \item \textbf{Aggregators (AG)}：集合記為 $\mathcal{A} = \{a_1, a_2, ..., a_K\}$。負責收集 UP 的更新，執行初步聚合生成提案。Aggregator 的選擇基於權益。
    \item \textbf{Verifier Committee (VC)}：集合記為 $\mathcal{V} = \{v_1, v_2, ..., v_M\}$。Verifiers 組成委員會，負責驗證 Aggregator 的提案。委員會成員通過共識機制批准提案並上鏈。
\end{enumerate}

\subsection{聚合與共識流程}
在每個訓練輪次 $r$，系統執行以下流程：
\begin{enumerate}
    \item \textbf{本地訓練}：UP 訓練 model update $\Delta w_i$ 並發送給 AG。
    \item \textbf{初步聚合}：AG 生成聚合更新 $\Delta w_{agg}$ 並提交提案交易。
    \item \textbf{委員會驗證}：委員會 $\mathcal{V}_r$ 執行驗證邏輯（如 Krum 檢驗）。
    \item \textbf{共識決策}：委員會通過 BFT 共識對提案投票。
    \item \textbf{獎勵分配}：若提案通過，AG、UP 與投票贊成的 Verifiers 共同瓜分系統獎勵。
\end{enumerate}

\subsection{權益動態與攻擊面}
權益（Stake）在系統中扮演核心角色，既是選擇權重的依據，也是經濟獎勵的來源。這種「贏家通吃」的正反饋特性雖然激勵了誠實行為，但也創造了攻擊面：若攻擊者能策略性地累積權益，便能逐步掌控委員會。與傳統 PoS 不同，BCFL 中的攻擊者不僅能破壞共識，還能透過投毒模型永久損害全域模型的效能，且難以被傳統 BFT 機制偵測。
