\begin{ZhChapter}

\chapter{實驗評估 (Experimental Evaluation)}
\label{chap:evaluation}

本章透過系統性的實驗設計，驗證挑戰增強型委員會架構在應對漸進式委員會佔領攻擊時的防禦效能。有別於傳統聯邦學習安全性研究將模型準確率視為首要評估指標，本研究的核心關注點在於經濟安全性機制能否有效遏止理性攻擊者的惡意行為，進而維護系統的長期治理穩定性。為了提供最嚴格的效能驗證，本章的實驗採用「最壞情況分析」的設計哲學，假設攻擊者完全不顧經濟理性而執意發動所有可能的攻擊，藉此檢驗即使在此極端條件下，防禦機制是否仍能確保每一次惡意行為都被偵測並受到懲罰。這種實驗設計的深層意涵在於：若攻擊者在最壞情況下仍無法逃脫制裁，則理性攻擊者在預見此結果後將選擇不發動攻擊，從而使系統在實務運作中自然趨向穩定均衡。基於此設計理念，本章將從權益動態演化、攻擊偵測與懲罰效果、以及系統穩定性等多維度指標進行追蹤分析，以實證角度檢驗第 \ref{chap:framework} 章所提出的理論主張。

\section{實驗設置}
\label{sec:eval_setup}

\subsection{資料集與模型配置}

本研究選用 MNIST 手寫數字資料集作為聯邦學習任務的測試平台，該資料集包含 60,000 張訓練影像與 10,000 張測試影像，每張影像為 28×28 像素的灰階圖像，對應 0 至 9 共十個數字類別。選擇此資料集的考量在於其作為聯邦學習研究標準基準的廣泛認可度，採用相同的測試平台能夠確保實驗結果與現有文獻具備可比較性，同時便於後續研究者進行效能對照與結果重現。在模型架構方面，本研究採用包含兩個卷積層與兩個全連接層的標準卷積神經網路，此架構的參數規模足以呈現聯邦學習在分散式訓練過程中的典型行為特徵，同時維持實驗運算的可行性與效率。

關於訓練資料的分配方式，本研究將資料以獨立同分布的方式均勻分配給所有參與的客戶端節點。這項設計選擇源於本研究防禦機制的本質特性：如第 \ref{chap:framework} 章所闘述，挑戰增強型委員會架構的核心防禦機制運作於共識層而非資料層，其功能在於透過經濟懲罰來威懾惡意的委員會行為。攻擊能否成功發動取決於委員會的組成結構與共識決策過程，這些因素與底層訓練資料的統計分佈特性相互獨立。換言之，無論資料呈現何種分佈型態，攻擊者控制委員會的機率計算方式、挑戰機制的觸發條件、以及罰沒協議的執行邏輯都維持完全一致。資料分佈特性所影響的是攻擊成功後對模型收斂造成的傷害程度，而非攻擊行為本身能否被偵測或攻擊者是否會因此受到經濟制裁，因此標準的均勻分配方式已足以充分驗證本架構在共識層防禦上的核心效能。

\subsection{基準方法與攻擊場景}

為確保評估結果的公平性與說服力，本實驗將挑戰增強型委員會架構與 BlockDFL 進行系統性的對照比較。BlockDFL 作為當前基於委員會機制的區塊鏈聯邦學習系統代表，採用固定規模的驗證委員會並依賴誠實多數假設來維護系統安全性，其設計理念與運作機制已在第 \ref{sec:blockdfl-baseline} 節進行詳細介紹。為了實現嚴謹的對照比較，兩種架構在本實驗中均採用相同的委員會規模 $C=7$，此配置參考了 BlockDFL 原始論文中建議的參數設定，旨在效率與基本安全性之間取得平衡。在共識機制方面，兩者皆遵循標準的拜占庭容錯協議，要求提案必須獲得超過三分之二委員會成員的同意方能通過。本研究方法與 BlockDFL 的關鍵差異在於引入了事後挑戰機制，此機制允許系統在正常運作時維持即時執行模式以確保高效率，同時賦予任何節點在偵測到異常時透過質押押金發起挑戰的權利，進而觸發全網仲裁流程並對確認的惡意行為執行罰沒制裁。

攻擊場景的設計嚴格遵循第 \ref{chap:threat-model} 章所定義的漸進式委員會佔領攻擊模型，攻擊者採取理性的兩階段策略來最大化其長期收益。在潛伏階段，攻擊者控制的節點完全模仿誠實行為模式，正常參與本地訓練並提交符合品質標準的模型更新，其目的在於透過持續的誠實參與來累積權益並建立良好的歷史信譽，為後續的攻擊行動奠定必要的資源基礎。當攻擊者在某輪委員會選舉中成功獲得超過三分之二的席位時，便立即進入佔領階段並根據當時對系統各組件的控制情況選擇適當的攻擊策略。佔領階段的攻擊行為依據控制範圍分為兩種類型：當攻擊者僅控制委員會多數但未同時控制聚合者角色時，將採取戰略性餓死策略，透過系統性地拒絕包含誠實節點更新的聚合提案來獨佔該輪的全部獎勵，同時阻止誠實節點的權益增長；當攻擊者同時控制委員會與聚合者時，則採取更為激進的全棧投毒策略，直接將包含標籤翻轉等惡意內容的模型更新強制寫入區塊鏈。這兩種攻擊類型分別對應了經濟層面的治理操縱與技術層面的模型破壞，完整涵蓋了理性攻擊者在不同控制情境下可能採取的策略空間。

\subsection{實驗參數配置}

表 \ref{tab:exp_params} 彙整了本研究實驗所採用的完整系統參數配置，這些參數的設定主要參考 BlockDFL \cite{qin2024blockdfl} 等主流區塊鏈聯邦學習研究的標準配置，以確保實驗結果具備良好的可比較性與可重現性。

\begin{table}[htbp]
    \centering
    \caption{實驗參數配置}
    \label{tab:exp_params}
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{參數名稱} & \textbf{設定值} \\
        \hline
        訓練輪數 & $R = 300$（基礎實驗）/ $R = 2000$（長期實驗） \\
        \hline
        驗證者池規模 & $N = 100$ \\
        \hline
        委員會大小 & $C = 7$ \\
        \hline
        惡意節點數量 & $M = 30$（初始權益佔比 30\%） \\
        \hline
        初始權益分配 & 所有節點均分配 100 單位 \\
        \hline
        角色配置 & 聚合者 4 位，其餘為更新提供者 \\
        \hline
        每輪獎勵 & 驗證者 1.0，聚合者 1.0，更新提供者 0.05 \\
        \hline
        罰沒規則 & 挑戰成功時全額沒收惡意節點質押 \\
        \hline
        學習率 & $\eta = 0.01$（衰減率 0.99） \\
        \hline
        本地訓練 & 每輪 1 個 epoch，批次大小 32 \\
        \hline
    \end{tabular}
\end{table}

在關鍵參數的設定考量上，惡意節點初始佔比設定為 30\% 代表了一個相當嚴峻的威脅情境，此比例已接近大多數拜占庭容錯系統所能容忍的理論上限，能夠有效測試防禦機制在高壓環境下的表現。委員會規模 $C=7$ 的選擇反映了實務部署中效率與安全性的典型權衡考量，根據第 \ref{sec:committee-size-security} 節的超幾何分佈分析，在全網 100 個節點且惡意節點佔比 30\% 的條件下，惡意節點在單輪中獲得委員會超過三分之二席位的機率約為 2.4\%。這個機率雖然在單輪來看並不算高，但考量到聯邦學習訓練通常需要經歷數百甚至數千輪迭代，累積下來足以產生多次攻擊機會，為驗證防禦機制的長期效能提供了充分的測試場景。獎勵機制的設定則遵循 BlockDFL 的原始設計原則，驗證者與聚合者因承擔較高的運算負擔與協調責任而獲得較高的單輪獎勵，更新提供者則獲得與其貢獻程度相稱的基礎獎勵，這種差異化的獎勵結構是驅動權益累積動態變化的重要因素。

\section{實驗結果與分析}
\label{sec:experimental_results}

\subsection{權益動態演化分析}
\label{sec:stake_dynamics}

本研究的核心主張在於挑戰增強型委員會架構能夠透過經濟懲罰機制有效打破漸進式委員會佔領攻擊所依賴的正反饋循環，為驗證此主張，本節深入分析兩種架構下惡意節點與誠實節點之間的權益演化動態。權益比值作為衡量系統治理結構健康程度的核心指標，其變化軌跡直接反映了經濟安全性機制能否成功重塑長期的權力分配格局。在以下的分析中，權益比值定義為惡意節點平均權益除以誠實節點平均權益，當此數值大於 1 時表示惡意節點處於優勢地位，小於 1 則表示誠實節點佔據主導。

在缺乏挑戰機制的 BlockDFL 架構中，實驗數據清楚呈現了權益分佈逐漸失衡的系統性趨勢。追蹤 2000 輪訓練過程中的權益演化軌跡可以發現，惡意節點的權益比值從初始的 1.0 開始穩定攀升，經過約 300 輪的初期波動後便收斂至 1.3 左右的水平並長期維持。這種持續性的優勢並非來自偶然的統計波動，而是根植於系統獎勵機制的內在結構特徵。由於聚合者與驗證者角色所獲得的單輪獎勵顯著高於一般更新提供者，而角色分配機制又採用權益加權的隨機選舉方式，這種設計在無形中創造了一個自我強化的正反饋結構：一旦某些節點透過早期的隨機優勢或策略性行為累積了相對較高的權益，其在後續輪次被選為高獎勵角色的機率便隨之提升，進而獲得更多獎勵並進一步鞏固既有的優勢地位。這種「權益優勢帶來更多獎勵，更多獎勵鞏固權益優勢」的循環結構，正是第 \ref{chap:threat-model} 章所描述的漸進式委員會佔領攻擊得以成立的經濟基礎。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/experiments/mnist_results_stack_comparison.png}
    \caption{BlockDFL 與 CACA 權益演化對比（300 輪基礎實驗）}
    \label{fig:stake_evolution_300}
\end{figure}

挑戰增強型委員會架構的權益演化軌跡則呈現出與 BlockDFL 截然不同的動態特徵。如圖 \ref{fig:stake_evolution_300} 所示的 300 輪基礎實驗中，惡意節點的權益比值並非沿著平滑的曲線緩慢變化，而是展現出明顯的「階梯式下降」模式。這種獨特的階梯狀軌跡精確對應了異步審計機制觸發罰沒制裁的具體時點：每當惡意節點嘗試利用其委員會控制權發動攻擊時，無論採取的是戰略性餓死還是全棧投毒策略，挑戰者都能夠透過重新執行 Krum 演算法來偵測聚合結果與正確運算之間的不一致，隨即發起挑戰交易並觸發全網仲裁流程。一旦惡意行為經仲裁確認，所有參與共謀的惡意節點將被沒收全額質押，造成其權益的瞬間大幅縮減。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/experiments/mnist_results_stack_comparison_2000_round.png}
    \caption{2000 輪長期模擬下的權益動態演化}
    \label{fig:stake_evolution_2000}
\end{figure}

將實驗觀察期延伸至 2000 輪的長期模擬，更能完整展現經濟懲罰機制作為「漸進式淨化」工具的運作特性。如圖 \ref{fig:stake_evolution_2000} 所示，BlockDFL 中惡意節點的權益比值在經歷初期波動後穩定收斂至 1.3 左右並長期維持此優勢地位，這種持續性的權益優勢使得攻擊者能夠在整個實驗期間持續保有對系統治理的顯著影響力。相較之下，本研究方法中的惡意節點權益軌跡呈現出五次明確的階梯式下降，每一次下降都對應著一次成功的罰沒制裁。第一次罰沒發生在第 15 輪，將權益比值從初始的 1.0 驟降至 0.77；第二次發生在第 136 輪，比值進一步降至 0.68；第三次在第 695 輪降至 0.53；第四次在第 815 輪降至 0.42；第五次在第 1332 輪降至 0.34。實驗結束時，惡意節點的權益比值穩定在 0.37，意味著惡意節點的平均權益僅為誠實節點的三分之一強。

這種漸進式淨化的過程揭示了罰沒機制的一項重要特性：由於每次罰沒僅能懲罰當輪實際參與共謀攻擊的惡意節點，其數量受限於委員會規模，因此單次罰沒無法一舉清除所有惡意參與者，而是需要透過多輪次的持續制裁來逐步削弱攻擊者的整體實力。然而，這種漸進式的特性並非缺陷，反而展現了系統的自我調節能力。觀察五次罰沒事件的時間間隔可以發現一個顯著的趨勢：隨著惡意節點權益基數的縮減，其成功組織委員會佔領攻擊的難度持續提高，導致罰沒事件的發生頻率逐漸降低。從第 15 輪到第 136 輪間隔 121 輪，從第 136 輪到第 695 輪間隔 559 輪，從第 695 輪到第 815 輪間隔 120 輪，從第 815 輪到第 1332 輪間隔 517 輪，而第 1332 輪之後的 668 輪中則未再發生任何攻擊。這種動態變化印證了正反饋循環被有效打破的核心主張：當惡意節點的權益基數下降後，其被選入委員會的機率降低，獲得獎勵的機會減少，恢復優勢的難度隨之提高，系統因此逐漸趨向誠實節點主導的穩定均衡。

\subsection{攻擊偵測與懲罰效果分析}
\label{sec:attack_frequency}

權益動態的變化最終會具體反映在攻擊事件的發生頻率與處置結果上，本節透過分析兩種架構在 2000 輪長期實驗中的攻擊事件記錄，量化評估經濟威懾機制對攻擊者行為的實質影響。需要特別強調的是，本實驗採用最壞情況分析的設計原則，假設攻擊者在每次獲得委員會控制權時都會不顧後果地發動攻擊，藉此驗證防禦機制在極端條件下的偵測與懲罰能力。在實際運作中，理性攻擊者若預見攻擊必然被偵測並遭受罰沒，將選擇不發動攻擊以保全其質押資產，因此本節所記錄的攻擊次數代表的是防禦機制所成功處置的最壞情況，而非系統在正常運作下預期會遭遇的攻擊頻率。

在 2000 輪的長期實驗中，BlockDFL 架構共記錄了 107 次委員會佔領攻擊事件，平均約每 19 輪便會發生一次安全事件。進一步分析攻擊類型的分佈可以發現，107 次攻擊中有 18 次屬於戰略性餓死類型，其餘 89 次則為全棧投毒攻擊。全棧投毒攻擊佔比高達 83\% 的現象反映了一個重要的系統特性：當攻擊者成功控制委員會時，往往也同時控制了當輪的聚合者角色，這使得攻擊者傾向於選擇破壞力更大的全棧投毒策略，而非僅止於經濟層面的戰略性餓死。由於 BlockDFL 缺乏事後挑戰機制，這些攻擊事件均未受到任何形式的經濟制裁，攻擊者在成功操控委員會決策後不僅能夠獲取不當的經濟利益，更能夠將這些利益轉化為後續輪次中的權益優勢，形成持續性的治理威脅。

挑戰增強型委員會架構在相同的 2000 輪實驗中僅記錄了 5 次攻擊事件，且這 5 次攻擊全部被挑戰者成功偵測並經全網仲裁確認後執行了罰沒制裁。在攻擊類型方面，5 次攻擊中有 2 次為戰略性餓死，3 次為全棧投毒，兩種攻擊類型均被完整偵測並懲罰，顯示本架構的防禦能力並不受攻擊策略差異的影響。攻擊發生次數從 BlockDFL 的 107 次大幅降至 5 次，這種數量級的差異主要源於兩個相互強化的因素。其一是罰沒事件所造成的權益削減效應：由於惡意節點在遭受罰沒後權益大幅縮水，其在後續輪次被選入委員會的機率隨之降低，從根本上減少了攻擊機會的出現頻率。其二是權益分佈改變對委員會組成機率的影響：隨著惡意節點的相對權益佔比下降，即使被選入委員會，要同時獲得超過三分之二席位的難度也顯著提高。

更值得關注的是這 5 次攻擊事件的時間分佈特徵。五次攻擊分別發生在第 15、136、695、815 與 1332 輪，全部集中在實驗的前三分之二階段。在第 1332 輪的最後一次罰沒之後，攻擊者的權益比值已降至 0.34，此後長達 668 輪的觀察期內再無任何成功攻擊的記錄。這項結果的意涵超越了單純的攻擊頻率統計：它從實證角度證明了經濟安全性機制能夠在系統的長期演化中發揮導向作用，透過持續的罰沒制裁將惡意節點逐步邊緣化，最終將權益分佈與治理結構引導至誠實節點穩定主導的均衡狀態。關鍵的觀察在於，本研究方法中的每一次攻擊嘗試都被完整偵測並受到懲罰，攻擊者無法從任何一次惡意行為中獲得淨收益，這與 BlockDFL 中攻擊者能夠持續累積不當利益的情況形成鮮明對比。

\subsection{系統穩定性分析}
\label{sec:system_stability}

攻擊頻率的降低與攻擊行為的有效懲罰會自然轉化為整體系統穩定性的提升，雖然系統穩定性並非本研究的核心貢獻焦點，但此指標對於評估防禦機制的實務部署價值仍具有重要的參考意義。本節從系統可用性與模型收斂品質兩個面向進行分析，以全面呈現防禦機制對系統整體運作的影響。

為了量化攻擊事件對系統運作造成的實質衝擊，本研究定義「最低不可用率」作為評估指標，該指標衡量系統因遭受攻擊而處於效能顯著下降狀態的時間比例。根據實驗過程中的觀測數據，每次成功執行的全棧投毒攻擊會導致模型準確率出現急劇下降，而聯邦學習固有的自我修復機制通常需要約 5 至 25 輪的後續訓練才能使模型效能恢復至正常水平。採用最為保守的 5 輪恢復期估計進行計算，BlockDFL 在 2000 輪實驗中因 89 次全棧投毒攻擊而累積產生至少 445 輪的效能下降期間，對應約 22.3\% 的最低不可用率。若採用實際觀測中更為常見的 15 輪恢復期進行估算，不可用率將攀升至 66.8\%，意味著系統有超過三分之二的運作時間處於從攻擊中恢復的過程中。相較之下，本研究方法憑藉僅 3 次全棧投毒攻擊的優異記錄，將最低不可用率有效控制在 0.75\% 以下。這種可用性差異在需要持續穩定運作的關鍵任務應用場景中具有重要意義：無論是醫療診斷輔助系統、自動駕駛決策模組、還是金融風險即時評估平台，這些應用不僅對最終模型的準確性有嚴格要求，更需要訓練過程中模型狀態維持高度穩定，頻繁的效能崩潰與恢復週期即使最終能夠收斂至相近的準確率，仍會嚴重損害系統的整體可靠性與服務品質。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/experiments/mnist_results_convergence.png}
    \caption{模型準確率收斂曲線比較}
    \label{fig:convergence_curve}
\end{figure}

在模型收斂品質方面，兩種架構最終均能達成相近的準確率水平，這一結果符合預期並印證了本研究的設計哲學。聯邦學習本身具備顯著的自我修復能力，只要攻擊者無法持續不間斷地佔領委員會，後續輪次中來自誠實節點的正確模型更新便能夠逐步抵銷惡意梯度所造成的參數偏差，引導模型重新收斂至正確的優化方向。從圖 \ref{fig:convergence_curve} 可以觀察到兩種架構在訓練過程穩定性上的差異：BlockDFL 的準確率曲線在多個時間點出現明顯的突發性下降與後續緩慢回升，這些波動精確對應了全棧投毒攻擊所造成的瞬時衝擊以及聯邦學習自我修復機制逐步發揮作用的恢復過程；相較之下，本研究方法的準確率曲線呈現更為平滑且穩定的上升趨勢，這反映了較低攻擊頻率所帶來的訓練過程連續性優勢。

兩種架構最終準確率相近這一現象，恰好印證了本研究在第 \ref{chap:framework} 章所闘述的設計哲學核心觀點。聯邦學習的自癒特性意味著偶發性的模型參數偏差能夠被後續的正常訓練自然修復，因此單純關注模型品質指標並不足以全面評估系統的安全性狀態。真正需要防禦的威脅並非個別輪次中的模型損傷，而是攻擊者透過權益累積機制逐步擴大影響力、最終奪取系統治理權的長期戰略性威脅。本研究方法透過經濟懲罰機制有效阻斷了這種權益累積的正反饋循環，確保系統的治理結構長期維持在誠實節點主導的健康狀態。實驗結束時惡意節點權益比值僅為 0.37 的事實，意味著攻擊者不僅未能建立持續性的治理優勢，反而被逐步邊緣化至難以再次組織有效攻擊的弱勢地位，這才是挑戰增強型委員會架構相對於傳統方法的根本性優勢所在。

\section{本章小結}
\label{sec:eval_summary}

本章透過系統性的最壞情況實驗分析，從權益動態演化、攻擊偵測與懲罰效果、以及系統穩定性三個層面驗證了挑戰增強型委員會架構的防禦效能。實驗設計假設攻擊者在每次獲得委員會控制權時都會執意發動攻擊，藉此檢驗防禦機制在極端條件下的表現。2000 輪長期實驗的結果顯示，所有 5 次攻擊嘗試均被成功偵測並執行罰沒制裁，沒有任何惡意行為能夠逃脫經濟懲罰。這項發現的深層意涵在於：理性攻擊者若能預見攻擊必然被偵測並遭受損失，將選擇不發動攻擊以保全質押資產，從而使系統在實務運作中自然趨向穩定均衡，維持第 \ref{sec:efficiency_analysis} 節所分析的 $O(c^2)$ 效率水平。

在經濟安全性機制的核心驗證方面，權益動態分析清楚揭示了兩種架構的本質差異。BlockDFL 中惡意節點的權益比值穩定收斂至 1.3，這種優勢在 2000 輪的長期實驗中持續存在並轉化為對系統治理的顯著影響力，共計發生 107 次未受懲罰的攻擊事件。本研究方法則透過罰沒機制實現了「漸進式淨化」的防禦效果：五次階梯式的權益下降將惡意節點的權益比值從初始的 1.0 逐步壓制至最終的 0.37，每一次罰沒都進一步削弱了攻擊者組織後續攻擊的能力。值得注意的是，隨著惡意節點權益基數的縮減，攻擊機會的出現頻率也相應降低，第 1332 輪的最後一次罰沒之後再無任何成功攻擊的記錄，這從實證角度證明了系統確實被引導至誠實節點主導的穩定均衡。在攻擊類型的分析上，無論是戰略性餓死還是全棧投毒，本架構均展現出完整的偵測與懲罰能力，確保了防禦機制對不同攻擊策略的普適有效性。這些實驗結果從實證角度印證了第 \ref{sec:incentive_mechanism} 節的理論分析，證明經濟懲罰機制確實能夠重塑攻擊者的決策空間，使誠實行為成為長期均衡下的最優策略選擇。

\end{ZhChapter}