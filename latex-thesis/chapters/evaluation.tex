\begin{ZhChapter}

\chapter{實驗評估 (Experimental Evaluation)}
\label{chap:evaluation}

本章透過系統性的實驗設計，驗證挑戰增強型委員會架構在應對漸進式委員會佔領攻擊時的防禦效能。有別於傳統聯邦學習安全性研究將模型準確率視為首要評估指標，本研究的核心關注點在於經濟安全性機制能否有效遏止理性攻擊者的惡意行為，進而維護系統的長期治理穩定性。為了提供最嚴格的效能驗證，本章的實驗採用「最壞情況分析」的設計哲學，假設攻擊者完全不顧經濟理性而執意發動所有可能的攻擊，藉此檢驗即使在此極端條件下，防禦機制是否仍能確保每一次惡意行為都被偵測並受到懲罰。這種實驗設計的深層意涵在於：若攻擊者在最壞情況下仍無法逃脫制裁，則理性攻擊者在預見此結果後將選擇不發動攻擊，從而使系統在實務運作中自然趨向穩定均衡。基於此設計理念，本章將從權益動態演化、攻擊偵測與懲罰效果、以及系統穩定性等多維度指標進行追蹤分析，以實證角度檢驗第 \ref{chap:framework} 章所提出的理論主張。

\section{實驗設置}
\label{sec:eval_setup}

\subsection{資料集與模型配置}

本研究選用 MNIST 手寫數字資料集作為聯邦學習任務的測試平台，該資料集由 60,000 張訓練影像與 10,000 張測試影像組成，每張影像為 28×28 像素的灰階圖像，分別對應 0 至 9 共十個數字類別。選擇此資料集的主要考量在於其作為聯邦學習研究標準基準的廣泛認可度，採用相同的測試平台能夠確保實驗結果與現有文獻具備可比較性，同時也便於後續研究者進行效能對照與結果重現。在模型架構方面，本研究採用包含兩個卷積層與兩個全連接層的標準卷積神經網路，此架構的參數規模足以呈現聯邦學習在分散式訓練過程中的典型行為特徵，同時維持實驗運算的可行性與效率。

關於訓練資料的分配方式，本研究將資料均勻隨機分配給所有參與的客戶端節點。這項設計選擇源於本研究防禦機制的本質特性，如第 \ref{chap:framework} 章所闘述，挑戰增強型委員會架構的核心防禦機制運作於共識層而非資料層，其功能在於透過經濟懲罰來威懾惡意的委員會行為。攻擊能否成功發動取決於委員會的組成結構與共識決策過程，這些因素與底層訓練資料的統計分佈特性相互獨立。換言之，無論資料呈現何種分佈型態，攻擊者控制委員會的機率計算方式、挑戰機制的觸發條件、以及罰沒協議的執行邏輯都維持完全一致。資料分佈特性所影響的是攻擊成功後對模型收斂造成的傷害程度，而非攻擊行為本身能否被偵測或攻擊者是否會因此受到經濟制裁，因此標準的均勻分配方式已足以充分驗證本架構在共識層防禦上的核心效能。

\subsection{基準方法與攻擊場景}

為確保評估結果的公平性與說服力，本實驗將挑戰增強型委員會架構與 BlockDFL 進行系統性的對照比較。BlockDFL 作為當前基於委員會機制的區塊鏈聯邦學習系統代表，採用固定規模的驗證委員會並依賴誠實多數假設來維護系統安全性，其設計理念與運作機制已在第 \ref{sec:blockdfl-baseline} 節進行詳細介紹。為了實現嚴謹的對照比較，兩種架構在本實驗中均採用相同的委員會規模 $C=7$，此配置參考了 BlockDFL 原始論文中建議的參數設定，旨在效率與基本安全性之間取得平衡。在共識機制方面，兩者皆遵循標準的拜占庭容錯協議，要求提案必須獲得超過三分之二委員會成員的同意方能通過。本研究方法與 BlockDFL 的關鍵差異在於引入了事後挑戰機制，此機制允許系統在正常運作時維持即時執行模式以確保高效率，同時賦予任何節點在偵測到異常時透過質押押金發起挑戰的權利，進而觸發全網仲裁流程並對確認的惡意行為執行罰沒制裁。

攻擊場景的設計嚴格遵循第 \ref{chap:threat-model} 章所定義的漸進式委員會佔領攻擊模型，攻擊者採取理性的兩階段策略來最大化其長期收益。在潛伏階段，攻擊者控制的節點完全模仿誠實行為模式，正常參與本地訓練並提交符合品質標準的模型更新，其目的在於透過持續的誠實參與來累積權益並建立良好的歷史信譽，為後續的攻擊行動奠定必要的資源基礎。當攻擊者在某輪委員會選舉中成功獲得超過三分之二的席位時，便立即進入佔領階段並根據當時對系統各組件的控制情況選擇適當的攻擊策略。佔領階段的攻擊行為依據控制範圍分為兩種類型，當攻擊者僅控制委員會多數但未同時控制聚合者角色時，將採取戰略性餓死策略，透過系統性地拒絕包含誠實節點更新的聚合提案來獨佔該輪的全部獎勵，同時阻止誠實節點的權益增長。當攻擊者同時控制委員會與聚合者時，則採取更為激進的全棧投毒策略，直接將包含標籤翻轉等惡意內容的模型更新強制寫入區塊鏈。這兩種攻擊類型分別對應了經濟層面的治理操縱與技術層面的模型破壞，完整涵蓋了理性攻擊者在不同控制情境下可能採取的策略空間。

\subsection{實驗參數配置}

表 \ref{tab:exp_params} 彙整了本研究實驗所採用的完整系統參數配置，這些參數的設定主要參考 BlockDFL \cite{qin2024blockdfl} 等主流區塊鏈聯邦學習研究的標準配置，以確保實驗結果具備良好的可比較性與可重現性。

\begin{table}[htbp]
    \centering
    \caption{實驗參數配置}
    \label{tab:exp_params}
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{參數名稱} & \textbf{設定值} \\
        \hline
        訓練輪數 & $R = 300$（基礎實驗）/ $R = 2000$（長期實驗） \\
        \hline
        驗證者池規模 & $N = 100$ \\
        \hline
        委員會大小 & $C = 7$ \\
        \hline
        惡意節點數量 & $M = 30$（初始權益佔比 30\%） \\
        \hline
        初始權益分配 & 所有節點均分配 100 單位 \\
        \hline
        角色配置 & 聚合者 4 位，其餘為更新提供者 \\
        \hline
        每輪獎勵 & 驗證者 1.0，聚合者 1.0，更新提供者 0.05 \\
        \hline
        罰沒規則 & 挑戰成功時全額沒收惡意節點質押 \\
        \hline
        學習率 & $\eta = 0.01$（衰減率 0.99） \\
        \hline
        本地訓練 & 每輪 1 個 epoch，批次大小 32 \\
        \hline
    \end{tabular}
\end{table}

在關鍵參數的設定考量上，惡意節點初始佔比設定為 30\% 代表了一個相當嚴峻的威脅情境，此比例已接近大多數拜占庭容錯系統所能容忍的理論上限，能夠有效測試防禦機制在高壓環境下的表現。委員會規模 $C=7$ 的選擇反映了實務部署中效率與安全性的典型權衡考量，根據第 \ref{sec:committee-size-security} 節的超幾何分佈分析，在全網 100 個節點且惡意節點佔比 30\% 的條件下，惡意節點在單輪中獲得委員會超過三分之二席位的機率約為 2.4\%。這個機率雖然在單輪來看並不算高，但考量到聯邦學習訓練通常需要經歷數百甚至數千輪迭代，累積下來足以產生多次攻擊機會，為驗證防禦機制的長期效能提供了充分的測試場景。獎勵機制的設定則遵循 BlockDFL 的原始設計原則，驗證者與聚合者因承擔較高的運算負擔與協調責任而獲得較高的單輪獎勵，更新提供者則獲得與其貢獻程度相稱的基礎獎勵，這種差異化的獎勵結構是驅動權益累積動態變化的重要因素。

\section{實驗結果與分析}
\label{sec:experimental_results}

\subsection{權益動態演化分析}
\label{sec:stake_dynamics}

本研究的核心主張在於挑戰增強型委員會架構能夠透過經濟懲罰機制有效打破漸進式委員會佔領攻擊所依賴的正反饋循環，為驗證此主張，本節首先深入分析兩種架構下惡意節點與誠實節點之間的權益演化動態，此指標直接反映了經濟安全性機制能否成功重塑系統的長期治理結構。在缺乏挑戰機制的 BlockDFL 架構中，實驗數據清楚呈現了權益分佈逐漸失衡的系統性趨勢。追蹤整個訓練過程中的原始權益數據可以發現，惡意節點的平均權益穩定維持在誠實節點的 1.1 至 1.2 倍，這種持續性的優勢並非來自偶然的統計波動，而是根植於系統獎勵機制的內在結構特徵。

造成此權益失衡現象的機制可從獎勵分配與角色選舉的連動關係來理解。由於聚合者與驗證者角色所獲得的單輪獎勵顯著高於一般更新提供者，而角色分配機制又採用權益加權的隨機選舉方式，這種設計在無形中創造了一個自我強化的正反饋結構。一旦某些節點透過早期的隨機優勢或策略性行為累積了相對較高的權益，其在後續輪次被選為高獎勵角色的機率便隨之提升，進而獲得更多獎勵並進一步鞏固既有的優勢地位。這種「權益優勢帶來更多獎勵，更多獎勵鞏固權益優勢」的循環結構，正是第 \ref{chap:threat-model} 章所描述的漸進式委員會佔領攻擊得以成立的經濟基礎。值得注意的是，惡意節點的權益優勢並未呈現指數級的無限膨脹，而是穩定收斂在 1.1 至 1.2 倍的區間，這是因為攻擊者無法完全操控角色分配中的隨機性成分，且系統中的誠實節點仍會在各輪次中獲得其應得的獎勵份額。然而，即便是這種具有上界的穩定優勢，在系統的長期運作中仍然構成不可忽視的治理威脅，因為它使得攻擊者能夠以高於隨機預期的頻率控制委員會決策。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/experiments/mnist_results_stack_comparison.png}
    \caption{BlockDFL 與 CACA 權益演化對比（300 輪基礎實驗）}
    \label{fig:stake_evolution_300}
\end{figure}

挑戰增強型委員會架構的權益演化軌跡則呈現出與 BlockDFL 截然不同的動態特徵。如圖 \ref{fig:stake_evolution_300} 所示，在本研究方法中，惡意節點的平均權益並非沿著平滑的曲線緩慢變化，而是展現出明顯的「階梯式下降」模式。這種獨特的階梯狀軌跡精確對應了異步審計機制觸發罰沒制裁的具體時點，每當惡意節點嘗試利用其委員會控制權發動攻擊時，無論採取的是戰略性餓死還是全棧投毒策略，挑戰者都能夠透過重新執行 Krum 演算法來偵測聚合結果與正確運算之間的不一致，隨即發起挑戰交易並觸發全網仲裁流程。一旦惡意行為經仲裁確認，所有參與共謀的惡意節點將被沒收全額質押，造成其權益的瞬間大幅縮減。在 300 輪的基礎實驗觀察期內，這種罰沒事件分別在第 90 輪與第 229 輪各發生一次，兩次懲罰的累積效果導致惡意節點的平均權益在實驗結束時降至誠實節點的 0.56 倍。這個數值的戰略意涵相當深遠，它意味著惡意節點不僅未能如在 BlockDFL 中那樣建立起持續性的權益優勢，反而陷入了相對於誠實節點的顯著劣勢地位，其在未來委員會選舉中獲得多數席位的機率將因此大幅降低。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/experiments/mnist_results_stack_comparison_2000_round.png}
    \caption{2000 輪長期模擬下的權益動態演化}
    \label{fig:stake_evolution_2000}
\end{figure}

將實驗觀察期延伸至 2000 輪的長期模擬進一步印證了經濟懲罰機制在持久運作下的威懾效果。如圖 \ref{fig:stake_evolution_2000} 所示，在 BlockDFL 架構中，惡意節點的權益優勢在經歷約 250 輪的初期波動後便穩定收斂並長期維持在誠實節點的 1.2 倍左右，這種「強者恆強」的馬太效應使得攻擊者能夠在整個實驗期間持續保有對系統治理的顯著影響力。相較之下，本研究方法中的惡意節點權益軌跡在第 909 輪出現了決定性的關鍵轉折，該輪次所發生的罰沒事件導致惡意節點的平均權益從先前的水平瞬間暴跌至僅為誠實節點的 22.6\%，這次嚴厲的經濟制裁產生了深遠且持久的邊緣化效果。在隨後長達 1091 輪的觀察期內，惡意節點因權益基礎過於薄弱而徹底喪失了在委員會選舉中競爭多數席位的能力，再也未能成功發動任何一次佔領攻擊。這項實驗結果有力地證實了經濟安全性機制的核心效能，罰沒機制不僅能夠懲罰單次的惡意行為，更能夠將攻擊失敗的後果轉化為永久性的治理排除，從根本上切斷了漸進式委員會佔領攻擊所依賴的權益累積正反饋循環。

\subsection{攻擊偵測與懲罰效果分析}
\label{sec:attack_frequency}

權益動態的變化最終會具體反映在攻擊事件的發生頻率與處置結果上，本節透過分析兩種架構在不同實驗規模下的攻擊事件記錄，量化評估經濟威懾機制對攻擊者行為的實質影響。需要特別強調的是，本實驗採用最壞情況分析的設計原則，假設攻擊者在每次獲得委員會控制權時都會不顧後果地發動攻擊，藉此驗證防禦機制在極端條件下的偵測與懲罰能力。在實際運作中，理性攻擊者若預見攻擊必然被偵測並遭受罰沒，將選擇不發動攻擊以保全其質押資產，因此本節所記錄的攻擊次數代表的是防禦機制所成功處置的最壞情況，而非系統在正常運作下預期會遭遇的攻擊頻率。

在 300 輪的基礎實驗中，BlockDFL 架構共記錄了 10 次委員會佔領攻擊事件，平均約每 30 輪便會發生一次。這個觀測頻率與第 \ref{sec:committee-size-security} 節的理論預測大致吻合，在惡意節點佔全網 30\% 且委員會規模為 7 的配置下，單輪發生委員會被惡意控制的機率約為 2.4\%，對應於 300 輪訓練中約 7.2 次的期望攻擊次數，實際觀測的 10 次雖略高於期望值但仍在合理的統計波動範圍內。由於 BlockDFL 缺乏事後挑戰機制，這些攻擊事件均未受到任何形式的經濟制裁，攻擊者在成功操控委員會決策後不僅能夠獲取不當的經濟利益，更能夠將這些利益轉化為後續輪次中的權益優勢，形成持續性的治理威脅。

挑戰增強型委員會架構在相同的 300 輪實驗中僅記錄了 2 次攻擊事件，且這 2 次攻擊全部被挑戰者成功偵測並經全網仲裁確認後執行了罰沒制裁。攻擊發生次數的減少主要源於兩個相互強化的因素，其一是先前罰沒事件所造成的權益削減效應，由於惡意節點在遭受罰沒後權益大幅縮水，其在後續輪次被選入委員會的機率隨之降低，從根本上減少了攻擊機會的出現頻率。其二是權益分佈改變對委員會組成機率的影響，隨著惡意節點的相對權益佔比下降，即使被選入委員會，要同時獲得超過三分之二席位的難度也顯著提高。更關鍵的是，在本研究方法中，每一次成功發動的攻擊都被完整偵測並受到懲罰，攻擊者無法從任何一次惡意行為中獲得淨收益，這與 BlockDFL 中攻擊者能夠持續累積不當利益的情況形成鮮明對比。

2000 輪的長期實驗更全面地展現了兩種架構在持久運作下的差異。在 BlockDFL 架構中，惡意節點在整個實驗期間共成功發動了 84 次委員會佔領攻擊，平均每 24 輪便會發生一次安全事件，這個高頻率意味著系統長期處於反覆遭受攻擊的不穩定狀態。本研究方法的表現則呈現截然不同的樣貌，2000 輪中僅發生 5 次攻擊事件，且這 5 次攻擊全部被成功偵測並執行罰沒，沒有任何一次惡意行為能夠逃脫制裁。更值得關注的是這些攻擊事件的時間分佈特徵，5 次攻擊全部集中在實驗的前 909 輪，如前節所述，第 909 輪的罰沒事件導致惡意節點權益暴跌至誠實節點的 22.6\%，在此關鍵轉折點之後的 1091 輪中，攻擊者再也未能成功組織任何一次委員會佔領。這項結果的意涵超越了單純的攻擊頻率統計，它從實證角度證明了經濟安全性機制能夠在系統的長期演化中發揮導向作用，將權益分佈與治理結構引導至「誠實者主導」的穩定均衡狀態。

\subsection{系統穩定性分析}
\label{sec:system_stability}

攻擊頻率的降低與攻擊行為的有效懲罰會自然轉化為整體系統穩定性的提升，雖然系統穩定性並非本研究的核心貢獻焦點，但此指標對於評估防禦機制的實務部署價值仍具有重要的參考意義，本節從系統可用性與模型收斂品質兩個面向進行分析。為了量化攻擊事件對系統運作造成的實質衝擊，本研究定義「最低不可用率」作為評估指標，該指標衡量系統因遭受攻擊而處於效能顯著下降狀態的時間比例。根據實驗過程中的觀測數據，每次成功執行的全棧投毒攻擊會導致模型準確率出現急劇下降，而聯邦學習固有的自我修復機制通常需要約 5 至 25 輪的後續訓練才能使模型效能恢復至正常水平。

採用最為保守的 5 輪恢復期估計進行計算，BlockDFL 在 300 輪實驗中因 10 次攻擊事件而累積產生至少 50 輪的效能下降期間，對應約 16.7\% 的最低不可用率。若採用實際觀測中更為常見的 15 輪恢復期進行估算，不可用率將攀升至 50\% 左右，意味著系統有將近一半的運作時間處於從攻擊中恢復的過程中。本研究方法憑藉僅 2 次攻擊事件的優異記錄，將最低不可用率有效控制在 3.3\% 以下。這種可用性差異在需要持續穩定運作的關鍵任務應用場景中具有重要意義，無論是醫療診斷輔助系統、自動駕駛決策模組、還是金融風險即時評估平台，這些應用不僅對最終模型的準確性有嚴格要求，更需要訓練過程中模型狀態維持高度穩定，頻繁的效能崩潰與恢復週期即使最終能夠收斂至相近的準確率，仍會嚴重損害系統的整體可靠性與服務品質。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/experiments/mnist_results_convergence.png}
    \caption{模型準確率收斂曲線比較}
    \label{fig:convergence_curve}
\end{figure}

在模型收斂品質方面，圖 \ref{fig:convergence_curve} 呈現了兩種架構在 300 輪實驗中的準確率變化軌跡。實驗結束時，本研究方法達成 98.63\% 的最終測試準確率，BlockDFL 則為 98.26\%，兩者差異僅約 0.37 個百分點。這個結果符合預期，因為聯邦學習本身具備顯著的自我修復能力，只要攻擊者無法持續不間斷地佔領委員會，後續輪次中來自誠實節點的正確模型更新便能夠逐步抵銷惡意梯度所造成的參數偏差，引導模型重新收斂至正確的優化方向。從圖中可以清楚觀察到兩種架構在訓練過程穩定性上的差異，BlockDFL 的準確率曲線在多個時間點出現明顯的突發性下降與後續緩慢回升，這些波動精確對應了全棧投毒攻擊所造成的瞬時衝擊以及聯邦學習自我修復機制逐步發揮作用的恢復過程。相較之下，本研究方法的準確率曲線呈現更為平滑且穩定的上升趨勢，這反映了較低攻擊頻率所帶來的訓練過程連續性優勢。

兩種架構最終準確率相近這一現象，恰好印證了本研究在第 \ref{chap:framework} 章所闘述的設計哲學核心觀點。聯邦學習的自癒特性意味著偶發性的模型參數偏差能夠被後續的正常訓練自然修復，因此單純關注模型品質指標並不足以全面評估系統的安全性狀態。真正需要防禦的威脅並非個別輪次中的模型損傷，而是攻擊者透過權益累積機制逐步擴大影響力、最終奪取系統治理權的長期戰略性威脅。本研究方法透過經濟懲罰機制有效阻斷了這種權益累積的正反饋循環，確保系統的治理結構長期維持在誠實節點主導的健康狀態，這才是挑戰增強型委員會架構相對於傳統方法的根本性優勢所在。

\section{本章小結}
\label{sec:eval_summary}

本章透過系統性的最壞情況實驗分析，從權益動態演化、攻擊偵測與懲罰效果、以及系統穩定性三個層面驗證了挑戰增強型委員會架構的防禦效能。實驗設計假設攻擊者在每次獲得委員會控制權時都會執意發動攻擊，藉此檢驗防禦機制在極端條件下的表現，結果顯示所有攻擊嘗試均被成功偵測並執行罰沒制裁，沒有任何惡意行為能夠逃脫經濟懲罰。這項發現的深層意涵在於，理性攻擊者若能預見攻擊必然被偵測並遭受損失，將選擇不發動攻擊以保全質押資產，從而使系統在實務運作中自然趨向穩定均衡，維持第 \ref{sec:efficiency_analysis} 節所分析的 $O(c^2)$ 效率水平。

在經濟安全性機制的核心驗證方面，權益動態分析清楚揭示了兩種架構的本質差異。BlockDFL 中惡意節點能夠穩定維持誠實節點 1.1 至 1.2 倍的權益優勢，這種優勢在 2000 輪的長期實驗中持續存在並轉化為對系統治理的顯著影響力。本研究方法則透過罰沒機制成功打破了權益累積的正反饋循環，惡意節點的權益軌跡呈現「階梯式下降」的特徵，在第 909 輪的關鍵轉折後權益暴跌至誠實節點的 22.6\%，此後的 1091 輪中再無任何成功攻擊的記錄，達成了事實上的永久性治理排除。在攻擊偵測效果方面，兩種架構的差異同樣顯著，300 輪實驗中 BlockDFL 遭受 10 次未受懲罰的攻擊，而本研究方法僅發生 2 次攻擊且全部被偵測並罰沒；2000 輪長期實驗中此對比更為懸殊，BlockDFL 的 84 次對比本研究方法的 5 次，且後者的攻擊全部集中在前 909 輪。這些實驗結果從實證角度印證了第 \ref{sec:incentive_mechanism} 節的理論分析，證明經濟懲罰機制確實能夠重塑攻擊者的決策空間，使誠實行為成為長期均衡下的最優策略選擇。

\end{ZhChapter}