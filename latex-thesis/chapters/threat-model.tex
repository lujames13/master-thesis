\begin{ZhChapter}

\chapter{威脅模型 (Threat Model)}
\label{chap:threat-model}

本章定義本研究所針對的威脅模型，特別聚焦於區塊鏈聯邦學習系統中的「委員會佔領攻擊」(Committee Capture Attack)。如第三章文獻分析所示，現有研究主要關注數據層的惡意客戶端攻擊，而系統性地忽略了共識層的驗證者共謀問題。本章將詳細描述系統模型、攻擊者能力、攻擊向量，並重點定義「漸進式權益佔領攻擊」(Progressive Committee Capture Attack, PCCA)，為後續章節的防禦機制設計提供明確的安全目標。

\section{系統模型與假設}
\label{sec:system_model}

\subsection{網絡模型}

本研究考慮一個去中心化的區塊鏈聯邦學習系統，由以下組件構成：

客戶端集合 $\mathcal{C} = \{c_1, c_2, ..., c_N\}$：共 $N$ 個參與訓練的客戶端，每個客戶端 $c_i$ 持有本地私有數據集 $\mathcal{D}_i$。客戶端負責在本地數據上訓練模型，並提交模型更新 (梯度或權重) 至區塊鏈網絡。

驗證者集合 $\mathcal{V} = \{v_1, v_2, ..., v_M\}$：共 $M$ 個驗證者節點，每個驗證者 $v_j$ 持有一定數量的權益 $s_j$。驗證者負責驗證客戶端提交的更新、執行聚合算法，並通過共識機制將聚合結果記錄上鏈。

委員會選擇機制：在每個訓練輪次 $r$，系統從驗證者集合中選擇一個大小為 $C$ 的委員會 $\mathcal{V}_r \subset \mathcal{V}$。選擇機制基於權益加權隨機抽樣，驗證者 $v_j$ 被選中的機率為：

\begin{equation}
P(v_j \in \mathcal{V}_r) = \frac{s_j}{\sum_{k=1}^{M} s_k}
\end{equation}

這種機制確保權益較高的驗證者有更高機率參與委員會，從而獲得更多獎勵機會。

\subsection{聚合與共識流程}

在每個訓練輪次，系統執行以下流程：

\begin{enumerate}
    \item 本地訓練：客戶端在本地數據上訓練模型，計算模型更新 $\Delta w_i$。
    \item 更新提交：客戶端將更新提交至區塊鏈網絡，等待委員會處理。
    \item 委員會聚合：委員會 $\mathcal{V}_r$ 收集客戶端更新，執行拜占庭魯棒聚合算法 (如 Krum、Trimmed Mean) 計算全局更新 $\Delta w_g$。
    \item 共識驗證：委員會成員通過 BFT 共識協議 (如 PBFT) 對聚合結果達成一致，並將結果記錄上鏈。
    \item 獎勵分配：成功參與聚合的委員會成員獲得獎勵 $R$，平分給所有參與成員。每個成員的權益增加 $\Delta s = R / C$。
\end{enumerate}

\subsection{權益動態機制}

權益在系統中扮演雙重角色：

\begin{itemize}
    \item 選擇權重：權益決定驗證者與其被選入委員會的機率，權益越高，參與機會越多。
    \item 經濟激勵：參與委員會的驗證者獲得獎勵，進一步增加其權益，形成正反饋循環。
\end{itemize}

這種機制設計的初衷是激勵誠實行為：誠實驗證者通過持續參與獲得獎勵，權益不斷增長，從而鞏固其在系統中的影響力。然而，如本章後續所示，這種機制也可能被惡意驗證者利用，通過排他性的獎勵分配實現權益壟斷。

\subsection{系統假設}

本研究基於以下假設：

\begin{itemize}
    \item 網絡假設：網絡為部分同步模型，消息最終會被傳遞，但傳遞延遲有上界。
    \item 密碼學假設：密碼學原語 (如數字簽名、哈希函數) 是安全的，攻擊者無法偽造簽名或碰撞哈希。
    \item 誠實客戶端存在：系統中至少存在一定比例的誠實客戶端，其提交的更新是基於真實數據的正常訓練結果。
    \item 可驗證性假設：聚合結果的正確性可以被驗證。任何節點都可以重新執行聚合算法，驗證委員會提交的結果是否正確。
\end{itemize}

\section{攻擊者模型}
\label{sec:adversary_model}

\subsection{攻擊者類型：理性攻擊者}

本研究考慮的攻擊者為理性攻擊者 (Rational Adversary)，而非傳統的拜占庭攻擊者。兩者的關鍵區別在於動機：

\begin{itemize}
    \item 拜占庭攻擊者：以破壞系統為目標，可能採取任意惡意行為，即使損害自身利益也在所不惜。
    \item 理性攻擊者：以利益最大化為目標，僅在預期收益大於成本時才發動攻擊。如果攻擊的預期收益為負，理性攻擊者不會嘗試作惡。
\end{itemize}

這種區分至關重要，因為它為基於博弈論的防禦機制提供了理論基礎。如果能夠設計激勵機制，使得攻擊的預期收益為負，理性攻擊者將自發地選擇誠實行為，無需依賴傳統的多數誠實假設。

\subsection{攻擊者目標}

理性攻擊者的主要目標包括：

\begin{itemize}
    \item 經濟利益：通過操縱委員會，獨佔訓練獎勵，排擠誠實節點的收益。
    \item 權益壟斷：通過阻止誠實節點的權益增長，逐步提高自身在系統中的權益佔比，最終控制委員會選擇過程。
    \item 網絡控制：當攻擊者的權益佔比足夠高時，可以持續控制委員會，進而控制整個聯邦學習過程，包括模型更新的接受與拒絕。
\end{itemize}

值得注意的是，理性攻擊者的目標不僅僅是短期的經濟收益，更重要的是長期的網絡控制權。這種攻擊不同於傳統的模型投毒攻擊，後者僅影響模型品質，而前者則從根本上顛覆了去中心化系統的安全假設。

\subsection{攻擊者能力}

本研究假設攻擊者具有以下能力：

\begin{itemize}
    \item 節點控制：攻擊者可以控制系統中一定比例的驗證者節點，記為 $f$。在典型場景下，假設 $f \leq 0.3$，即攻擊者控制不超過 30\% 的節點。
    \item 協同作惡：被攻擊者控制的節點可以相互協調，共同執行攻擊策略。例如，當多個惡意節點同時被選入委員會時，它們可以串通一致地投票。
    \item 策略性行為：攻擊者可以根據系統狀態動態調整策略。例如，在權益較低時表現誠實以積累信譽，在獲得委員會多數席位時發動攻擊。
    \item 觀察能力：攻擊者可以觀察區塊鏈上的所有公開信息，包括其他節點的權益、歷史行為、委員會組成等，並據此制定攻擊策略。
\end{itemize}

\subsection{攻擊者限制}

同時，攻擊者受到以下限制：

\begin{itemize}
    \item 密碼學限制：攻擊者無法破解密碼學原語，無法偽造其他節點的簽名或篡改已上鏈的數據。
    \item 算力限制：攻擊者無法控制全網多數節點，無法單獨發動 51\% 攻擊。
    \item 經濟約束：攻擊者受經濟激勵約束，如果攻擊的預期成本大於收益，理性攻擊者不會嘗試攻擊。
    \item 可驗證性：攻擊者無法阻止其他節點驗證聚合結果的正確性。任何節點都可以重新執行聚合算法，檢測委員會是否正確執行協議。
\end{itemize}

\section{攻擊向量分析}
\label{sec:attack_vectors}

區塊鏈聯邦學習系統面臨多層次的安全威脅。本節分析不同層次的攻擊向量，並說明本研究的關注目點。

\subsection{數據層攻擊：已有防禦}

數據層攻擊主要指惡意客戶端通過投毒攻擊破壞模型品質：

\begin{itemize}
    \item 數據投毒 (Data Poisoning)：惡意客戶端在本地訓練時使用被污染的數據集，導致訓練出的模型更新偏離正常分佈。
    \item 模型投毒 (Model Poisoning)：惡意客戶端直接構造惡意的模型更新，而非基於真實訓練過程。
\end{itemize}

針對這類攻擊，現有研究已提出多種拜占庭魯棒聚合算法，如 Krum、Trimmed Mean、Median 等。這些算法通過統計方法識別並過濾異常更新，在一定比例的惡意客戶端存在時仍能保證模型收斂。

然而，這些防禦方法存在一個關鍵假設：執行聚合算法的驗證者是誠實的。如果驗證者本身是惡意的，它們可以選擇不執行這些防禦算法，或者篡改算法的執行結果，從而使數據層的防禦完全失效。

\subsection{共識層攻擊：本研究重點}

共識層攻擊針對的是執行聚合和驗證的委員會本身：

\begin{itemize}
    \item 驗證者共謀 (Verifier Collusion)：多個惡意驗證者協同作惡，共同通過惡意的聚合結果。
    \item 委員會佔領 (Committee Capture)：攻擊者通過操縱委員會選擇機制，逐步增加惡意節點在委員會中的佔比，最終控制委員會。
\end{itemize}

如第三章文獻分析所示，現有區塊鏈聯邦學習研究存在系統性的「驗證層盲點」：約 93\% 的研究假設驗證者是誠實的或滿足誠實多數，僅有極少數研究 (如 KFC) 明確考慮惡意驗證者的場景。

本研究聚焦於共識層攻擊，特別是委員會佔領攻擊。這種攻擊的危險性在於：

\begin{itemize}
    \item 繞過數據層防禦：惡意委員會可以直接接受惡意更新，無需執行 Krum 等防禦算法。
    \item 隱蔽性強：攻擊者在初期表現誠實，不易被檢測，等到權益足夠高時才發動攻擊。
    \item 自我強化：一旦攻擊成功，攻擊者的權益會進一步增加，形成正反饋，使得攻擊越來越容易。
\end{itemize}

\subsection{攻擊層次對比}

表 \ref{tab:attack_comparison} 對比了不同層次攻擊的特徵與現有防禦情況。

\begin{table*}[htbp]
\centering
\caption{攻擊層次對比}
\label{tab:attack_comparison}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
攻擊層次 & 攻擊者 & 攻擊目標 & 現有防禦 & 防禦假設 & 本研究關注 \\ \hline
數據層 & 惡意客戶端 & 模型品質 & Krum, Trimmed Mean & 驗證者誠實 & 否 \\ \hline
共識層 & 惡意驗證者 & 網絡控制 & 誠實多數假設 & 多數驗證者誠實 & 是 \\ \hline
\end{tabular}
\end{table*}

從表中可以看出，數據層攻擊已有成熟的防禦方法，但這些方法依賴於驗證者誠實執行的假設。相比之下，共識層攻擊的防禦仍依賴於誠實多數假設，缺乏針對理性攻擊者的激勵相容機制。

\section{漸進式權益佔領攻擊 (Progressive Committee Capture Attack)}
\label{sec:pcca}

本節詳細定義本研究針對的核心威脅：漸進式權益佔領攻擊 (Progressive Committee Capture Attack, PCCA)。這是一種針對基於權益的委員會選擇機制的隱蔽性攻擊，通過兩階段策略逐步實現網絡控制。

\subsection{攻擊定義}

漸進式權益佔領攻擊是指攻擊者通過以下策略，逐步增加其在系統中的權益佔比，最終控制委員會選擇過程：

\begin{enumerate}
    \item 潛伏階段：攻擊者在初期表現誠實，提交正常的模型更新，積累權益與信譽。
    \item 佔領階段：當攻擊者在委員會中獲得多數席位時，啟動「戰略性餓死」策略，拒絕打包誠實節點的更新，獨佔獎勵。
    \item 權益壟斷：由於誠實節點無法獲得獎勵，其權益停滯；而惡意節點持續獲得獎勵，權益呈指數增長，進一步提高其在未來委員會中的佔比。
\end{enumerate}

這種攻擊的關鍵在於利用了權益機制的正反饋特性：權益高的節點更容易被選入委員會，獲得更多獎勵，進而權益更高。攻擊者通過操縱這一循環，實現權益的指數增長與網絡控制權的轉移。

\subsection{攻擊階段詳述}

\subsubsection{階段一：潛伏階段 (Latent Phase)}

在潛伏階段，攻擊者的目標是積累初始權益並建立信譽，具體策略包括：

\begin{itemize}
    \item 誠實行為：攻擊者控制的節點在被選入委員會時，誠實執行聚合算法，提交正確的聚合結果。
    \item 權益積累：通過誠實參與，攻擊者節點獲得獎勵，權益逐漸增加。
    \item 等待時機：攻擊者持續觀察委員會組成，等待多個惡意節點同時被選入委員會，形成多數席位的時機。
\end{itemize}

潛伏階段的持續時間取決於攻擊者的初始權益佔比與委員會大小。假設攻擊者控制 $f = 0.3$ 的節點，委員會大小 $C = 7$，則攻擊者需要至少 4 個節點被選入委員會才能形成多數。根據超幾何分佈，這種情況發生的機率為：

\begin{equation}
P(\text{多數}) = \sum_{k=\lceil C/2 \rceil}^{\min(fM, C)} \frac{\binom{fM}{k} \binom{(1-f)M}{C-k}}{\binom{M}{C}}
\end{equation}

當 $f = 0.3, C = 7$ 時，這一機率約為 10-15\%，意味著攻擊者平均需要等待 7-10 輪才能獲得一次攻擊機會。

\subsubsection{階段二：佔領階段 (Capture Phase)}

一旦攻擊者在委員會中形成多數，立即啟動佔領階段：

\begin{itemize}
    \item 戰略性餓死 (Strategic Starvation)：惡意委員會拒絕打包誠實節點提交的更新，僅接受攻擊者自身控制的客戶端更新。
    \item 排他性獎勵：由於只有惡意節點的更新被接受，獎勵僅分配給惡意委員會成員，誠實節點無法獲得任何獎勵。
    \item 權益分化：經過一輪攻擊後，惡意節點的平均權益增加 $\Delta s = R / C$，而誠實節點的權益保持不變。隨著攻擊輪次增加，權益差距呈線性擴大。
    \item 循環強化：權益差距擴大後，攻擊者在未來委員會中的佔比進一步提高，獲得攻擊機會的頻率增加，形成自我強化的惡性循環。
\end{itemize}

\subsection{核心機制分析}

PCCA 的成功依賴於三個核心機制：

\subsubsection{機制一：次優更新 (Sub-optimal Update)}

惡意委員會不一定需要提交完全錯誤的聚合結果，而是可以提交「次優更新」：

\begin{itemize}
    \item 選擇性接受：僅接受部分客戶端的更新，排除誠實節點的貢獻。
    \item 偏向性聚合：在執行聚合算法時，給予惡意客戶端更新更高的權重。
\end{itemize}

這種策略的隱蔽性在於，次優更新仍然可能使模型收斂，只是收斂速度較慢或最終準確率較低。在訓練初期，這種差異不易被察覺，使得攻擊者有足夠時間積累權益。

\subsubsection{機制二：戰略性餓死 (Strategic Starvation)}

戰略性餓死是 PCCA 的關鍵策略，其目標不是直接破壞模型，而是通過排他性的獎勵分配阻止誠實節點的權益增長：

\begin{itemize}
    \item 獎勵壟斷：惡意委員會獨佔訓練獎勵，誠實節點即使提交了正常更新，也無法獲得任何收益。
    \item 相對權益下降：雖然誠實節點的絕對權益不變，但其相對權益佔比持續下降，因為惡意節點的權益在不斷增長。
    \item 選擇機率下降：由於委員會選擇基於權益加權，誠實節點被選入委員會的機率逐輪下降，進一步減少其獲得獎勵的機會。
\end{itemize}

\subsubsection{機制三：權益指數增長}

在沒有外部干預的情況下，PCCA 會導致惡意節點的權益呈指數增長：

\begin{itemize}
    \item 初始階段：假設攻擊者初始權益佔比為 $f_0 = 0.3$。
    \item 首次攻擊：當攻擊者首次獲得委員會多數時，獨佔獎勵 $R$，權益增加至 $S_{mal}(1) = S_{mal}(0) + R$。
    \item 循環攻擊：隨著權益增加，攻擊者獲得委員會多數的機率提高，攻擊頻率增加。假設每 $k$ 輪成功攻擊一次，則經過 $t$ 輪後，惡意節點的平均權益為：
\end{itemize}

\begin{equation}
S_{mal}(t) = S_{mal}(0) + \frac{t}{k} \cdot R
\end{equation}

而誠實節點的權益保持 $S_{hon}(t) = S_{hon}(0)$，導致權益比例為：

\begin{equation}
\frac{S_{mal}(t)}{S_{hon}(t)} = \frac{S_{mal}(0) + \frac{t}{k} \cdot R}{S_{hon}(0)}
\end{equation}

隨著 $t$ 增加，這一比例趨向無窮，意味著攻擊者最終將完全控制系統。

\subsection{攻擊效果與影響}

PCCA 對系統造成多層次的破壞：

\begin{itemize}
    \item 模型品質下降：由於惡意委員會可能接受次優更新或排除部分誠實更新，模型收斂速度變慢，最終準確率下降。在極端情況下，如果惡意委員會完全拒絕誠實更新，模型將無法收斂。
    \item 網絡控制權轉移：隨著惡意節點權益佔比的提高，它們在委員會中的佔比也持續上升。最終，攻擊者可以持續控制委員會，完全掌握聯邦學習過程。
    \item 去中心化假設崩潰：區塊鏈聯邦學習的核心價值在於去中心化，避免單點故障與中心化信任。然而，PCCA 通過權益壟斷，實質上將系統重新中心化至攻擊者手中，違背了去中心化的初衷。
    \item 經濟激勵扭曲：誠實節點發現無論如何努力，都無法獲得獎勵，可能選擇退出系統。這進一步降低了誠實節點的佔比，加速了系統的崩潰。
\end{itemize}

\subsection{與傳統攻擊的區別}

PCCA 與傳統的拜占庭攻擊或數據投毒攻擊有本質區別，如表 \ref{tab:comparison_traditional} 所示。

\begin{table*}[htbp]
\centering
\caption{與傳統攻擊的區別}
\label{tab:comparison_traditional}
\begin{tabular}{|l|l|l|}
\hline
特徵 & 傳統攻擊 & PCCA \\ \hline
攻擊目標 & 模型品質 & 網絡控制權 \\ \hline
攻擊者動機 & 破壞 & 利益最大化 \\ \hline
攻擊策略 & 直接投毒 & 漸進式滲透 \\ \hline
隱蔽性 & 低 (立即可檢測) & 高 (初期表現誠實) \\ \hline
自我強化 & 無 & 有 (權益正反饋) \\ \hline
防禦方法 & 數據層防禦 & 需要激勵相容機制 \\ \hline
\end{tabular}
\end{table*}

傳統攻擊可以通過 Krum 等數據層防禦方法應對，但 PCCA 繞過了這些防禦，直接攻擊共識層。這種攻擊的隱蔽性與自我強化特性，使得傳統的誠實多數假設不再可靠。

\section{安全目標}
\label{sec:security_goals}

基於上述威脅模型，本研究的防禦機制需要達成以下安全目標：

\subsection{防止委員會被惡意節點控制}

核心目標：即使攻擊者在某一輪獲得委員會多數席位，也無法持續控制委員會。

具體要求：
\begin{itemize}
    \item 攻擊者無法通過單次成功攻擊獲得長期優勢。
    \item 系統能夠檢測並懲罰惡意委員會的行為。
    \item 懲罰機制足以剝奪攻擊者的作惡能力，防止其再次獲得委員會多數。
\end{itemize}

\subsection{確保誠實節點的權益公平增長}

核心目標：誠實節點通過正常參與系統，能夠持續獲得獎勵，權益穩定增長。

具體要求：
\begin{itemize}
    \item 惡意委員會無法阻止誠實節點獲得應得的獎勵。
    \item 即使在攻擊發生時，誠實節點仍有機制保障其權益不受損害。
    \item 長期來看，誠實節點的權益佔比應保持穩定或增長，而非下降。
\end{itemize}

\subsection{維持模型收斂性與準確性}

核心目標：在存在 PCCA 攻擊的情況下，系統仍能保證模型正常收斂，達到預期準確率。

具體要求：
\begin{itemize}
    \item 防禦機制能夠識別並拒絕次優更新。
    \item 即使部分輪次受到攻擊影響，整體訓練過程仍能收斂。
    \item 最終模型準確率與無攻擊場景相當。
\end{itemize}

\subsection{保持系統的去中心化特性}

核心目標：防禦機制本身不應引入新的中心化風險或信任假設。

具體要求：
\begin{itemize}
    \item 不依賴可信第三方或中心化仲裁者。
    \item 不依賴誠實多數假設，而是基於激勵相容的博弈論機制。
    \item 任何節點都能參與驗證與挑戰，無需特殊權限。
\end{itemize}

\subsection{激勵相容性}

核心目標：使得理性攻擊者的最優策略是誠實行為，而非發動攻擊。

具體要求：
\begin{itemize}
    \item 攻擊的預期收益必須為負，即 $E[\text{Payoff}] = P_{success} \cdot G_{attack} - P_{caught} \cdot L_{slash} < 0$。
    \item 懲罰機制 $L_{slash}$ 必須遠大於潛在收益 $G_{attack}$，使得即使攻擊成功機率較高，預期收益仍為負。
    \item 獎勵機制應激勵誠實行為，使得誠實節點的長期收益高於攻擊者。
\end{itemize}

\section{本章小結}
\label{sec:threat_summary}

本章定義了本研究針對的威脅模型，重點聚焦於區塊鏈聯邦學習系統中的「漸進式權益佔領攻擊」(PCCA)。與傳統的數據層攻擊不同，PCCA 針對的是共識層的驗證者，通過兩階段策略 (潛伏$\rightarrow$佔領) 逐步實現網絡控制權的轉移。

PCCA 的核心機制包括：
\begin{itemize}
    \item 次優更新：惡意委員會提交次優聚合結果，隱蔽性強。
    \item 戰略性餓死：通過排他性獎勵分配，阻止誠實節點權益增長。
    \item 權益指數增長：利用權益機制的正反饋特性，實現權益壟斷。
\end{itemize}

這種攻擊的危險性在於其隱蔽性、自我強化性，以及對去中心化假設的根本性顛覆。現有的數據層防禦方法 (如 Krum) 無法應對這種攻擊，因為它們依賴於驗證者誠實執行的假設。

基於這一威脅模型，本研究提出了五個安全目標：防止委員會控制、確保權益公平增長、維持模型收斂、保持去中心化特性，以及實現激勵相容性。下一章將介紹本研究提出的防禦機制，展示如何通過激勵相容的挑戰與罰沒機制，在不依賴誠實多數假設的前提下，有效防禦 PCCA 攻擊。

\end{ZhChapter}
