\begin{ZhChapter}

\chapter{系統架構設計}
\label{chap:framework-design}

本章詳細描述基於異步審計與即時執行機制的區塊鏈聯邦學習系統架構。針對分散式學習中的效率瓶頸與安全性挑戰，本研究提出一個創新的防禦框架。該框架核心理念在於移除傳統區塊鏈的「確認等待期」，改採「即時執行 (Immediate Execution)」配合「異步審計 (Asynchronous Audit)」或稱「回溯挑戰 (Retrospective Challenge)」。此設計在確保系統活性 (Liveness) 的同時，透過雙層安全假設與嚴格的懲罰機制，實現對惡意行為的有效威懾與究責。

\section{系統架構概覽}
\label{sec:arch_overview}

本節介紹系統的整體架構、核心角色職責以及重構後的工作流程。

\subsection{核心角色定義}

本系統包含四個核心角色，各自承擔不同的職責：

\begin{itemize}
    \item \textbf{訓練者 (Update Provider, UP)}：持有本地數據的參與節點，負責在本地數據集上訓練模型並產生本地更新。訓練者不直接參與共識過程，而是將訓練結果提交給聚合者。
    \item \textbf{聚合者 (Aggregator, AG)}：負責收集多個訓練者的本地更新，執行聚合算法 (如聯邦平均或 Krum)，並產生候選全局更新。聚合者需要質押一定數量的代幣以確保其行為誠實。
    \item \textbf{驗證委員會 (Verifier Committee, VC)}：由質押權重選出的小型委員會，負責對聚合者提交的更新進行即時簽署與上鏈。與傳統方法不同，委員會不進行長時間的等待與繁重的全網共識，而是專注於快速確認。
    \item \textbf{挑戰者 (Challenger / Fisherman)}：任何持有足夠質押的節點都可以擔任挑戰者角色。挑戰者在背景異步監聽鏈上數據，當發現異常 (如輸入數據與聚合結果不符) 時，隨時發起挑戰。
\end{itemize}

\subsection{工作流程重構}

為了極大化訓練效率，本系統移除了傳統的「等待期」，工作流程分為三個主要階段：

\begin{enumerate}
    \item \textbf{提案與共識 (Proposal and Consensus)}：
    \begin{itemize}
        \item 聚合者收集本地更新並計算全域模型。
        \item 委員會對聚合結果進行快速驗證 (如格式檢查、基本範圍檢查) 並簽名。
        \item 更新立即寫入區塊鏈，標記為最終確認 (Finalized)，且下一輪訓練直接基於此新模型開始。此過程實現了訓練流程的零阻塞 (Non-blocking)。
    \end{itemize}
    
    \item \textbf{異步審計 (Asynchronous Audit)}：
    \begin{itemize}
        \item 在更新上鏈後的任意時間 (但在證據過期前，例如若干區塊內)，挑戰者可異步下載鏈上數據進行驗證。
        \item 若挑戰者發現委員會簽署的更新存在數學錯誤或惡意操縱，即可發起挑戰。
    \end{itemize}
    
    \item \textbf{仲裁與懲罰 (Arbitration and Slashing)}：
    \begin{itemize}
        \item 若挑戰被觸發，智能合約將啟動全網仲裁流程。
        \item 全網節點 (或隨機抽選的大型陪審團) 介入進行最終驗證。
        \item 若判定為惡意，系統執行「僅懲罰不回滾 (Slash-Only)」策略：罰沒惡意委員會與聚合者的質押金，但不回滾模型狀態。
    \end{itemize}
\end{enumerate}

\section{異步審計與究責機制}
\label{sec:async_audit}

本節詳細闡述異步審計與究責機制的設計哲學與運作細節，取代傳統的樂觀挑戰窗口機制。

\subsection{即時執行策略}

設計哲學上，本系統區別於金融交易系統對「強一致性 (Strong Consistency)」的追求。聯邦學習作為一種機器學習過程，具有天然的「抗噪性 (Noise Tolerance)」。模型參數的微小偏差通常不會導致災難性後果，且可透過後續訓練修正。

因此，本系統優先保證「活性 (Liveness)」：
\begin{itemize}
    \item \textbf{機制}：只要驗證委員會達成共識，更新即視為有效。模型參數立即更新，所有訓練者基於新模型進行下一輪訓練。
    \item \textbf{優勢}：端到端延遲 (End-to-End Latency) 降至最低，系統運作效率與無防禦的中心化系統幾乎一致。
\end{itemize}

\subsection{異步挑戰流程}

挑戰流程的設計旨在確保任何惡意行為無所遁形，同時避免對正常流程造成干擾。

\begin{enumerate}
    \item \textbf{觸發條件}：挑戰者監控鏈上數據，發現輸入的本地模型哈希值與輸出的聚合結果不一致。
    \item \textbf{挑戰發起}：挑戰者提交挑戰交易並附帶質押金 (Stake)。質押金用於防止濫用挑戰機制的DoS攻擊。
    \item \textbf{仲裁執行 (Arbitration)}：
    \begin{itemize}
        \item 智能合約鎖定相關質押金，並觸發全網仲裁 (Network-wide Arbitration)。
        \item 全網驗證者 (或隨機抽選的大型陪審團) 下載原始數據重新計算聚合結果。
        \item 採用 PBFT 共識機制對仲裁結果進行投票，以獲得最終判決。
    \end{itemize}
\end{enumerate}

\subsection{處置決策：僅懲罰不回滾 (Slash-Only Policy)}

當仲裁認定委員會作惡時，系統採取「僅懲罰不回滾」的處置策略。

\begin{itemize}
    \item \textbf{決策依據}：若選擇回滾模型 (Revert)，將導致基於該惡意模型後續訓練的所有輪次失效，造成巨大的算力浪費與系統停擺。考慮到 FL 算法對雜訊的魯棒性，系統選擇承受單次攻擊的代價以換取無限的執行效率。
    \item \textbf{處理方式}：
    \begin{itemize}
        \item \textbf{執行懲罰}：罰沒惡意委員會成員與聚合者的全額質押金，並將其分配給挑戰者作為獎勵。
        \item \textbf{模型處理}：保留該次 (可能微毒的) 更新。系統依靠 FL 算法自身的自我修正能力，或者由下一輪的誠實更新逐步覆蓋其影響。
    \end{itemize}
    \item \textbf{威懾力}：雖然攻擊者成功注入了一次毒，但其付出了巨額資金損失且被踢出網絡，無法維持長期的多數控制，從而中斷了連續的攻擊鏈 (如 Progressive Committee Capture Attack, PCCA)。
\end{itemize}

\section{安全性保證}
\label{sec:security_guarantee}

本節分析系統的安全性來源，提出雙層信任模型並分析攻擊成本。

\subsection{雙層信任模型 (Two-Tier Trust Model)}

本系統採用混合信任假設，將效率與安全性職責分層：

\begin{itemize}
    \item \textbf{檢測層 (Detection Layer)}：採用 \textbf{1-of-N 誠實假設}。只要全網 $N$ 個節點中，有一個誠實節點 (無論是委員會外的閒置節點還是候補節點) 願意擔任挑戰者，攻擊行為就會被揭露。這極大降低了監督門檻。
    \item \textbf{仲裁層 (Arbitration Layer)}：採用 \textbf{全網 2/3 誠實假設}。當挑戰發起後，最終判決權回歸全網 (或大型陪審團)。假設 $N_{total} > 3f$，即全網誠實節點佔多數。這是區塊鏈系統的標準安全假設。
\end{itemize}

\textbf{邏輯總結}：小委員會 (Small Committee) 負責效率，容忍其可能被短暫收買；大網絡 (Full Network) 負責最終安全與仲裁，因其規模巨大而難以被收買。

\subsection{攻擊成本分析}

在此雙層模型下，攻擊者若想成功發動攻擊且不被懲罰，必須同時滿足以下條件：
\begin{enumerate}
    \item 收買當前輪次的委員會多數，以通過惡意更新。
    \item 收買全網超過 $1/3$ 的節點，以在仲裁階段阻擋共識達成或扭曲判決。
\end{enumerate}

\textbf{結論}：這將攻擊成本從單純收買小委員會的 $O(C)$ 提升到了收買全網節點的 $O(N_{total})$，實現了安全性的顯著擴展。

\section{效率分析}
\label{sec:efficiency_analysis}

本節透過通訊複雜度比較與概率模型分析，論證本系統的高效性與安全性平衡。

\subsection{通訊複雜度公式}

對比三種模式的訊息複雜度 (Message Complexity)：

\begin{itemize}
    \item \textbf{傳統 PBFT (全網驗證)}：需要全網廣播與確認，複雜度為 $O(N^2)$。
    \item \textbf{BlockDFL (固定小委員會)}：僅在委員會內共識，複雜度為 $O(C^2)$，但安全性隨 $C$ 減小而降低。
    \item \textbf{本方案}：
    \begin{itemize}
        \item \textbf{正常情況}：僅需委員會共識，複雜度為 $O(C^2)$。由於有威懾機制，可安全使用極小的 $C$。
        \item \textbf{挑戰情況}：委員會共識加上全網仲裁，複雜度為 $O(C^2) + O(N^2)$。
    \end{itemize}
\end{itemize}

設挑戰發生概率為 $p$。在理性假設下，由於高額懲罰的存在，攻擊者傾向於不攻擊，故 $p \to 0$。
期望通訊複雜度為：
\begin{equation}
E[Comm] = (1-p) \cdot O(C^2) + p \cdot (O(C^2) + O(N^2)) \approx O(C^2)
\end{equation}
這表明在絕大多數時間，系統運行效率與輕量級的小委員會方案一致。

\subsection{委員會大小的概率分析}

為了進一步證明小委員會的安全性，我們使用超幾何分佈 (Hypergeometric Distribution) 進行分析。
目標是計算最小委員會大小 $C$，使得惡意節點佔據委員會多數 ($> C/2$) 的機率 $P_{mal}$ 低於特定閾值 (如 1\%)。

\textbf{參數定義}：
\begin{itemize}
    \item $N$: 驗證者總池大小。
    \item $f$: 網絡中惡意節點的比例 (例如 30\%)。
    \item $X$: 委員會中惡意節點的數量。
\end{itemize}

\textbf{數學模型}：
委員會選舉屬於無放回抽樣，服從超幾何分佈。惡意節點數量 $X$ 的概率質量函數為：
\begin{equation}
P(X = k) = \frac{\binom{fN}{k} \binom{(1-f)N}{C-k}}{\binom{N}{C}}
\end{equation}
惡意節點佔據多數 (即攻擊成功) 的概率 $P_{mal}$ 為 $X \ge \lfloor C/2 \rfloor + 1$ 的累像概率：
\begin{equation}
P(X \ge \lfloor C/2 \rfloor + 1) = \sum_{k=\lfloor C/2 \rfloor + 1}^{C} \frac{\binom{fN}{k} \binom{(1-f)N}{C-k}}{\binom{N}{C}}
\end{equation}

\textbf{分析實例}：
設 $N = 100$, 惡意比例 $f = 0.3$ (即 30 個惡意節點)。不同 $C$ 值下的風險如下：
\begin{itemize}
    \item 若 $C=7$，惡意多數 ($X \ge 4$) 的機率約為 12.6\%。
    \item 若 $C=21$，惡意多數 ($X \ge 11$) 的機率降至約 2.8\%。
    \item 若 $C=35$，惡意多數 ($X \ge 18$) 的機率降至 $< 0.5\%$。
\end{itemize}

\textbf{結論}：即使在 $N$ 較大時，只需要一個相對較小的 $C$ (如 30-40) 即可將被惡意控制的風險控制在 1\% 以下。配合異步審計機制，即使這 1\% 的風險發生，攻擊者也會隨後面臨高額懲罰。這證明了使用小委員會兼顧效率與安全的可行性。

\section{激勵機制}
\label{sec:incentive_mechanism}

激勵機制是維持系統長期安全運行的動力核心。本系統維持基於 Slashing 的獎懲邏輯，但強調資金流向與即時執行的配合。

\begin{itemize}
    \item \textbf{獎勵來源}：系統不依賴額外的增發來支付高額的審計費用，而是透過對違規者的資產沒收 (Slashing) 來支付審計與仲裁成本。
    \item \textbf{動態調整}：若系統長期無挑戰發生，可適當降低挑戰者的質押門檻以鼓勵更多節點參與監聽；若挑戰頻發，則提高質押門檻與懲罰力度。
    \item \textbf{長期收益}：對於誠實節點，參與委員會獲得的區塊獎勵是穩定的預期收益；而對於潛在攻擊者，一次攻擊的收益是有限的 (本次更新的控制權)，但損失是巨大的 (全額質押金)。这种不對稱的風險收益比確保了誠實是經濟上的最優策略。
\end{itemize}

\section{本章小結}

本章提出了一種基於異步審計與即時執行的防禦框架。透過移除傳統的確認等待期，我們最大化了聯邦學習的訓練效率。同時，利用雙層信任模型與超幾何分佈分析，我們證明了小委員會配合異步挑戰機制，能夠在極低的通訊成本下實現等同於全網共識的安全性。這種設計成功解決了區塊鏈聯邦學習中效率與安全的兩難困境。

\end{ZhChapter}
