\begin{ZhChapter}

\chapter{系統架構設計}
\label{chap:framework-design}

本章詳細描述本研究提出的「挑戰增強型委員會架構 (Challenge-Augmented Committee Architecture, CACA)」之系統設計。針對區塊鏈聯邦學習在共識層可能遭遇的安全性挑戰，CACA 引入了「非阻塞式異步挑戰 (Non-blocking Asynchronous Challenge)」機制，旨在解耦系統的「活性 (Liveness)」與「安全性 (Security)」。該框架的核心設計在於採用「即時執行 (Immediate Execution)」配合「異步審計 (Asynchronous Audit)」。基於聯邦學習模型對噪聲的強健性與天然的自癒能力，本架構採取「僅懲罰不回滾 (Slash-only Policy)」的處置策略，在確保系統最高運作效率的前提下，透過嚴格的經濟罰沒機制實現對惡意行為的有效威懾，並建立完善的系統究責體系。

\section{系統架構概覽}
\label{sec:arch_overview}

本系統旨在建立一個具備經濟安全性與執行效率的去中心化學習平台。圖 \ref{fig:caca_arch} 展示了本研究所提出的 Challenge-Augmented Committee Architecture (CACA) 整體運作流程，涵蓋了從角色分配、模型訓練、聚合驗證到潛在挑戰仲裁的完整生命週期。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/utils/Challenge-Augmented-Committee-Architecture.drawio.png}
    \caption{Challenge-Augmented Committee Architecture (CACA) 系統架構與工作流程圖}
    \label{fig:caca_arch}
\end{figure}

\subsection{核心角色定義}

本系統包含四個核心角色，各自承擔不同的職責：

\begin{itemize}
    \item \textbf{訓練者 (Update Provider, UP)}：持有本地私有資料的參與節點。負責在本地進行模型訓練，並將運算出的本地更新 (Local Updates) 提交給選定的聚合者。
    \item \textbf{聚合者 (Aggregator, AG)}：負責收集來自多個訓練者的本地更新，執行初步彙整並生成聚合更新 (Aggregated Updates)，隨後將其作為「提案 (Proposal)」提交給驗證委員會。
    \item \textbf{驗證委員會 (Verifier Committee, VC)}：由質押權重選出的小型委員會。其核心職責是針對多個聚合者提交的提案運行 Krum 評分，並透過 PBFT 共識投票決定其中哪一份定為該輪之全域更新 (Global Update)，隨後將其上鏈。
    \item \textbf{挑戰者 (Challenger)}：任何持有足夠質押的節點均可擔任。挑戰者在背景異步監聽鏈上資料，重新運算 Krum 演算法；若發現委員會選定的全域更新與正確之 Krum 計算結果不符，則發起挑戰。
\end{itemize}

\subsection{工作流程}

本系統之工作流程分為以下階段，旨在兼顧訓練效率與共識公正性：

\begin{enumerate}
    \item \textbf{動態角色抽選}：在每一輪次起始時，區塊鏈根據前一區塊的哈希值 (Hash) 分配該輪角色。抽選機率與節點權益 (Stake) 成正比，且嚴格按照 \textbf{Verifier $\rightarrow$ Aggregator $\rightarrow$ Update Provider} 的順序進行抽選。
    \item \textbf{本地訓練與廣播}：被選定為 UP 的節點使用本地資料進行模型訓練，並將結果傳遞給當輪選定的 Aggregators。
    \item \textbf{提案彙整與提交}：Aggregators 整合接收到的多個 Local Updates，計算出初步的 Aggregated Updates 並提交給 Verifier Committee。
    \item \textbf{委員會驗證與投票}：驗證委員會針對所有收到的聚合提案運行 Krum 演算法進行評分。委員會成員隨後透過 PBFT 共識投票，選出評分最優的提案作為最終的 Global Update。
    \item \textbf{即時更新與獎勵分發}：區塊鏈更新全域模型，並根據貢獻度向 UP、AG 與 VC 成員發放獎勵。此過程為非阻塞式，下一輪訓練將立即基於新模型開始。
    \item \textbf{異步挑戰 (選用階段)}：若挑戰者發現委員會選定的結果與 Krum 運算答案不一致，可質押押金發起挑戰。隨後區塊鏈發起全參與者的 PBFT 仲裁，重新執行 Krum 運算以判定正確答案。
\end{enumerate}

\section{異步審計與究責機制}
\label{sec:async_audit}

\subsection{即時執行策略}

設計哲學上，本系統區別於金融交易系統對「強一致性 (Strong Consistency)」的追求。聯邦學習作為一種機器學習過程，具有天然的「抗噪性 (Noise Tolerance)」。模型參數的微小偏差通常不會導致災難性後果，且可透過後續訓練修正。因此，本系統優先保證「活性 (Liveness)」：

\begin{itemize}
    \item \textbf{機制}：只要驗證委員會達成共識，更新即視為有效。模型參數立即更新，所有訓練者基於新模型進行下一輪訓練。
    \item \textbf{優勢}：端到端延遲 (End-to-End Latency) 降至最低，系統運作效率與無防禦的中心化系統幾乎一致。
\end{itemize}

\subsection{異步挑戰流程}

挑戰流程之核心在於「數學確定性」，確保委員會無法利用資訊不對稱來操縱模型聚合結果。

\begin{enumerate}
    \item \textbf{觸發條件}：挑戰者監控鏈上資料，發現委員會選定的全域更新與對該輪所有聚合提案執行 Krum 運算所得之結果不一致。
    \item \textbf{挑戰發起}：挑戰者提交挑戰交易並繳納質押金，以防止濫用挑戰機制造成的 DoS 攻擊。
    \item \textbf{仲裁執行 (Arbitration)}：
    \begin{itemize}
        \item 智能合約鎖定相關質押金，並調取該輪鏈上緩存的所有聚合提案。
        \item 觸發全網仲裁，全網驗證者重新運算 Krum 演算法並通過 PBFT 共識對仲裁結果進行投票判決。
    \end{itemize}
\end{enumerate}

\subsection{處置決策：僅懲罰不回滾 (Slash-Only Policy)}

當仲裁認定委員會作惡時，系統採取「僅懲罰不回滾」的處置策略。本設計不採用傳統分散式系統的回滾 (Revert) 機制，主要基於以下三點學術考量：

\begin{itemize}
    \item \textbf{決策依據}：
    \begin{enumerate}
        \item \textbf{算力效率與自癒特性}：回滾模型將導致該輪次後的所有訓練失效，造成嚴重的算力與資源浪費。考量到聯邦學習具備顯著的自我修復能力 (Self-healing Capacity)，誠實節點的後續更新能逐步抵銷惡意梯度帶來的噪音。
        \item \textbf{仲裁延遲與模型時效}：全參與者的 PBFT 仲裁機制具備較高的通訊複雜度與延遲。在高度動態的訓練過程中，當仲裁判定成立時，模型往往已透過後續輪次完成了初步自癒；此時若強行回滾，不僅不具時效性，反而會破壞系統的連續性。
        \item \textbf{正規化效應}：從機器學習角度分析，少許非最佳的次優選擇 (Sub-optimal Updates) 可視為向全域模型引入隨機噪音，在特定情境下有助於避免過擬合 (Overfitting) 問題，提升模型的泛化能力。
    \end{enumerate}

    \item \textbf{處理方式}：
    \begin{itemize}
        \item \textbf{執行懲罰}：系統將立即罰沒 (Slash) 惡意委員會成員與聚合者的全額質押金。該筆資金除了作為挑戰者的賞金外，其餘部分將分配給全體誠實參與者作為補償獎勵，以維持激勵相容性。
        \item \textbf{模型處理}：保留受影響的更新紀錄，不執行狀態回退。系統依靠 FL 演算法自身的強健性，由後續輪次的誠實更新逐步覆蓋並修正其影響。
    \end{itemize}

    \item \textbf{威懾力}：透過將安全性由「事前預防」轉向「經濟制裁」，即便攻擊者成功注入一次毒化更新，其代價將是損失巨額資金並被永久移出治理委員會。這種極高且不可逆的作惡成本，足以中斷漸進式委員會佔領攻擊 (PCCA) 的權益正反饋循環，達成長期治理的穩定。
\end{itemize}

\section{安全性保證}
\label{sec:security_guarantee}

本節分析系統的安全性來源，提出雙層信任模型並分析攻擊成本。

\subsection{雙層信任模型 (Two-Tier Trust Model)}

本系統採用混合信任假設，將效率與安全性職責分層：

\begin{itemize}
    \item \textbf{檢測層 (Detection Layer)}：採用 \textbf{1-of-N 誠實假設}。只要全網 $N$ 個節點中，有一個誠實節點 (無論是委員會外的閒置節點還是候補節點) 願意擔任挑戰者，攻擊行為就會被揭露。這極大降低了監督門檻。
    \item \textbf{仲裁層 (Arbitration Layer)}：採用 \textbf{全網 2/3 誠實假設}。當挑戰發起後，最終判決權回歸全網 (或大型陪審團)。假設 $N_{total} > 3f$，即全網誠實節點佔多數。這是區塊鏈系統的標準安全假設。
\end{itemize}

\textbf{邏輯總結}：小委員會 (Small Committee) 負責效率，容忍其可能被短暫收買；大網路 (Full Network) 負責最終安全與仲裁，因其規模巨大而難以被收買。

\subsection{攻擊成本分析}

在此雙層模型下，攻擊者若想成功發動攻擊且不被懲罰，必須同時滿足以下條件：
\begin{enumerate}
    \item 收買當前輪次的委員會超過 2/3 成員，以通過惡意更新。
    \item 收買全網超過 $1/3$ 的節點，以在仲裁階段阻擋共識達成或扭曲判決。
\end{enumerate}

\textbf{結論}：這將攻擊成本從單純收買小委員會的 $O(C)$ 提升到了收買全網節點的 $O(N_{total})$，實現了安全性的顯著擴展。

\section{效率分析}
\label{sec:efficiency_analysis}

本節透過通訊複雜度比較與概率模型分析，論證本系統的高效性與安全性平衡。

\subsection{通訊複雜度公式}

對比三種模式的訊息複雜度 (Message Complexity)：

\begin{itemize}
    \item \textbf{傳統 PBFT (全網驗證)}：需要全網廣播與確認，複雜度為 $O(N^2)$。
    \item \textbf{BlockDFL (固定小委員會)}：僅在委員會內共識，複雜度為 $O(C^2)$，但安全性隨 $C$ 減小而降低。
    \item \textbf{本方案}：
    \begin{itemize}
        \item \textbf{正常情況}：僅需委員會共識，複雜度為 $O(C^2)$。由於有威懾機制，可安全使用極小的 $C$。
        \item \textbf{挑戰情況}：委員會共識加上全網仲裁，複雜度為 $O(C^2) + O(N^2)$。
    \end{itemize}
\end{itemize}

設挑戰發生概率為 $p$。在理性假設下，由於高額懲罰的存在，攻擊者傾向於不攻擊，故 $p \to 0$。
期望通訊複雜度為：
\begin{equation}
E[Comm] = (1-p) \cdot O(C^2) + p \cdot (O(C^2) + O(N^2)) \approx O(C^2)
\end{equation}
這表明在絕大多數時間，系統運行效率與輕量級的小委員會方案一致。

\subsection{委員會大小的概率分析}

為了進一步證明小委員會的安全性，我們使用超幾何分佈 (Hypergeometric Distribution) 進行分析。
目標是運算最小委員會大小 $C$，使得惡意節點佔據委員會超過 2/3 ($> 2C/3$) 的機率 $P_{mal}$ 低於特定閾值 (如 1\%)。

\textbf{參數定義}：
\begin{itemize}
    \item $N$: 驗證者總池大小。
    \item $f$: 網路中惡意節點的比例 (例如 30\%)。
    \item $X$: 委員會中惡意節點的數量。
\end{itemize}

\textbf{數學模型}：
委員會選舉屬於無放回抽樣，服從超幾何分佈。惡意節點數量 $X$ 的概率質量函數為：
\begin{equation}
P(X = k) = \frac{\binom{fN}{k} \binom{(1-f)N}{C-k}}{\binom{N}{C}}
\end{equation}
惡意節點佔據超過 2/3 (即攻擊成功) 的概率 $P_{mal}$ 為 $X \ge \lfloor 2C/3 \rfloor + 1$ 的累積機率：
\begin{equation}
P(X \ge \lfloor 2C/3 \rfloor + 1) = \sum_{k=\lfloor 2C/3 \rfloor + 1}^{C} \frac{\binom{fN}{k} \binom{(1-f)N}{C-k}}{\binom{N}{C}}
\end{equation}

\textbf{分析實例}：
設 $N = 100$, 惡意比例 $f = 0.3$ (即 30 個惡意節點)。不同 $C$ 值下的風險如下：
\begin{itemize}
    \item 若 $C=5$，惡意佔領 ($X \ge 4$) 的機率約為 2.74\%。
    \item 若 $C=7$，惡意佔領 ($X \ge 5$) 的機率約為 2.42\%。
    \item 若 $C=9$，惡意佔領 ($X \ge 7$) 的機率驟降至 0.28\%。
    \item 若 $C=11$，惡意佔領 ($X \ge 8$) 的機率約為 0.25\%。
    \item 若 $C=13$，惡意佔領 ($X \ge 9$) 的機率約為 0.21\%。
\end{itemize}

\textbf{結論}：即使在 $N$ 較大時，只需要一個極小的 $C$ (如 9) 即可將被惡意控制的風險控制在 1\% 以下。配合異步審計機制，即使這 1\% 的風險發生，攻擊者也會隨後面臨高額懲罰。這證明了使用小委員會兼顧效率與安全的可行性。

\section{激勵機制}
\label{sec:incentive_mechanism}

激勵機制是維持系統長期安全運行的動力核心。本系統維持基於 Slashing 的獎懲邏輯，但強調資金流向與即時執行的配合。

\begin{itemize}
    \item \textbf{獎勵來源}：系統不依賴額外的增發來支付高額的審計費用，而是透過對違規者的資產罰沒 (Slashing) 來支付審計與仲裁成本。
    \item \textbf{動態調整}：若系統長期無挑戰發生，可適當降低挑戰者的質押門檻以鼓勵更多節點參與監聽；若挑戰頻發，則提高質押門檻與懲罰力度。
    \item \textbf{長期收益}：對於誠實節點，參與委員會獲得的區塊獎勵是穩定的預期收益；而對於潛在攻擊者，一次攻擊的收益是有限的 (本次更新的控制權)，但損失是巨大的 (全額質押金)。这种不對稱的風險收益比確保了誠實是經濟上的最優策略。
\end{itemize}

\section{本章小結}

本章提出了一種基於異步審計與即時執行的防禦框架。透過移除傳統的確認等待期，我們最大化了聯邦學習的訓練效率。同時，利用雙層信任模型與超幾何分佈分析，我們證明了小委員會配合異步挑戰機制，能夠在極低的通訊成本下實現等同於全網共識的安全性。這種設計成功解決了區塊鏈聯邦學習中效率與安全的兩難困境。

\end{ZhChapter}
