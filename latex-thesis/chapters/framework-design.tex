\begin{ZhChapter}

\chapter{系統架構設計}
\label{chap:framework-design}

本章詳細描述基於激勵相容機制的區塊鏈聯邦學習系統架構。針對第四章提出的委員會捕獲攻擊威脅，本研究提出一個創新的防禦框架，該框架通過樂觀挑戰機制和內部懲罰獎勵系統，在不犧牲系統效率的前提下提供強安全性保證。

\section{系統架構概覽}
\label{sec:arch_overview}

本節介紹系統的整體架構和核心設計理念。

\subsection{核心角色定義}

本系統包含四個核心角色，各自承擔不同的職責：

\begin{itemize}
    \item \textbf{訓練者 (Trainer)}：持有本地數據的參與節點，負責在本地數據集上訓練模型並產生本地更新。訓練者不直接參與共識過程，而是將訓練結果提交給聚合者。
    \item \textbf{聚合者 (Aggregator)}：負責收集多個訓練者的本地更新，執行聚合算法 (如聯邦平均或 Krum)，並產生候選全局更新。聚合者需要質押一定數量的代幣以確保其行為誠實。
    \item \textbf{驗證委員會 (Verifier Committee)}：由質押權重選出的小型委員會，負責對聚合者提交的更新進行快速驗證和共識。委員會採用拜占庭容錯共識協議達成一致。
    \item \textbf{挑戰者 (Challenger)}：任何持有足夠質押的節點都可以擔任挑戰者角色。挑戰者監控已確認的更新，當發現可疑更新時可以提出挑戰，觸發全網驗證。
\end{itemize}

\subsection{基本工作流程}

系統的基本工作流程分為四個階段：

\begin{enumerate}
    \item \textbf{階段一：訓練與聚合}。訓練者在本地數據上訓練模型，產生本地更新並提交給聚合者。聚合者收集足夠數量的本地更新後，執行聚合算法產生候選全局更新。
    \item \textbf{階段二：樂觀驗證}。驗證委員會對候選更新進行快速驗證。驗證過程採用樂觀執行策略，即預設更新有效，委員會主要驗證聚合過程的形式正確性和基本合理性。驗證通過後，更新被標記為「暫時確認」狀態。
    \item \textbf{階段三：挑戰窗口}。暫時確認的更新進入挑戰窗口期 (例如 10 個區塊)。在此期間，任何節點都可以提出挑戰。若挑戰窗口期結束仍無挑戰，更新被標記為「最終確認」狀態。
    \item \textbf{階段四：挑戰驗證 (條件觸發)}。若有節點提出挑戰，系統觸發全網驗證流程。所有驗證節點重新執行聚合算法，將結果與原始更新比對。若發現不一致，原驗證委員會被懲罰，挑戰者獲得獎勵；若一致，挑戰者損失挑戰質押。
\end{enumerate}

\subsection{設計理念}

本系統的設計基於以下三個核心理念：

\begin{itemize}
    \item \textbf{樂觀執行優先}。在大多數情況下，參與者是誠實的。因此系統採用樂觀執行策略，預設更新有效，不阻塞訓練流程。這確保了系統在正常情況下的高效運行。
    \item \textbf{事後問責機制}。安全性不依賴於事前的多數誠實假設，而是通過事後的挑戰和懲罰機制來保證。任何惡意行為都可以在事後被檢測和懲罰，這使得系統能夠容忍更高比例的惡意節點。
    \item \textbf{激勵相容設計}。通過精心設計的經濟激勵，使得理性節點的最優策略是誠實行為。攻擊的預期收益為負，因此理性攻擊者不會發動攻擊。這將攻擊者的貪婪轉化為系統的防禦力量。
\end{itemize}

\subsection{與傳統方法的對比}

傳統的區塊鏈聯邦學習系統 (如 BlockDFL) 主要依賴「誠實多數」假設來保證安全性。這種方法存在兩個關鍵問題：首先，為了抵抗共謀攻擊，必須維持較大的委員會規模，這導致通訊複雜度為 $O(C^2)$，其中 $C$ 是委員會大小。其次，當惡意節點通過策略性飢餓攻擊逐步增加質押權重時，系統無法有效防禦。

相較之下，本系統將安全性和活性 (liveness) 解耦。活性由小型委員會保證，通訊複雜度維持在 $O(C_{small}^2)$ 的低水平。安全性則由挑戰機制和經濟懲罰保證，不依賴於委員會規模。這種設計實現了效率與安全性的雙贏。

\section{樂觀挑戰機制}
\label{sec:optimistic_challenge}

本節詳細說明樂觀執行和挑戰機制的設計。

\subsection{樂觀執行流程}

樂觀執行的核心思想是「先執行，後驗證」。具體流程如下：

當聚合者提交候選更新時，驗證委員會不需要重新執行完整的聚合計算，而是進行輕量級驗證。驗證內容包括：聚合者是否收集了足夠數量的本地更新、更新格式是否正確、更新數值是否在合理範圍內等。

這種輕量級驗證的計算複雜度遠低於完整的聚合計算。例如，若使用 Krum 聚合算法，完整執行需要計算所有更新之間的成對距離，複雜度為 $O(n^2)$，其中 $n$ 是訓練者數量。而輕量級驗證只需檢查格式和基本統計特性，複雜度為 $O(n)$。

驗證通過後，更新被寫入區塊鏈並標記為「暫時確認」狀態。此時，訓練者可以立即使用該更新繼續下一輪訓練，不需要等待挑戰窗口期結束。這確保了訓練流程不被阻塞。

\subsection{挑戰者角色與動機}

任何持有足夠質押的節點都可以擔任挑戰者。挑戰者的主要動機有兩種：

\begin{itemize}
    \item \textbf{經濟動機}：成功的挑戰可以獲得來自惡意委員會的懲罰獎勵。這種「賞金獵人」機制吸引理性節點主動監控系統安全。
    \item \textbf{防禦動機}：被策略性飢餓攻擊的誠實節點有強烈動機提出挑戰。當誠實節點發現自己長期未被選入委員會或未獲得獎勵時，可以通過挑戰機制揭露惡意委員會的不當行為，恢復公平的獎勵分配。
\end{itemize}

這種雙重動機確保了系統中始終存在足夠的監督力量。即使大部分節點是被動的，只要存在少數主動的挑戰者，系統安全性就能得到保證。

\subsection{挑戰流程設計}

挑戰流程包含以下步驟：

\begin{enumerate}
    \item \textbf{步驟一：挑戰提交}。挑戰者選定一個處於挑戰窗口期的更新，提交挑戰交易。挑戰交易必須包含挑戰質押，質押金額需足以支付全網驗證的計算成本。這個設計防止了惡意挑戰者通過大量無效挑戰來癱瘓系統。
    \item \textbf{步驟二：全網驗證觸發}。智能合約接收到挑戰交易後，觸發全網驗證流程。所有驗證節點 (或隨機選出的大型驗證委員會) 被要求重新執行聚合算法。
    \item \textbf{步驟三：驗證執行}。驗證節點從區塊鏈上讀取原始的本地更新數據，在本地重新執行聚合算法 (如 Krum)，產生驗證結果。
    \item \textbf{步驟四：結果比對與判定}。智能合約收集驗證節點的結果，採用多數投票機制達成最終判定。若多數驗證節點的結果與原始更新不一致，則判定挑戰成功；否則判定挑戰失敗。
    \item \textbf{步驟五：獎懲執行}。若挑戰成功，原驗證委員會的質押被罰沒 (slashing)，其中一部分分配給挑戰者作為獎勵，一部分分配給參與驗證的節點作為計算補償，剩餘部分銷毀。若挑戰失敗，挑戰者的挑戰質押被罰沒，用於補償參與驗證的節點。
\end{enumerate}

\subsection{挑戰窗口期設計}

挑戰窗口期的長度需要在兩個目標之間平衡：

\begin{itemize}
    \item \textbf{足夠長以允許挑戰}。挑戰者需要時間來檢測可疑更新、準備挑戰證明、提交挑戰交易。若窗口期過短，誠實挑戰者可能來不及反應。
    \item \textbf{足夠短以保證最終性}。訓練流程需要確定性的全局更新才能繼續。若窗口期過長，會延遲訓練進度。
\end{itemize}

基於實際的區塊鏈出塊時間和計算能力，建議挑戰窗口期設置為 10-20 個區塊。以以太坊為例，出塊時間約 12 秒，則窗口期為 2-4 分鐘。這個時間足以讓自動化的監控程序檢測異常並提交挑戰。

\subsection{與傳統同步驗證的對比}

傳統的同步驗證方法要求所有驗證節點在每次更新時都執行完整的聚合計算。這種方法的優點是安全性高，但存在嚴重的效率問題：

\begin{itemize}
    \item \textbf{計算冗餘}：若有 $C$ 個驗證節點，則相同的聚合計算被重複執行 $C$ 次，造成 $C$ 倍的計算資源浪費。
    \item \textbf{通訊開銷}：所有驗證節點都需要接收完整的本地更新數據，通訊複雜度為 $O(C \cdot n)$，其中 $n$ 是訓練者數量。
    \item \textbf{延遲增加}：必須等待所有驗證節點完成計算並達成共識後，訓練才能繼續，這增加了每輪訓練的延遲。
\end{itemize}

相較之下，樂觀挑戰機制在正常情況下 (無挑戰發生) 只需要輕量級驗證，計算 and 通訊開銷都大幅降低。只有在異常情況下 (挑戰發生) 才觸發完整驗證，而這種情況的發生概率 $p$ 通常很小 (在激勵相容的設計下，理性攻擊者不會發動攻擊)。因此，系統的平均計算開銷為 $O(C \cdot n \cdot p)$，遠低於傳統方法的 $O(C \cdot n)$。

\section{激勵機制設計}
\label{sec:incentive_design}

本節說明如何通過經濟激勵確保系統安全性。

\subsection{內部懸賞系統}

本系統的核心創新在於「內部懸賞」機制。與傳統的外部激勵 (如通貨膨脹或基金會補貼) 不同，本系統的獎勵完全來自於惡意行為者的懲罰。

\begin{itemize}
    \item \textbf{懲罰機制 (Slashing)}：當驗證委員會被證明提交了錯誤的更新時，其質押的代幣被罰沒。罰沒比例設置為質押金額的較大比例 (如 50\%-100\%)，以產生足夠的威慑力。
    \item \textbf{獎勵分配}：被罰沒的代幣按以下比例分配：
    \begin{itemize}
        \item 挑戰者獎勵：40\%，作為成功挑戰的賞金
        \item 驗證者補償：30\%，分配給參與全網驗證的節點，補償其計算成本
        \item 系統銷毀：30\%，永久銷毀以減少代幣總供應量
    \end{itemize}
\end{itemize}

這種設計的關鍵優勢在於自我維持性。系統不需要外部資金來源，懲罰本身產生了足夠的獎勵來激勵監督行為。這使得系統在長期運行中保持激勵的可持續性。

\subsection{激勵相容性分析}

激勵相容性是指系統設計使得參與者的最優策略與系統目標一致。本系統通過以下分析確保激勵相容：

\begin{enumerate}
    \item \textbf{理性攻擊者的決策模型}：假設攻擊者是理性的經濟人，追求預期收益最大化。攻擊者在決定是否發動攻擊時，會比較攻擊的預期收益與預期成本。
    \item \textbf{攻擊的潛在收益 $G_{attack}$ 包括}：
    \begin{itemize}
        \item 通過提交次優更新獲得的獨佔獎勵
        \item 通過操縱模型可能獲得的外部收益 (如市場操縱)
    \end{itemize}
    \item \textbf{攻擊的預期成本}為 $P_{catch} \times L_{slash}$，其中 $P_{catch}$ 是被抓到的概率，$L_{slash}$ 是懲罰金額。
\end{enumerate}

在本系統的「1-of-N」挑戰模型下，只要存在至少一個誠實且有能力的挑戰者，$P_{catch} \approx 1$。這是因為挑戰者可以獨立驗證更新的正確性，不需要依賴其他節點。

因此，理性攻擊者的預期收益為：
$Expected Payoff = G_{attack} - P_{catch} \times L_{slash} \approx G_{attack} - L_{slash}$

只要設置 $L_{slash} \gg G_{attack}$，預期收益為負，理性攻擊者就不會發動攻擊。

\subsection{參數設計}

為了實現激勵相容，系統參數需要滿足以下約束：

\begin{itemize}
    \item \textbf{Slashing 比例}：設驗證委員會每個成員的質押金額為 $S$，委員會大小為 $C$。若攻擊成功，委員會可能獲得的獎勵約為 $R$ (一輪訓練的總獎勵)。為了使攻擊無利可圖，需要：
    $Slashing Amount = \alpha \times S \times C \gg R$
    其中 $\alpha$ 是 slashing 比例。合理的設置是 $\alpha = 0.5, S = 10R/C$，則 $Slashing Amount = 5R \gg R$。

    \item \textbf{挑戰質押要求}：挑戰者需要質押的金額應足以支付全網驗證的成本，但不應過高以免阻礙誠實挑戰。設全網驗證需要 $N$ 個驗證節點，每個節點的計算成本為 $c$，則挑戰質押應設為：
    $Challenge Stake = N \times c \times (1 + \beta)$
    其中 $\beta$ 是安全邊際 (如 0.2)。若挑戰失敗，該質押被罰沒並用於補償驗證節點。

    \item \textbf{最小質押要求}：為了防止女巫攻擊 (Sybil Attack)，系統要求所有參與者 (聚合者、驗證者、挑戰者) 都必須質押最小金額。該金額應足夠高以使得創建大量女巫身份的成本超過潛在收益。
\end{itemize}

\subsection{與傳統誠實多數假設的對比}

傳統的區塊鏈聯邦學習系統依賴「誠實多數」假設，即假設驗證委員會中超過 2/3 的成員是誠實的。這種假設存在兩個問題：

\begin{itemize}
    \item \textbf{靜態假設的脆弱性}：誠實多數假設是靜態的，無法應對動態的攻擊策略。如第四章所述的策略性飢餓攻擊，可以使惡意節點的質押權重逐步增長，最終突破誠實多數的閾值。
    \item \textbf{缺乏經濟理性基礎}：誠實多數假設沒有考慮節點的經濟動機。在現實中，節點可能因為經濟利益而選擇共謀，特別是當攻擊收益遠超過誠實行為的收益時。
\end{itemize}

相較之下，本系統基於「理性節點」假設，這是一個更弱且更現實的假設。系統不要求節點天生誠實，而是通過經濟激勵使得誠實行為成為理性選擇。這種「Security by Deterrence」(威懾安全) 的範式比「Security by Majority」(多數安全) 更加穩健。

\section{安全性保證分析}
\label{sec:security_analysis}

本節從理論角度分析系統的安全性保證。

\subsection{安全性不等式}

系統的安全性基於以下核心不等式：
$L_{slash} \gg G_{attack}$

其中 $L_{slash}$ 是攻擊失敗時的損失 (slashing 懲罰)，$G_{attack}$ 是攻擊成功時的潛在收益。

詳細推導如下。設驗證委員會由 $C$ 個成員組成，每個成員質押金額為 $S$。若委員會共謀提交錯誤更新，被挑戰成功後，總損失為：
$L_{slash} = \alpha \times S \times C$
其中 $\alpha$ 是 slashing 比例 (如 0.5)。

攻擊的潛在收益包括兩部分：
\begin{enumerate}
    \item 直接收益：通過獨佔獎勵獲得的額外收益。在正常情況下，獎勵 $R$ 會分配給所有誠實參與者。若惡意委員會排除誠實節點，獨佔獎勵，則額外收益約為 $R$。
    \item 間接收益：通過操縱模型可能獲得的外部收益，記為 $G_{ext}$。這取決於具體應用場景，可能包括市場操縱、競爭優勢等。
\end{enumerate}

因此，總收益為：
$G_{attack} = R + G_{ext}$

為了確保安全性，需要：
$\alpha \times S \times C \gg R + G_{ext}$

在實際設計中，可以設置 $S = 10R/C, \alpha = 0.5$，則：
$L_{slash} = 0.5 \times 10R/C \times C = 5R$

若假設 $G_{ext} \leq 4R$ (這對大多數應用是合理的)，則 $L_{slash} = 5R > G_{attack} = R + G_{ext}$，滿足安全性條件。

\subsection{1-of-N 安全模型}

本系統'的安全性基於「1-of-N」模型，即只要 $N$ 個節點中存在至少 1 個誠實且有能力的挑戰者，系統就是安全的。

這個模型的關鍵在於挑戰的獨立性。與傳統的多數投票不同，挑戰者不需要與其他節點協調或達成共識。任何單個挑戰者都可以獨立驗證更新的正確性，並提出挑戰。

因此，被抓到的概率 $P_{catch}$ 可以表示為：
$P_{catch} = 1 - (1 - p_{hon})^N$
其中 $p_{hon}$ 是單個節點誠實且有能力的概率，$N$ 是潛在挑戰者的數量。

即使 $p_{hon}$ 很小 (如 0.1)，只要 $N$ 足夠大 (如 $N = 100$)，$P_{catch}$ 也接近 1：
$P_{catch} = 1 - (1 - 0.1)^{100} = 1 - 0.9^{100} \approx 0.99997$

這意味著攻擊幾乎必然被檢測到。在這種情況下，理性攻擊者的預期收益為：
$Expected Payoff = G_{attack} - P_{catch} \times L_{slash} \approx G_{attack} - L_{slash} < 0$

因此，理性攻擊者不會發動攻擊。

\subsection{信任假設層級提升}

根據現有文獻的分析，區塊鏈聯邦學習系統可以按信任假設分為六個層級：

\begin{itemize}
    \item Level 1：完全信任中心化服務器
    \item Level 2：信任聯邦成員誠實
    \item Level 3：信任驗證者誠實多數 ($>2/3$)
    \item Level 4：信任驗證者誠實少數 ($>1/3$)
    \item Level 5：信任驗證者理性 (無共謀)
    \item Level 6：信任驗證者理性 (允許共謀但有經濟懲罰)
\end{itemize}

傳統的區塊鏈聯邦學習系統 (如 BlockDFL) 運行在 Level 3，即假設驗證委員會中超過 2/3 的成員是誠實的。這個假設在面對策略性攻擊時是脆弱的。

本系統運行在 Level 6，即允許驗證者共謀，但通過經濟懲罰機制使得共謀行為無利可圖。這是一個更弱的信任假設，因為它不要求節點天生誠實，只要求節點是理性的經濟人。

這種信任假設的提升顯著增強了系統的安全性。即使在極端情況下 (如所有驗證委員會成員都是惡意的)，只要存在至少一個理性的挑戰者，系統仍然是安全的。

\subsection{攻擊成本分析}

從攻擊者的角度分析，要成功攻擊本系統需要滿足以下條件：

\begin{enumerate}
    \item \textbf{控制驗證委員會}：攻擊者需要在某一輪中控制驗證委員會的多數席位。這需要累積足夠的質押權重，成本為 $O(S \times C)$。
    \item \textbf{阻止所有挑戰者}：攻擊者需要確保沒有任何節點提出挑戰。在 1-of-N 模型下，這需要控制或賄賂所有 $N$ 個潛在挑戰者，成本為 $O(N \times Bribe)$。
\end{enumerate}

即使攻擊成功，收益也只是一輪訓練的獎勵 $R$ 加上可能的外部收益 $G_{ext}$。而攻擊失敗的損失是 $L_{slash} = \alpha \times S \times C$。

因此，攻擊的成本效益比為：
$Cost/Benefit = (S \times C + N \times Bribe) / (R + G_{ext})$

在合理的參數設置下 (如 $S = 10R/C$)，這個比值遠大於 1，使得攻擊在經濟上不可行。

\section{效率分析}
\label{sec:efficiency_analysis}

本節分析系統的效率特性，並與傳統方法進行對比。

\subsection{安全性與活性解耦}

傳統的區塊鏈聯邦學習系統將安全性和活性 (liveness) 耦合在一起，都依賴於驗證委員會。這導致了一個兩難困境：

\begin{itemize}
    \item 若委員會規模 $C$ 較小 (如 $C = 7$)，系統具有高效率 (低通訊開銷、低延遲)，但安全性較弱，容易受到共謀攻擊。
    \item 若委員會規模 $C$ 較大 (如 $C = 100$)，系統具有高安全性 (難以共謀)，但效率較低，通訊複雜度為 $O(C^2)$。
\end{itemize}

本系統通過挑戰機制實現了安全性與活性的解耦：

\begin{itemize}
    \item \textbf{活性保證}：由小型驗證委員會 (如 $C = 7$) 負責快速達成共識，確保訓練流程不被阻塞。委員會的主要職責是保證系統的 liveness，而非 security。
    \item \textbf{安全性保證}：由挑戰機制和經濟懲罰負責。安全性不依賴於委員會規模，而是依賴於懲罰的威懾力和挑戰者的存在。
\end{itemize}

這種解耦設計使得系統可以同時實現高效率和高安全性，打破了傳統的效率-安全性權衡。

\subsection{通訊複雜度分析}

通訊複雜度是衡量區塊鏈聯邦學習系統效率的關鍵指標。本節分析不同方法的通訊複雜度。

傳統方法 (BlockDFL)：
\begin{itemize}
    \item 委員會內共識：$O(C^2)$，其中 $C$ 是委員會大小
    \item 若要提高安全性，需增大 $C$，則複雜度增長為 $O(C^2_{large})$
\end{itemize}

本方法：
\begin{itemize}
    \item 正常情況 (無挑戰)：$O(C^2_{small})$，其中 $C_{small}$ 是小型委員會大小 (如 7)
    \item 挑戰情況：$O(N^2)$，其中 $N$ 是參與全網驗證的節點數
    \item 平均複雜度：$O(C^2_{small} + p \times N^2)$，其中 $p$ 是挑戰發生概率
\end{itemize}

關鍵觀察：在激勵相容的設計下，理性攻擊者不會發動攻擊，因此 $p \approx 0$。即使考慮誤報或非理性行為，$p$ 也應該很小 (如 $p < 0.01$)。

定量對比：
\begin{itemize}
    \item BlockDFL (高安全性配置)：$O(100^2) = O(10,000)$
    \item 本方法：$O(7^2 + 0.01 \times 100^2) = O(49 + 100) = O(149)$
    \item 效率提升：約 67 倍
\end{itemize}

這個巨大的效率提升來自於兩個因素：委員會規模的縮減 (100 $\rightarrow$ 7) 和挑戰的低頻率 ($p \approx 0.01$)。

\subsection{計算開銷分析}

計算開銷主要來自於聚合算法的執行。以 Krum 算法為例，其複雜度為 $O(n^2)$，其中 $n$ 是訓練者數量。

傳統同步驗證方法：
\begin{itemize}
    \item 每個驗證節點都執行完整的 Krum 算法
    \item 總計算量：$C \times O(n^2)$
\end{itemize}

本方法：
\begin{itemize}
    \item 正常情況：只有聚合者執行 Krum，驗證委員會執行輕量級驗證
    \item 聚合者計算量：$O(n^2)$
    \item 驗證委員會計算量：$O(n)$ (僅檢查格式和基本統計)
    \item 總計算量：$O(n^2) + C \times O(n) \approx O(n^2)$
    \item 挑戰情況：$N$ 個驗證節點執行 Krum
    \item 總計算量：$N \times O(n^2)$
    \item 平均計算量：$O(n^2) + p \times N \times O(n^2) = O((1 + p \times N) \times n^2)$
\end{itemize}

定量對比 ($C = 100, N = 100, n = 1000, p = 0.01$)：
\begin{itemize}
    \item 傳統方法：$100 \times O(1,000,000) = O(100,000,000)$
    \item 本方法：$(1 + 0.01 \times 100) \times O(1,000,000) = 2 \times O(1,000,000) = O(2,000,000)$
    \item 效率提升：約 50 倍
\end{itemize}

\subsection{端到端延遲分析}

端到端延遲是指從訓練者提交本地更新到全局更新被最終確認的時間。

傳統方法總延遲：$T_{agg} + T_{verify} + T_{consensus}$

本方法 (正常情況)：
\begin{itemize}
    \item 總延遲 (訓練視角)：$T_{agg} + T_{light} + T_{consensus}$
    \item 總延遲 (最終確認視角)：$T_{agg} + T_{light} + T_{consensus} + T_{window}$
\end{itemize}

關鍵觀察：從訓練流程的角度，本方法的延遲為 $T_{agg} + T_{light} + T_{consensus}$，由於 $T_{light} \ll T_{verify}$，這顯著低於傳統方法。雖然最終確認需要額外的 $T_{window}$，但這不影響訓練的進行。

\subsection{與 BlockDFL 的定量對比}

表 \ref{tab:comparison_blockdfl} 總結了本方法與 BlockDFL 在各項指標上的對比。

\begin{table*}[htbp]
\centering
\caption{與 BlockDFL 的定量對比}
\label{tab:comparison_blockdfl}
\begin{tabular}{|l|l|l|l|}
\hline
指標 & BlockDFL & 本方法 & 改進 \\ \hline
信任假設 & Level 3: 誠實多數 ($>2/3$) & Level 6: 理性節點 & 更強 \\ \hline
委員會角色 & 安全性 + 活性 (耦合) & 活性 (解耦) & 更靈活 \\ \hline
委員會規模 & 需增大以提高安全性 & 可保持最小 & 更高效 \\ \hline
通訊複雜度 & $O(C^2_{large})$ & $O(C^2_{small})$ & $\sim$67 倍 \\ \hline
計算複雜度 & $O(C \times n^2)$ & $O((1+p \times N) \times n^2)$ & $\sim$50 倍 \\ \hline
共謀抵抗性 & 小委員會時脆弱 & 小委員會時仍強健 & 顯著提升 \\ \hline
訓練延遲 & $T_{agg} + T_{verify} + T_{consensus}$ & $T_{agg} + T_{light} + T_{consensus}$ & 降低 \\ \hline
\end{tabular}
\end{table*}

\section{系統實現細節}
\label{sec:implementation_details}

本節說明關鍵技術細節和實現考量。

\subsection{智能合約架構}

系統的核心邏輯通過三個智能合約實現：

\begin{itemize}
    \item \textbf{質押管理合約 (StakeManager)}：管理所有參與者的質押、解質押、獎勵分配。
    \item \textbf{更新管理合約 (UpdateManager)}：管理全局更新的提交、驗證、確認。
    \item \textbf{挑戰管理合約 (ChallengeManager)}：管理挑戰的提交、驗證、判定。
\end{itemize}

\subsection{鏈上與鏈下計算分工}

為了平衡安全性和效率，系統採用鏈上鏈下混合架構：

鏈上計算 (智能合約執行)：
\begin{itemize}
    \item 質押和解質押邏輯
    \item 委員會選擇 (基於質押權重的隨機選擇)
    \item 投票和共識邏輯
    \item 懲罰和獎勵分配
    \item 挑戰判定 (基於驗證節點的投票)
\end{itemize}

鏈下計算 (節點本地執行)：
\begin{itemize}
    \item 模型訓練 (在本地數據上)
    \item 聚合算法執行 (如 Krum)
    \item 挑戰驗證 (重新執行聚合算法)
    \item 更新的存儲和傳輸
\end{itemize}

\subsection{委員會選擇算法}

委員會選擇採用基於質押權重的可驗證隨機函數 (Verifiable Random Function, VRF)。

\textbf{算法 5.1：委員會選擇}

\begin{enumerate}
    \item $seed = VRF(round)$ // 使用 VRF 生成隨機種子
    \item $totalStake = sum(stake_i)$
    \item $committee = []$
    \item for $j = 1$ to $C$:
    \item \quad $r = Random(seed, j) \pmod{totalStake}$ // 生成 $[0, totalStake)$ 範圍的隨機數
    \item \quad $accumulatedSum = 0$
    \item \quad for each $node_i$:
    \item \qquad $accumulatedSum += stake_i$
    \item \qquad if $accumulatedSum > r$:
    \item \quad \qquad $committee.append(node_i)$
    \item \quad \qquad break
    \item return $committee$
\end{enumerate}

\subsection{挑戰驗證算法}

當挑戰被提交後，系統觸發以下驗證流程：

\textbf{算法 5.2：挑戰驗證}

\begin{enumerate}
    \item // 階段一：重新執行聚合
    \item $update_{recomputed} = Krum(\{local_1, ..., local_n\})$
    \item // 階段二：比對結果
    \item if $Distance(update_{original}, update_{recomputed}) > threshold$:
    \item \quad return "挑戰成功"
    \item else:
    \item \quad return "挑戰失敗"
    \item // 階段三：多數投票 (由智能合約執行)
    \item 收集所有驗證節點的結果
    \item if 多數節點返回 "挑戰成功":
    \item \quad 執行懲罰和獎勵分配
    \item else:
    \item \quad 罰沒挑戰者質押
\end{enumerate}

\subsection{數據結構設計}

更新記錄格式 (Update Record Format)：
每個全局更新在區塊鏈上記錄包含輪次編號、更新哈希、本地更新哈希集合、聚合者地址、委員會成員、狀態 (PENDING, CONFIRMED, CHALLENGED, FINALIZED)、時間戳與投票記錄。

挑戰證明格式 (Challenge Proof Format)：
挑戰者提交的挑戰包含挑戰編號、被挑戰輪次、挑戰者地址、質押金額、時間戳、驗證節點結果與狀態 (PENDING, RESOLVED\_SUCCESS, RESOLVED\_FAIL)。

\section{本章小結}

本章詳細描述了基於激勵相容機制的區塊鏈聯邦學習系統架構。系統的核心創新在於將安全性從「誠實多數假設」轉變為「經濟理性假設」，通過樂觀挑戰機制和內部懲罰獎勵系統實現了「Security by Deterrence」。

主要貢獻包括：
\begin{itemize}
    \item 系統架構設計：提出了包含訓練者、聚合者、驗證委員會和挑戰者的四角色架構，實現了安全性與活性的解耦。
    \item 樂觀挑戰機制：設計了「先執行，後驗證」的流程，在正常情況下保持高效率，在異常情況下觸發全網驗證。
    \item 激勵相容機制：通過內部懸賞系統，將攻擊者的懲罰轉化為挑戰者的獎勵，實現了自我維持的安全保證。
    \item 安全性分析：證明了在威懾條件下，理性攻擊者不會發動攻擊。
    \item 效率分析：展示了系統在通訊複雜度、計算開銷和延遲方面相比傳統方法的顯著優勢。
\end{itemize}

下一章將通過實驗評估驗證本章提出的理論分析，展示系統在實際場景中的性能表現。

\end{ZhChapter}
